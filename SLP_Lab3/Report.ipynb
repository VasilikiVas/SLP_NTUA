{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"ProLab3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VV6-awvS6vA3","colab_type":"text"},"source":["<img src=\"https://www.rephil.eu/images/emp-in.jpg\" width=\"250\" align=\"center\">\n","<i><br>\n","<font size=\"5\"><b>Εθνικό Μετσόβιο Πολυτεχνείο</b></font><br>\n","<font size=\"4\">Σχολή Ηλεκτρολόγων Μηχανικών και Μηχανικών Υπολογιστών </font><br>\n","<font size=\"3\">Τομέας Σημάτων, Ελέγχου και Ρομποτικής</font><br>\n","<font size=\"3\">Εργαστήριο Όρασης Υπολογιστών, Επικοινωνίας Λόγου και Επεξεργασίας Σημάτων</font><br><br>\n","<font size=\"3\"><b>Επεξεργασία Φωνής και Φυσικής Γλώσσας</b></font>\n","</i><br><br>"]},{"cell_type":"markdown","metadata":{"id":"yM0CFwJN6vBA","colab_type":"text"},"source":["<i>\n","<font size=\"4\"><b> Προπαρασκευή 3ου εργαστηρίου + 3ο Εργαστήριο</b></font><br>\n","<font size=\"4\">Ακ. Έτος: 2019 - 2020</font><br>\n","<font size=\"3\">Εξάμηνο: 7ο</font><br>\n","<br><br>\n","<font size=\"3\"><b>Βασιλείου Βασιλική - 03115033</font><br>\n","<font size=\"3\"><b>Ψαρουδάκης Ανδρέας - 03116001</font>\n","</i><br><br><br>"]},{"cell_type":"markdown","metadata":{"id":"vSSE5EjJ6vBI","colab_type":"text"},"source":["# Περιεχόμενα\n","\n","## 1. [Προπαρασκευή 3ου εργαστηριου](http://localhost:8888/notebooks/Downloads/slp-lab3-prep-master/ProLab3.ipynb#%CE%9C%CE%AD%CF%81%CE%BF%CF%82-1:-%CE%A0%CF%81%CE%BF%CF%80%CE%B1%CF%81%CE%B1%CF%83%CE%BA%CE%B5%CF%85%CE%AE)\n","\n","## 2. [3ο Εργαστήριο](http://localhost:8888/notebooks/Downloads/slp-lab3-prep-master/ProLab3.ipynb#%CE%9C%CE%AD%CF%81%CE%BF%CF%82-2:-%CE%95%CF%81%CE%B3%CE%B1%CF%83%CF%84%CE%AE%CF%81%CE%B9%CE%BF)\n","<br><br><br>"]},{"cell_type":"code","metadata":{"id":"WHsZCVqM6-e1","colab_type":"code","outputId":"b5beb07e-f21a-436e-8c6c-79a9e892b767","executionInfo":{"status":"ok","timestamp":1580338626219,"user_tz":-120,"elapsed":698,"user":{"displayName":"Sila Vassiliou","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBczENOkf_0tutuC6ZxMaKre-GZe-2xSVNe5DGsTg=s64","userId":"12235529962578225857"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aFm6iUc5_N5Q","colab_type":"code","outputId":"f967ab7c-f389-49e9-ace2-88c88aa420bf","executionInfo":{"status":"ok","timestamp":1580338641979,"user_tz":-120,"elapsed":4818,"user":{"displayName":"Sila Vassiliou","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBczENOkf_0tutuC6ZxMaKre-GZe-2xSVNe5DGsTg=s64","userId":"12235529962578225857"}},"colab":{"base_uri":"https://localhost:8080/","height":208}},"source":["ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["AttentionBiLSTM.json             dataloading.py  models_6_1.py\n","AttentionBiLSTM_predictions.txt  \u001b[0m\u001b[01;34mdatasets\u001b[0m/       models.py\n","AttentionBiLSTM.pt               \u001b[01;34membeddings\u001b[0m/     ProLab3.ipynb\n","AttentionDNN.json                main.py         \u001b[01;34m__pycache__\u001b[0m/\n","AttentionDNN_predictions.txt     models_1_1.py   README.md\n","AttentionDNN.pt                  models_2_1.py   requirements.txt\n","AttentionLSTM.json               models_2_2.py   SelfAttention.py\n","AttentionLSTM_predictions.txt    models_3_1.py   training.py\n","AttentionLSTM.pt                 models_3_2.py   \u001b[01;34mutils\u001b[0m/\n","config.py                        models_4_1.py\n","\u001b[01;34mdataloading_files\u001b[0m/               models_4_2.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KvxnpFuS7UKp","colab_type":"code","outputId":"5afda390-6c8e-4505-bd15-d9b63ea28f07","executionInfo":{"status":"ok","timestamp":1580338634300,"user_tz":-120,"elapsed":663,"user":{"displayName":"Sila Vassiliou","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBczENOkf_0tutuC6ZxMaKre-GZe-2xSVNe5DGsTg=s64","userId":"12235529962578225857"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd \"drive/My Drive/slp-lab3-prep-master.zip (Unzipped Files)/slp-lab3-prep-master\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/slp-lab3-prep-master.zip (Unzipped Files)/slp-lab3-prep-master\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2BPy1wfs6vBM","colab_type":"text"},"source":["# Μέρος 1: Προπαρασκευή"]},{"cell_type":"markdown","metadata":{"id":"vvnII3pQ6vBR","colab_type":"text"},"source":["## **Εισαγωγή**"]},{"cell_type":"markdown","metadata":{"id":"T4dOzRgl6vBZ","colab_type":"text"},"source":["Σκοπός της παρούσας εργαστηριακής άσκησης είναι η υλοποίηση μοντέλου για την __επεξεργασία και κατηγοριοποίηση κειμένων με την χρήση βαθιών νευρωνικών δικτύων (Deep Neural Networks - DNN)__. Για την ανάπτυξη των μοντέλων θα γίνει χρήση της βιβλιοθήκης __Pytorch__. Αρχικά, με χρήση προ-εκπαιδευμένων διανυσματικών αναπαραστάσεων λέξεων (pretrained word embeddings), καλούμαστε να δημιουργήσουμε αναπαραστάσεις για κάθε κείμενο. Στη συνέχεια, θα χρησιμοποιήσουμε τις αναπαραστάσεις των κειμένων, ώστε να κάνουμε την κατηγοριοποίηση. Στόχος είναι να εκπαιδεύσουμε τα μοντέλα, ώστε αυτά να μπορούν να κάνουν ανάλυση συναισθήματος(sentiment analysis) σε προτάσεις. Για την εκπαίδευση των μοντέλων μας παρέχονται τα 2 ακόλουθα σύνολα δεδομένων:\n","\n"," - __Sentence Polarity Dataset2__ [Pang and Lee, 2005]:  To dataset αυτό περιέχει 5331 θετικές και 5331 αρνητικές κριτικές ταινιών,από το Rotten Tomatoes και είναι binary-classification πρόβλημα(positive, negative)\n"," \n","- __Semeval 2017 Task4-A3__ [Rosenthal et al., 2017]:  To dataset αυτό περιέχει tweets τα οποία είναι κατηγοριοποιημένα σε 3 κλάσεις (positive,  negative,  neutral) με 49570 παραδείγματα εκπαίδευσης και 12284 παραδείγματα αξιολόγησης."]},{"cell_type":"markdown","metadata":{"id":"qVDMzHjA6vBd","colab_type":"text"},"source":["## **1. Περιβάλλον Ανάπτυξης**"]},{"cell_type":"markdown","metadata":{"id":"ivwlNY356vBj","colab_type":"text"},"source":["Στήνουμε το περιβάλλον ανάπτυξης στον υπολογιστή μας. Αρχικά, κατεβάζουμε το αποθετήριο: https://github.com/slp-ntua/slp-lab3-prep. Στην συνέχεια, επιλέγουμε να κατεβάσουμε τα προεκπαιδευμένα διανύσματα λέξεων __GloVe embeddings__ στον φάκελο __/embeddings__ του project καθώς υπάρχουν διαθέσιμα embeddings σε χαμηλές διαστάσεις (περιέχει ακόμα και 50-διάστατα embeddings), το οποίο σημαίνει λιγότερες υπολογιστικές απαιτήσεις. Εναλλακτικά θα μπορούσαμε να χρησιμοποιήσουμε και τα __FastText  embeddings__, τα οποία ωστόσο είναι διαθέσιμα μόνο σε 300 διαστάσεις. Χρειάζεται ακόμα να εγκαταστήσουμε ορισμένες βιβλιοθήκες για την υλοποίηση της άσκησης. Η εγκατάσταση αυτή θα γίνει σε ένα ανεξάρτητο περιβάλλον, ώστε να μην υπάρξουν διενέξεις με τις υπόλοιπες βιβλιοθήκες στον υπολογιστή μας. Για το σκοπό αυτό θα κάνουμε χρήση του εργαλείου __conda__. Ετσι λοιπόν, δημιουργούμε ένα νέο περιβάλλον και το ενεργοποιούμε με τις ακόλουθες εντολές:\n","\n"," __conda create -n slp3 python=3__                                                                                                                    \n"," __source activate slp3__\n","\n","Έπειτα, εγκαθιστούμε το __PyTorch__ εκτελώντας την ακόλουθη εντολή:\n","\n","__conda install pytorch torchvision cudatoolkit=10.1 -c pytorch__\n","\n","και στη συνέχεια όλες τις υπόλοιπες βιβλιοθήκες με την εντολή:\n","\n","__pip install -r requirements.txt__"]},{"cell_type":"markdown","metadata":{"id":"v9ZdhuOR6vBo","colab_type":"text"},"source":["__Σημείωση__: Για την αποφυγή ορισμένων errors που προέκυπταν τροποποιήσαμε το αρχείο requirements.txt θέτοντας την έκδοση του numpy σε 1.17.1 (numpy==1.17.1)"]},{"cell_type":"markdown","metadata":{"id":"OYzxvRso6vBr","colab_type":"text"},"source":["## **1. Προεπεξεργασία Δεδομένων**"]},{"cell_type":"markdown","metadata":{"id":"4a4YgvH76vBw","colab_type":"text"},"source":["Σε αυτό το βήμα θα πρέπει να επεξεργαστούμε τα δεδομένα, ώστε να μπορέσουμε να εκπαιδεύσουμε στη συνέχεια το νευρωνικό δίκτυο. Για την καλύτερη διαχείριση των δεδομένων εκπαίδευσης θα χρησιμοποιήσουμε τα εργαλεία που παρέχει το PyTorch (κλάσεις __Dataset__ και __Dataloader__),κληρονομώντας τις αντίστοιχες κλάσεις και φτιάχνοντας δικές μας. Η κλάση __torch.utils.data.Dataset__ μετατρέπει κάθε παράδειγμα στην μορφή που απαιτείται για την εκπαίδευση του νευρωνικού δικτύου και η κλάση __torch.utils.data.Dataloader__ χρησιμοποιεί ένα στιγμιότυπο της κλάσης Dataset για να μετατρέψει τα παραδείγματα του σε torchTensors και να τα οργανώσει σε mini-batces. Η επέκταση της κλάσης __Dataset__ που θα υλοποιήσουμε θα περιέχει τις μεταβλητές με τα παραδείγματα και τις επισημειώσεις (labels) κάθε συνόλου δεδομένων,καθώς και τις μεθόδους για την επεξεργασία και την προετοιμασία τους."]},{"cell_type":"markdown","metadata":{"id":"RspHRF-c6vB2","colab_type":"text"},"source":["<font size=\"4\"><b>1.1 Κωδικοποίηση Επισημειώσεων(Labels)</b></font> "]},{"cell_type":"markdown","metadata":{"id":"MY5nUNDT6vB6","colab_type":"text"},"source":["Αρχικά, οι επισημειώσεις (labels) των παραδειγμάτων εκπαίδευσης έχουν την μορφή κειμένου (positive, neutral, negative...). Τις κωδικοποιούμε με χρήση του __LabelEncoder__ του __scikit-learn__ ώστε κάθε κλάση να αντιστοιχεί σε έναν συγκεκριμένο αριθμό. Η αντιστοίχηση είναι ίδια για training και test sets."]},{"cell_type":"markdown","metadata":{"id":"l3aIjVQN6vB9","colab_type":"text"},"source":["<u> __Ζητούμενο 1</u>__ : Συμπληρώστε τα κενά στη θέση __main.py:EX1__ και τυπώστε τα πρώτα 10 labels από τα δεδομένα εκπαίδευσης και τις αντιστοιχίες τους σε αριθμούς."]},{"cell_type":"markdown","metadata":{"id":"yHbeKq0v6vCA","colab_type":"text"},"source":["Για την υλοποίηση των προηγουμένων εκτελούμε τον εξής κώδικα:\n","\n","```python\n","print(\"loading word embeddings...\")\n","word2idx, idx2word, embeddings = load_word_vectors(EMBEDDINGS, EMB_DIM)\n","\n","# load the raw data\n","for DATASET in DATASETS:\n","\tif DATASET == \"Semeval2017A\":\n","    \t\tX_train, y_train, X_test, y_test = load_Semeval2017A()\n","\telif DATASET == \"MR\":\n","    \t\tX_train, y_train, X_test, y_test = load_MR()\n","\telse:\n","    \t\traise ValueError(\"Invalid dataset\")\n","\n","\t# convert data labels from strings to integers\n","\tle = LabelEncoder()\n","\n","\ty_train = le.fit_transform(y_train)  # EX1\n","\ty_test = le.fit_transform(y_test)    # EX1\n","\tn_classes = le.classes_.size         # EX1\n","\n","\tprint(\"------------------- EX1 -\", DATASET, \"-------------------\")\n","\tprint(\"The first 10 unencoded labels from the training set are: \")\n","\tprint(le.inverse_transform(y_train[:10]))\n","\tprint(\"The first 10 encoded labels from the training set are: \")\n","\tprint(y_train[:10])\n","\n","```"]},{"cell_type":"markdown","metadata":{"id":"Hhl0e7V26vCC","colab_type":"text"},"source":["Τα αποτελέσματα που πήραμε εκτελώντας το προηγούμενο κομμάτι της main.py στο bash είναι:\n","\n","<a href=\"https://ibb.co/SxFz3Zr\"><img src=\"https://i.ibb.co/GJzq5rT/Screenshot-from-2020-01-12-23-35-39.png\" alt=\"Screenshot-from-2020-01-12-23-35-39\" border=\"0\"></a>"]},{"cell_type":"markdown","metadata":{"id":"u7RxMtge6vCH","colab_type":"text"},"source":["<font size=\"4\"><b>1.2 Λεκτική Ανάλυση (Tokenization)</b></font>  "]},{"cell_type":"markdown","metadata":{"id":"zdgJI0ri6vCK","colab_type":"text"},"source":["Θέλουμε τώρα να μετατρέψουμε τα δεδομένα μας από κείμενα σε ακολουθίες από tokens. Στο αρχείο __dataloading.py__ έχει δηλωθεί η κλάση __SentenceDataset__,η οποία επεκτείνει την κλάση __torch.utils.data.Dataset__ . Εκτελούμε το __tokenization__ κατά την αρχικοποίηση του __Dataset__ σε όλα τα δεδομένα του και διατηρούμε τα επεξεργασμένα δεδομένα σε μεταβλητή στην κλάση. Ανάλογα με τις ιδιαιτερότητες του dataset μας χρησιμοποιούμε διαφορετικούς tokenizers. Συγκεκριμένα, για το __Semeval2017A dataset__ που περιέχει tweets θα χρησιμοποιήσουμε τον __TweetTokenizer__ της βιβλιοθήκης __nltk__ ενώ για το MR dataset, του οποίου τα κείμενα δεν εμφανίζουν κάποια μεγάλη ιδιαιτερότητα, μπορούμε να χρησιμοποιήσουμε κάποιον δικό μας tokenizer και να μην κάνουμε χρήση κάποιου έτοιμου."]},{"cell_type":"markdown","metadata":{"id":"GrHuWIx16vCO","colab_type":"text"},"source":["<u> __Ζητούμενο 2</u>__ : Συμπληρώστε τα κενά στη θέση __dataloading.py:EX2__ και τυπώστε τα πρώτα 10 παραδείγματα από τα δεδομένα εκπαίδευσης."]},{"cell_type":"markdown","metadata":{"id":"3nWvAqF86vCR","colab_type":"text"},"source":["Το τμήμα κώδικα του αρχείου __dataloading.py__  το οποίο θα συμπληρώσουμε είναι __αρχικά__ ως εξής:\n","```python\n","def __init__(self, X, y, word2idx):\n","    \"\"\"\n","    In the initialization of the dataset we will have to assign the\n","    input values to the corresponding class attributes\n","    and preprocess the text samples\n","\n","    -Store all meaningful arguments to the constructor here for debugging\n","     and for usage in other methods\n","    -Do most of the heavy-lifting like preprocessing the dataset here\n","\n","\n","    Args:\n","        X (list): List of training samples\n","        y (list): List of training labels\n","        word2idx (dict): a dictionary which maps words to indexes\n","    \"\"\"\n","\n","    # self.data = X\n","    # self.labels = y\n","    # self.word2idx = word2idx\n","\n","    # EX2\n","    raise NotImplementedError\n","```"]},{"cell_type":"markdown","metadata":{"id":"BzZP8cif6vCU","colab_type":"text"},"source":["__Μετά την συμπλήρωση του κώδικα__ για το Ζητούμενο2 ο κώδικας έχει την ακόλουθη εικόνα:\n","\n","    \n","```python\n","    def __init__(self, X, y, word2idx,DATASET):\n","        \"\"\"\n","        In the initialization of the dataset we will have to assign the\n","        input values to the corresponding class attributes\n","        and preprocess the text samples\n","\n","        -Store all meaningful arguments to the constructor here for debugging\n","         and for usage in other methods\n","        -Do most of the heavy-lifting like preprocessing the dataset here\n","\n","\n","        Args:\n","            X (list): List of training samples\n","            y (list): List of training labels\n","            word2idx (dict): a dictionary which maps words to indexes\n","        \"\"\"\n","        # EX2\n","        if DATASET == \"Semeval2017A\":\n","            tweetToken = TweetTokenizer()\n","            self.data = [tweetToken.tokenize(example) for example in X]\n","        elif DATASET == \"MR\":\n","            self.data = []\n","            for sample in X:\n","                new_string = sample.strip()\n","                new_string = new_string.lower()\n","                for punctuation in string.punctuation:\n","                    new_string = new_string.replace(punctuation,' ')\n","                new_string = \"\".join((char for char in new_string if char.isalpha() or char.isspace()))\n","                new_string = new_string.replace(\"\\n\", \" \")\n","                new_string = new_string.split()\n","                self.data.append(new_string)\n","        else:\n","            raise ValueError(\"Invalid dataset\")\n","        self.labels = y\n","        self.word2idx = word2idx\n","```"]},{"cell_type":"markdown","metadata":{"id":"MVIGw0YF6vCZ","colab_type":"text"},"source":["Τα αποτελέσματα που πήραμε εκτελώντας το εως τώρα κομμάτι της main.py χωρίς την εμφάνιση των αποτελεσμάτων του προηγούμενου ερωτήματος στο bash είναι:\n","\n","<a href=\"https://ibb.co/pfzZgBy\"><img src=\"https://i.ibb.co/Jv72NwQ/Screenshot-from-2020-01-13-02-44-33.png\" alt=\"Screenshot-from-2020-01-13-02-44-33\" border=\"0\"></a>\n","<a href=\"https://ibb.co/N99chSD\"><img src=\"https://i.ibb.co/5rrbDFp/Screenshot-from-2020-01-13-02-45-35.png\" alt=\"Screenshot-from-2020-01-13-02-45-35\" border=\"0\"></a>"]},{"cell_type":"markdown","metadata":{"id":"UkONlNGZ6vCc","colab_type":"text"},"source":["<font size=\"4\"><b> 1.3 Κωδικοποίηση Παραδειγμάτων (Λέξεων)</b></font>  "]},{"cell_type":"markdown","metadata":{"id":"z72bkdJC6vCf","colab_type":"text"},"source":["Αυτό είναι το τελικό βήμα,στο οποίο θα πρέπει να προετοιμάσουμε κάθε παράδειγμα στην κατάλληλη μορφή για την εκπαίδευση\n","του νευρωνικού δικτύου. \n","\n","<u> __Ζητούμενο 3</u>__ : Υλοποιήστε τη μέθοδοgetitemτης κλάσηςSentenceDataset(θέσηdataloading.py:EX3)και τυπώστε5παραδείγματα στην αρχική τους μορφή και όπως τα επιστρέφειη κλάσηSentenceDataset.\n","\n","Απαιτείται να υλοποιήσουμε τα εξής:\n","\n","1. Κάθε όρος(token - term) πρέπει να χαρτογραφηθεί σε ένα αριθμό,ώστε να μπορεί το embedding layer να τον αντιστοιχίσει στη σωστή διανυσματική αναπαράσταση (word embedding). Αρχικά \"πλοτάρουμε\" τα αρχικά μας δεδομένα και όπως βλέπουμε και στο σχήμα που ακολουθεί υπάρχον κάποιες outliers τιμές,<a href=\"https://ibb.co/yQNN2PT\"><img src=\"https://i.ibb.co/5R11Z4D/imgonline-com-ua-twotoone-Er-COT75-GNo.png\" alt=\"imgonline-com-ua-twotoone-Er-COT75-GNo\" border=\"0\"></a> τις οποίες αφαιρούμε μέσω του κώδικα που προσθέτουμε στην συνάρτηση init της κλάσης SentenceDataset. Συγκεκριμένα κρατάμε μόνο τις τιμές που βρίσκονται γύρω από την μέση τιμή +- 2 * τυπική αποκλιση. Ενώ παράλληλα επιλέγουμε ως best length το 0.8 * την μέγιστη τιμή ώστε να αποκλίσουμε κάποιες επιπλέον μεγάλες τιμές που έχουν απομείνει και δεν αφορούν την πλειοψηφία. Η συνάρτηση λοιπόν γίνεται:\n","\n","```python\n","    def __init__(self, X, y, word2idx,DATASET):\n","        \"\"\"\n","        In the initialization of the dataset we will have to assign the\n","        input values to the corresponding class attributes\n","        and preprocess the text samples\n","\n","        -Store all meaningful arguments to the constructor here for debugging\n","         and for usage in other methods\n","        -Do most of the heavy-lifting like preprocessing the dataset here\n","\n","\n","        Args:\n","            X (list): List of training samples\n","            y (list): List of training labels\n","            word2idx (dict): a dictionary which maps words to indexes\n","        \"\"\"\n","        # EX2\n","        if DATASET == \"Semeval2017A\":\n","            tweetToken = TweetTokenizer()\n","            self.data = [tweetToken.tokenize(example) for example in X]\n","        elif DATASET == \"MR\":\n","            self.data = []\n","            for sample in X:\n","                new_string = sample.strip()\t\t# remove all the leading and trailing spaces from a string\n","                new_string = new_string.lower()\t\t# lowercase string\n","                for punctuation in string.punctuation:\t# remove punctuation\n","                    new_string = new_string.replace(punctuation,' ')\n","                # Keeps only letters and spaces\n","                new_string = \"\".join((char for char in new_string if char.isalpha() or char.isspace()))\t\t\n","                new_string = new_string.replace(\"\\n\", \" \")\t\t# replace newlines with spaces\n","                # use split without parameter to split the words indipendently of spaces number\n","                new_string = new_string.split()\t\t\t\n","                self.data.append(new_string)\n","        else:\n","            raise ValueError(\"Invalid dataset\")\n","        self.labels = y\n","        self.word2idx = word2idx\n","\n","        # raise NotImplementedError\n","        \n","        #EX3\n","        init_len = [len(sample) for sample in self.data]\n","        init_len_mean = np.mean(init_len)\n","        init_len_std = np.std(init_len)\n","        upper_bound = init_len_mean+2*init_len_std\n","        lower_bound = init_len_mean-2*init_len_std\n","        without_outl_len = [l for l in init_len if l >= lower_bound and l <= upper_bound]\n","        without_outl_len = sorted(without_outl_len)\n","        self.best_len = without_outl_len[ceil(0.8*len(without_outl_len))]\n","```\n","\n","2. Όλα τα παραδείγματα θα πρέπει να έχουν το ίδιο μήκος. Αυτό είναι αναγκαίο για να μπορούν να εκτελεστούν πράξεις γραμμικής άλγεβρας,όπως πολλαπλασιασμός πινάκων. Αφού επιλέξαμε λοιπόν το καλύτερο μήκος πρέπει στην συνέχεια οποιαδήποτε πρόταση να έχει το μήκος αυτό. Για να μπορέσουμε να μεγαλώσουμε τις μικρές προτάσεις αρχικαποιήσαμε τον πίνακα example με μηδενικά και στην συνέχεια τον γεμίσαμε με τις ___word2idx___ αντιστοιχίσεις. Στην περίπτωση που μία λέξη δεν έχει αντιστοίχιση την αντιστοιχίζουμε με τον όρο < unk>. Όσο αναφορά τις μεγαλύτερες προτάσεις για να τις μικρύνουμε, απλά κόψαμε τις αντιστοιχήσεις των επιπλέον όρων. Για να τα επιτύχουμε αυτά προσθέσαμε στην get_item τον εξής κώδικα:\n","```python\n","    def __getitem__(self, index):\n","       \"\"\"\n","       Returns the _transformed_ item from the dataset\n","       Args:\n","           index (int):\n","       Returns:\n","           (tuple):\n","               * example (ndarray): vector representation of a training example\n","               * label (int): the class label\n","               * length (int): the length (tokens) of the sentence\n","       Examples:\n","           For an `index` where:\n","           ::\n","               self.data[index] = ['this', 'is', 'really', 'simple']\n","               self.target[index] = \"neutral\"\n","           the function will have to return something like:\n","           ::\n","               example = [  533  3908  1387   649   0     0     0     0]\n","               label = 1\n","               length = 4\n","       \"\"\"\n","       # EX3\n","       i = 0\n","       example = np.zeros(self.best_len, dtype = np.int64)\n","       for word in self.data[index]:\n","           if i < self.best_len:\n","               if word in self.word2idx.keys():\n","                   example[i] = (self.word2idx[word])\n","               else:\n","                   example[i] = (self.word2idx['<unk>'])\n","               i += 1\n","       length = len(self.data[index])\n","       label = self.labels[index]\n","       return example, label, length\n","```\n","Στη συνέχεια παρουσιάζουμε τα πέντα πρώτα αποτελέσματα με την μορφή που δίνονται και στην εκφώνηση, εκτελώντας το εως τώρα κομμάτι της main.py χωρίς την εμφάνιση των αποτελεσμάτων των προηγούμενων ερωτημάτων:\n","\n","<a href=\"https://ibb.co/JF7pbHM\"><img src=\"https://i.ibb.co/HpzPMqk/Screenshot-from-2020-01-13-23-09-42.png\" alt=\"Screenshot-from-2020-01-13-23-09-42\" border=\"0\"></a>\n","<a href=\"https://ibb.co/gRxPGyY\"><img src=\"https://i.ibb.co/rwVcgk9/Screenshot-from-2020-01-13-23-10-13.png\" alt=\"Screenshot-from-2020-01-13-23-10-13\" border=\"0\"></a>\n","<a href=\"https://ibb.co/rdLCkVj\"><img src=\"https://i.ibb.co/Z2wnd0j/Screenshot-from-2020-01-13-23-11-37.png\" alt=\"Screenshot-from-2020-01-13-23-11-37\" border=\"0\"></a>\n","<a href=\"https://ibb.co/svKTgJh\"><img src=\"https://i.ibb.co/HDtcKp0/Screenshot-from-2020-01-13-23-12-07.png\" alt=\"Screenshot-from-2020-01-13-23-12-07\" border=\"0\"></a>"]},{"cell_type":"markdown","metadata":{"id":"4kycJv7x6vCj","colab_type":"text"},"source":["## **2. Μοντέλο**"]},{"cell_type":"markdown","metadata":{"id":"xpOWXFo66vCm","colab_type":"text"},"source":["<font size=\"4\"><b>  2.1  Embedding Layer </b></font>\n","\n","Στο ερώτημα αυτό καλούμαστε να υλοποιήσουμε τα εξής:\n","- Να δημιουργήσουμε ένα embedding layer.\n","- Να αρχικοποιήσσουμε τα βάρη του δικτύου από τα προεκπαιδευμένα word embeddings.\n","- Παγώσουμε το embedding layer, δηλαδή να δηλώσουμε ότι τα βάρη του δικτύου δεν θα ενημερωθούν περαιτέρω κατά την εκπαίδευση του μοντέλου.\n","\n","<u> __Ζητούμενο 4</u>__ : Συμπληρώστε τα κενά στις θέσεις models.py:EX4 και απαντήστε στα ερωτήματα.\n","\n","Προσθέσαμε λοιπόν στην συνάρτηση init της κλάσης BaselineDNN τον εξής κώδικα (_# EX4_):\n","```python\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        \"\"\"\n","\n","        Args:\n","            output_size(int): the number of classes\n","            embeddings(bool):  the 2D matrix with the pretrained embeddings\n","            trainable_emb(bool): train (finetune) or freeze the weights\n","                the embedding layer\n","        \"\"\"\n","\n","        super(BaselineDNN, self).__init__()\n","        num_emb, dim_emb = embeddings.shape\n","        \n","        # 1 - define the embedding layer\n","        self.embedding = nn.Embedding(num_embeddings = num_emb, embedding_dim = emb_dim) # EX4\n","\n","        # 2 - initialize the weights of our Embedding layer\n","        # from the pretrained word embeddings\n","        self.embedding.weights(torch.from_numpy(embeddings))   # EX4\n","\n","        # 3 - define if the embedding layer will be frozen or finetuned\n","        if not trainable_emb:\n","\t    self.embeddings.weight.requires_grad = False # EX4\n","\n","        # 4 - define a non-linear transformation of the representations\n","        ...  # EX5\n","\n","        # 5 - define the final Linear layer which maps\n","        # the representations to the classes\n","        ...  # EX5\n","```\n","<br><br>\n","\n","__Γιατί αρχικοποιούμε το embedding layer με τα προ-εκπαιδευμένα word embeddings?__\n","\n","Ο λόγος για τον οποίο αρχικοποιούμε το __embedding layer__ με τα __προ-εκπαιδευμένα word embeddings__ είναι ότι θέλουμε από την αρχή τα embeddings να __μην είναι τυχαία__ αλλά να αναπαριστούν τις __σημασιολογικά παρόμοιες λέξεις κοντά στον πολυδιάστατο χώρο__. Έτσι, πραγματοποιείται πιο ποιοτική και γρήγορη εκπαίδευση του νευρωνικού μας δικτύου. Αν αρχικοποιούσαμε το embedding layer με τυχαίες τιμές και το αφήναμε να εκπαιδευτεί πάνω στα δεδομένα μας τότε θα ηταν πολύ πιο δύσκολο για το νευρωνικό να βρει κάποιο μοτίβο σε αυτά τα unstructered δεδομένα καθώς αυτά θα αναπαρηστούσαν τις λέξεις εντελώς τυχαία στο χώρο και θα καταλήγαμε σε κάποια προσέγγιση η οποία θα απείχε αρκετά από αυτό που επιθυμούμε. Μάλιστα,η τυχαία αναπάραση των λέξεων στο χώρο και η εκπαίδευση του νευρωνικού δικτύου με αυτές θα οδηγούσε σε καθυστέρηση εξαγωγής της σωστής αναπαράστασης και κατά συνέπεια σε μειωμένη ακρίβεια. \n","\n","<br><br>\n","\n","__Γιατί κρατάμε παγωμένα τα βάρη του embedding layer κατά την εκπαίδευση?__\n","\n","Τα __βάρη του embedding layer__ λειτουργούν ως παράμετροι. Το να κρατάμε τα βάρη αυτά παγωμένα πρακτικά ισοδυναμεί με τη διατήρηση των παραμέτρων σταθερών. \n","\n","Η χρήση αυτής της τεχνικής κατά την εκπαίδευση έχει __δύο σημαντικά πλεονεκτήματα__:\n","\n","1. __Αποφεύγεται το overfitting__ το οποίο είναι πολύ πιθανό να συμβεί αν εκτός από το νευρωνικό είχαμε και τις αναπαραστάσεις που μπαίνουν σε αυτό να εκπαιδεύονται πάνω στο train set μας. Σε αυτή την περίπτωση ο αλγόριθμος δεν θα μπορεί να γενικεύσει και θα καταλήξουμε με ένα μοντέλο που απλά έχει μάθει πολύ καλά τα δεδομένα που του δώσαμε.\n","\n","2. Μειώνονται οι συνολικές παράμετροι του μοντέλου μας __κερδίζοντας έτσι σε υπολογιστική πολυπλοκότητα__. Η συνεισφορά αυτής της τεχνικής είναι σημαντική στην ταχύτητα εκτέλεσης της εκπαίδευσης. Η μη τροποποίηση των παραμέτρων ουσιαστικά ισοδυναμεί με μη διεξαγωγή του backward pass, με αποτέλεσμα τη σημαντική αύξηση της ταχύτητας, σχεδόν στο διπλάσιο καθώς η μισή διαδικασία παραλείπεται."]},{"cell_type":"markdown","metadata":{"id":"lz7aT0D76vCp","colab_type":"text"},"source":["<font size=\"4\"><b>  2.2  Output Layer(s) </b></font>\n","\n","Στο ερώτημα αυτό καλούμαστε να υλοποιήσουμε τα εξής:\n","- Να δημιουργήσουμε ένα layer με μία μη γραμμική συνάρτηση ενεργοποίησης, το οποίο θα μαθαίνει ένα μετασχηματισμό της αναπαράστασης κάθε παραδείγματος.\n","- Να δημιουργήσουμε το τελευταίο layer το οποίο προβάλει τις τελικές αναπαραστάσεις των κειμένωνσ τις κλάσεις.\n","\n","<u> __Ζητούμενο 5</u>__ : Συμπληρώστε τα κενά στις θέσεις models.py:EX5 και απαντήστε στα ερωτήματα.\n","\n","Προσθέσαμε λοιπόν στην συνάρτηση init της κλάσης BaselineDNN τον εξής κώδικα (# EX5):\n","```python\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        \"\"\"\n","\n","        Args:\n","            output_size(int): the number of classes\n","            embeddings(bool):  the 2D matrix with the pretrained embeddings\n","            trainable_emb(bool): train (finetune) or freeze the weights\n","                the embedding layer\n","        \"\"\"\n","\n","        super(BaselineDNN, self).__init__()\n","        num_emb, dim_emb = embeddings.shape\n","        \n","        # 1 - define the embedding layer\n","        self.embedding = nn.Embedding(num_embeddings = num_emb, embedding_dim = emb_dim) # EX4\n","\n","        # 2 - initialize the weights of our Embedding layer\n","        # from the pretrained word embeddings\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings)) # EX4\n","\n","        # 3 - define if the embedding layer will be frozen or finetuned\n","        if not trainable_emb:\n","\t    self.embedding.weights.requires_grad = False # EX4\n","\n","        # 4 - define a non-linear transformation of the representations\n","        self.linear_hid = nn.Linear(dim_emb, 256) # EX5\n","        self.relu = nn.ReLU() # EX5\n","\n","        # 5 - define the final Linear layer which maps\n","        # the representations to the classes\n","        self.linear = nn.Linear(256, output_size) # EX5\n","```\n","\n","<br><br>\n","\n","__Γιατί βάζουμε μία μη γραμμική συνάρτηση ενεργοποίησης στο προτελευταίο layer?Τι διαφορά θα είχε αν είχαμε 2 ή περισσότερους γραμμικούς μετασχηματισμούς στη σειρά?__\n","\n","Η εισαγωγή μιας μη γραμμικής συνάρτησης ενεργοποιήσης στο προτελευταίο layer γίνεται ώστε να εισάγουμε την μη\n","γραμμικότητα στο μοντέλο και αυτό να μπορέσει να __αντιστοιχίσει με μεγαλύτερη επιτυχία την είοσοδο στην έξοδο__. Αν απλά είχαμε 2 ή περισσότερους γραμμικούς μετασχηματισμούς στη σειρά τότε αυτό θα ισοδυναμούσε με ένα απλό perceptron αφού το γινόμενο γραμμικών συναρτήσεων έχει ως αποτέλεσμα μια γραμμική συνάρτηση. Το νευρωνικό δίκτυο θα είχε τότε μειωμένη ακρίβεια καθώς θα μπορούσε να πραγματοποιήσει μια σωστή αντιστοίχιση μόνο για ένα πολύ περιορισμένο εύρος. Έτσι λοιπόν, προτιμάται η χρήση μιας μη γραμμικής συνάρτησης ενεργοποίησης για το προτελευταίο layer (βαθμού >1) η οποία αυξάνει την πολυπλοκότητα αλλά βελτιώνει σημαντικά τις επιδόσεις."]},{"cell_type":"markdown","metadata":{"id":"U2iAaEvE6vCs","colab_type":"text"},"source":["<font size=\"4\"><b>  2.3  Forward pass </b></font> \n","\n","Στο ερώτημα αυτό καλούμαστε να υλοποιήσουμε τα εξής:\n","- Να προβάλλουμε τις λέξεις κάθε πρότασης με το embedding layer που δημιουργήσαμε, όπου κάθε όρος(λέξη) θα αντιστοιχεί σε ένα διάνυσμα.\n","- Να δημιουργήσουμε μία αναπαράσταση για κάθε πρόταση, υπολογίζοντας τον μέσο όρο(κέντρο βάρους) των word embeddings σε μία πρόταση.\n","- Να εφαρμόσουμε τον μη-γραμμικό μετασχηματισμό που σχεδιάσαμε στο προηγούμενο ερώτημα σε κάθε αναπαράσταση και δημιουργήσουμε καινούριες αναπαραστάσεις.\n","- Να προβάλουμε τις τελικές αναπαραστάσεις στον χώρο των κλάσεων.\n","\n","<u> __Ζητούμενο 6</u>__ : Συμπληρώστε τα κενά στις θέσεις models.py:EX6 και απαντήστε στα ερωτήματα.\n","\n","Προσθέσαμε λοιπόν στην συνάρτηση forward της κλάσης BaselineDNN τον εξής κώδικα (# EX6):\n","Προσθέσαμε λοιπόν στην συνάρτηση init της κλάσης BaselineDNN τον εξής κώδικα (# EX5):\n","```python\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        \"\"\"\n","        This is the heart of the model.\n","        This function, defines how the data passes through the network.\n","\n","        Returns: the logits for each class\n","\n","        \"\"\"\n","\n","        # 1 - embed the words, using the embedding layer\n","        embeddings = self.embedding(x)  # EX6\n","\n","        # 2 - construct a sentence representation out of the word embeddings\n","        representations = torch.zeros([len(x), embeddings.shape[2]])  # EX6\n","        for i in range(batch_size):\n","           representations[i] = torch.sum(embeddings[i], dim=0) / lengths[i] # EX6\n","\n","        # 3 - transform the representations to new ones.\n","        representations = self.relu(self.linear_hid(representations)) # EX6\n","\n","        # 4 - project the representations to classes using a linear layer\n","        logits = self.linear(representations) # EX6\n","\n","        return logits\n","```\n","<br><br>\n","\n","__Αν θεωρήσουμε ότι κάθε διάσταση του embedding χώρου αντιστοιχεί σε μία αφηρημένη έννοια, μπορείτε να δώσετε μία διαισθητική ερμηνεία για το τι περιγράφει η αναπαράσταση που φτιάξατε (κέντρο-βάρους) ?__\n","\n","Στο μοντέλο που κατασκευάσαμε, η αναπαράσταση μιας πρότασης προκύπτει από το κέντρο βάρους των embeddings των λέξεων που απαρτίζουν την πρόταση. Έτσι, οι προτάσεις, οι οποίες αποτελούνται από λέξεις (διανύσματα στον πολυδιάστατο χώρο) συνιστούν και αυτές διανύσματα τα οποία σε κάθε διάσταση περιέχουν το μέσο όρο των τιμών των λέξεων που τις απαρτίζουν στην διάσταση αυτή. Αυτό πρακτικά μας δείχνει ότι η αναπαράσταση μας εκφράζει μια έννοια αν και μόνο αν οι λέξεις που την απαραρτίζουν εκφράζουν την ίδια σημασιολογική έννοια. Με άλλα λόγια, μπορούμε να δούμε την σχέση που έχει μια πρόταση με μια συγκεκριμένη αφηρημένη έννοια απλά κοιτώντας την τιμή της σε αυτήν την διάσταση. Ωστόσο, η αναπαράσταση αυτή δεν λαμβάνει υπόψιν της τα συντακτικά χαρακτηριστικά και έτσι υπάρχει το ενδεχόμενο να μην είναι απόλυτα ορθή η αποτύπωση των εννοιών που εμπεριέχεται σε μια πρόταση.\n","\n","<br><br>\n","\n","__Αναφέρετε πιθανές αδυναμίες της συγκεκριμένης προσέγγισης για να αναπαραστήσουμε κείμενα.__\n","\n","Η σημαντικότερη αδυναμία της συγκεκριμένης προσέγγισης για την αναπαράσταση κειμένων είναι το γεγονός ότι __δεν λαμβάνει υπόψιν τα συντακτικά χαρακτηριστικά μιας πρότασης__. Συγκεκριμένα, αντιμετωπίζει τις λέξεις με τον ίδιο τρόπο είτε αυτές βρίσκονται στην αρχή, είτε στο μέσον είτε στο τέλος μιας πρότασης. Αυτό ωστόσο, όπως αναφέραμε και προηγουμένως, ενδέχεται να οδηγήσει σε ανακριβείς ερμηνείες, μιας και τα συντακτικά χαρακτηριστικά μιας πρότασης παίζουν καθοριστικό ρόλο στην ορθή αποτύπωση των εννοιών που εκφράζονται μέσω αυτής. Για παράδειγμα, στην πρόταση “dog bites man” το dog είναι το υποκείμενο, το bites το ρήμα και το man το αντικείμενο. Αλλάζοντας την σειρά των λέξεων μπορεί να προκύψει η πρόταση “man bites dog” στην οποία το man πλέον είναι το υποκείμενο και το dog αντικείμενο και η οποία προφανώς έχει εντελώς διαφορετική σημασία από την προηγούμενη (παρόλο που αποτελείται από τις ίδιες ακριβώς λέξεις). Ένα ακόμη μειονέκτημα που αξίζει να αναφερθεί είναι η __αφαίρεση των σημείων στίξης__ κατά την προετοιμασία των δεδομένων. Όπως είναι προφανές και αυτά αποτελούν μια σημαντική συνιστώσα της σημασίας μιας πρότασης. Για παράδειγμα, η αφαίρεση του κόμματος στην πρόταση “Most of the time, travellers worry about their luggage.” αλλάζει εντελώς το νόημα της πρότασης."]},{"cell_type":"markdown","metadata":{"id":"vxv4j4zm6vCw","colab_type":"text"},"source":["## **3. Διαδικασία Εκπαίδευσης**\n","Στο βήμα αυτό εκπαιδεύοουμε το δίκτυο που δημιουργήσαμε στο βήμα 2. Συγκεκριμένα οργανώνουμε τα παραδείγματα σε mini batches και στη συνέχεια εκτελούμε stochastic gradient descent για να ενημερώνουμε τα βάρη του δικτύου. Όπως είναι γνωστό κατά το μεγαλύτερο μέρος του σχεδιασμού νευρωνικών δικτύων είναι δύσκολο να ελέγξουμε το αν μια λειτουργία που υλοποιούμε ή όχι. Συνεπώς και στην περίπτωση της παρούσας εργαστηριακής άσκησης τα βήματα 3.1 - 3.3 θα περιέχουν μόνο κώδικα και όχι αποτελέσματα. Στο βήμα 3.4 παρουσιάζονται τα αποτελέσματα που προκύπτουν."]},{"cell_type":"markdown","metadata":{"id":"Q_iUReUb6vCy","colab_type":"text"},"source":["<font size=\"4\"><b>  3.1 Φόρτωση Παραδειγμάτων(DataLoaders) </b></font>\n","\n","<u> __Ζητούμενο 7</u>__ : Συμπληρώστε τα κενά στις θέσεις main.py:EX7 και απαντήστε στα ερωτήματα.\n","\n","Για να μπορέσουμε να φτιάξουμε ένα στιγμιότυπο για κάθε dataset καλούμε την συνάρτηση DataLoader χρησιμοποιώντας ώς όρισμα την πρώτη φορά το trainning set και την δεύτερη φορά το testing set. Συνεπώς στον κώδικα main.py προσθέτουμε τις επόμενες γραμμές.\n","```python\n","    # EX7 - Define our PyTorch-based DataLoader\n","    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) # EX7\n","    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True) # EX7\n","```\n","<br><br>\n","\n","__Τι συνέπειες έχουν τα μικρά και μεγάλα mini-batches στην εκπαίδευση των μοντέλων?__\n","\n","Το μέγεθος των mini-batches καθορίζει τον αριθμό των δειγμάτων που θα μεταφερθούν μέσα στο δίκτυο σε κάθε επανάληψη και __επηρεάζει την εκπαίδευση του μοντέλου μας με δύο τρόπους__. Αρχικά, κατά την διάρκεια εκτέλεσης του __SGD (Stochastic Gradient Descent)__, __όσο μεγαλύτερο είναι το μέγεθος του mini-batch τόσο μικρότερος είναι ο θόρυβος που εισάγουμε στο μοντέλο μας__ καθώς βρισκόμαστε πιο κοντά στα gradients του training set. Αυτό ωστόσο δεν είναι συνήθως θετικό, καθώς στην περίπτωση που το mini-batch γίνει αρκετά μεγάλο ενδέχεται το νευρωνικό μας να συγκλίνει σε κάποιο τοπικό ελάχιστο και όχι στο ζητούμενο ολικό. Αυτό μπορεί να αποφευχθεί αν το μοντέλο έχει μικρότερα mini-batches, δηλαδή περισσότερο θόρυβο. Επίσης, __αν τα mini-batches είναι μικρά τότε η αναβάθμιση των βαρών σε κάθε επανάληψη γίνεται πιο γρήγορα και έτσι λαμβάνουμε μια πιο άμεση και ολοκληρωμένη εικόνα για το τι συμβαίνει στο μοντέλο μας__. Αξίζει να σημειωθεί βέβαια ότι αν το μέγεθος των mini-batches γίνει πολύ μικρό τότε έχουμε ανεπιθύμητες επιπτώσεις αφού εισάγεται πλέον στο σύστημά μας και στις εκτιμήσεις των gradients πολύς θόρυβος. \n","\n","<br><br>\n","\n","__Συνήθως ανακατεύουμε την σειρά των mini-batches στα δεδομένα εκπαίδευσης σε κάθε εποχή.Μπορείτε να εξηγήσετε γιατί?__\n","\n","Το ανακάτεμα (shuffling) της σειράς των mini-batches στα δεδομένα εκπαίδευσης σε κάθε εποχή γίνεται για __δύο λόγους__:\n","1. __Αποτρέπουμε το νευρωνικό μας δίκτυο από το να μάθει την σειρά με την οποία εισέρχονται τα δεδομένα σε αυτό__. Όπως έχουμε ήδη αναφέρει, το νευρωνικό δίκτυο έχει την δυνατότητα να μαθαίνει περίπλοκες μη γραμμικές συναρτήσεις που αντιστοιχούν την είσοδο στην έξοδο. Είναι λοιπόν ευνόητο ότι διαθέτει την ικανότητα εκμάθησης ακόμα και της σειράς των δεδομέων που εισέρχονται σε αυτό. Αν θέλουμε να το αποφύγουμε αυτό θα πρέπει να ανακατεύουμε (shuffle) τα mini-batches στα δεδομένα εκπαίδευσης (training data) σε κάθε εποχή. Με τον τρόπο αυτό το νευρωνικό θα βλέπει κάθε φορά τα δεδομένα με διαφορετική (τυχαία) σειρά και έτσι δεν θα λαμβάνει υπόψιν του τη σειρά αυτή κατά την εκπαίδευσή του.\n","\n","\n","2. __Παίζει καθοριστικό ρόλο στην σύγκλιση στο ολικό ελάχιστο__, η οποία και αποτελεί τον απώτερο στόχο του SGD (Stochastic Gradient Descent). Αυτό συμβαίνει καθώς δίνουμε διαρκώς διαφορετικά δεδομένα στο νευρωνικό δίκτυο, με αποτέλεσμα αν αυτό κολλήσει σε κάποιο τοπικό ελάχιστο, να έχει τη δυνατότητα άμεσης και εύκολης διαφυγής από αυτό σε επόμενες επαναλήψεις."]},{"cell_type":"markdown","metadata":{"id":"CgHVlXnn6vC0","colab_type":"text"},"source":["<font size=\"4\"><b>  3.2 Βελτιστοποίηση </b></font>\n","\n","Για την βελτιστοποίηση του μοντέλου ορίζουμε τα εξής:\n","1. __Κριτήριο__: Για το Sentence Polarity Dataset2 που έχει μόνο δύο κλάσεις χρησιμοποιούμε το BCEWithLogitsLoss,ενώ για το Semeval 2017 Task4-A3 που έχει τρείς κλάσεις χρησιμοποιούμε το CrossEntropyLoss. Στο σημείο αυτό αναφέρουμε ότι για το BCE στα labels να εφαρμοστεί _one hot encoding_, δηλαδή όταν το label έχει την τιμή 0 να πάρει την τιμή [1,0] σε αντίθετη περίπτωση να πάρει την τιμή [0,1] (υλοποιείται στο επόμενο βήμα).\n","2. __Παράμετροι__: Τροποποιούμε μόνο τις παραμέτρους που είναι εκπαιδεύσιμες, δηλαδή για αυτές που ισχύει model.parameters().requires_grad == True.\n","3. __Optimizer__: Ως αλγόριθμο βελτιστοποίησης που προσαρμόζει αυτόματα την ταχύτητα ενημέρωσης των βαρών επιλέξαμε τον Adam.\n","\n","<u> __Ζητούμενο 8</u>__ :Συμπληρώστε τα κενά στις θέσεις main.py:EX8.\n","\n","Συνεπώς οι προηγούμενες παραμετροποιήσεις εκτελούν το ζητούμενο και υλοποιούνται μέσω του επόμενου κώδικα.\n","\n","```python\n","    #############################################################################\n","    # Model Definition (Model, Loss Function, Optimizer)\n","    #############################################################################\n","    model = BaselineDNN(output_size=n_classes, embeddings=embeddings, trainable_emb=EMB_TRAINABLE) # EX8\n","\n","    # move the mode weight to cpu or gpu\n","    model.to(DEVICE)\n","    print(model)\n","\n","    # We optimize ONLY those parameters that are trainable (p.requires_grad==True)\n","    criterion = torch.nn.BCEWithLogitsLoss() if n_classes == 2 else torch.nn.CrossEntropyLoss() # EX8\n","    parameters = []  # EX8\n","    for param in model.parameters():  # EX8\n","        if param.requires_grad == True: parameters.append(param)  # EX8\n","    optimizer = torch.optim.Adam(parameters, lr = 0.0001) # EX8\n","```"]},{"cell_type":"markdown","metadata":{"id":"5bqjFkyj6vC3","colab_type":"text"},"source":["<font size=\"4\"><b>  3.3 Εκπαίδευση </b></font>\n","\n","H συνάρτηση traindataset καλείται για κάθε batch σε μία εποχή, δίνει τα δεδομένα εκπαίδευσης στο μοντέλο,υπολογίζει το σφάλμα και ενημερώνειτα βάρη του δικτύου με τον αλγόριθμο backpropagation. Τα ίδια κάνει και η συνάρτηση evaldataset, η οποία καλείται στο τέλος κάθε εποχής, για να αξιολογήσει το μοντέλο.\n","\n","<u> __Ζητούμενο 9</u>__ :Συμπληρώστε τα κενά στις θέσεις training.py:EX9.\n","\n","Για την υλοποίηση των παραπάνω λειτουργιών ο δωθείς κώδικας συμπληρώθηκε ως εξής:\n","\n","```python\n","def train_dataset(_epoch, dataloader, model, loss_function, optimizer):\n","    # IMPORTANT: switch to train mode\n","    # enable regularization layers, such as Dropout\n","    model.train()\n","    running_loss = 0.0\n","\n","    # obtain the model's device ID\n","    device = next(model.parameters()).device\n","\n","    for index, batch in enumerate(dataloader, 1):\n","        # get the inputs (batch)\n","        inputs, labels, lengths = batch\n","\n","        # move the batch tensors to the right device\n","        inputs = inputs.to(device) # EX9\n","        labels = labels.to(device) # EX9\n","        \n","        # Step 1 - zero the gradients\n","        # Remember that PyTorch accumulates gradients.\n","        # We need to clear them out before each batch!\n","        optimizer.zero_grad() # EX9\n","\n","        # Step 2 - forward pass: y' = model(x)\n","        ypred = model(inputs, lengths) # EX9\n","\n","        # Optimize labels to be compatible with each criterion\n","        if str(loss_function) == \"BCEWithLogitsLoss()\":  # EX9\n","            opt_labels = torch.nn.functional.one_hot(labels, 2).float()  # EX9\n","        else:\n","            opt_labels = labels  # EX9\n","        \n","        loss = loss_function(ypred, opt_labels) # EX9\n","\n","        # Step 4 - backward pass: compute gradient wrt model parameters\n","        loss.backward() # EX9\n","\n","        # Step 5 - update weights\n","        optimizer.step() # EX9\n","\n","        running_loss += loss.data.item()\n","\n","        # print statistics\n","        progress(loss=loss.data.item(),\n","                 epoch=_epoch,\n","                 batch=index,\n","                 batch_size=dataloader.batch_size,\n","                 dataset_size=len(dataloader.dataset))\n","\n","    return running_loss / index\n","\n","\n","def eval_dataset(dataloader, model, loss_function):\n","    # IMPORTANT: switch to eval mode\n","    # disable regularization layers, such as Dropout\n","\n","    model.eval()\n","    running_loss = 0.0\n","\n","    y_pred = []  # the predicted labels\n","    y = []  # the gold labels\n","\n","    # obtain the model's device ID\n","    device = next(model.parameters()).device\n","\n","    # IMPORTANT: in evaluation mode, we don't want to keep the gradients\n","    # so we do everything under torch.no_grad()\n","    with torch.no_grad():\n","        for index, batch in enumerate(dataloader, 1):\n","            # get the inputs (batch)\n","            inputs, labels, lengths = batch\n","\n","            # Step 1 - move the batch tensors to the right device\n","            inputs = inputs.to(device) # EX9\n","            labels = labels.to(device) # EX9\n","            lengths = lengths.to(device) # EX9\n","\n","            # Step 2 - forward pass: y' = model(x)\n","            ypred = model(inputs, lengths) # EX9\n","\n","            # Step 3 - compute loss.\n","            # We compute the loss only for inspection (compare train/test loss)\n","            # because we do not actually backpropagate in test time\n","            if str(loss_function) == \"BCEWithLogitsLoss()\":  # EX9\n","                opt_labels = torch.nn.functional.one_hot(labels, 2).float()  # EX9\n","            else:\n","                opt_labels = labels  # EX9\n","            loss = loss_function(ypred, opt_labels) # EX9\n","\n","            # Step 4 - make predictions (class = argmax of posteriors)\n","            arg_max_post = torch.argmax(ypred, 1) # EX9\n","\n","            # Step 5 - collect the predictions, gold labels and batch loss\n","            y_pred.append(arg_max_post.numpy()) # EX9\n","            y.append(labels.numpy()) # EX9\n","\n","            running_loss += loss.data.item()\n","\n","    return running_loss / index, (y_pred, y)\n","```"]},{"cell_type":"markdown","metadata":{"id":"D5TXJGmP6vC7","colab_type":"text"},"source":["<a href=\"https://ibb.co/pJjhWyP\"><img src=\"https://i.ibb.co/hDFYXfM/Screenshot-from-2020-01-18-01-38-26.png\" alt=\"Screenshot-from-2020-01-18-01-38-26\" border=\"0\"></a>\n","<a href=\"https://ibb.co/s3YknXT\"><img src=\"https://i.ibb.co/SvCWbZk/Screenshot-from-2020-01-18-01-39-47.png\" alt=\"Screenshot-from-2020-01-18-01-39-47\" border=\"0\"></a>\n","<a href=\"https://ibb.co/44rRWrq\"><img src=\"https://i.ibb.co/6DC0YCM/Screenshot-from-2020-01-18-01-42-20.png\" alt=\"Screenshot-from-2020-01-18-01-42-20\" border=\"0\"></a>\n","<a href=\"https://ibb.co/9GWZvLq\"><img src=\"https://i.ibb.co/stqWPGF/Screenshot-from-2020-01-18-01-43-25.png\" alt=\"Screenshot-from-2020-01-18-01-43-25\" border=\"0\"></a>"]},{"cell_type":"markdown","metadata":{"id":"IEKP4ftr6vC9","colab_type":"text"},"source":["<font size=\"4\"><b>  3.4 Αξιολόγηση </b></font>\n","\n","Στο βήμα αυτό καλούμαστε χρησιμοποιώντας κάποιες μετρικές να αξιολογήσουμε την απόδοση του μοντέλου μας.\n","\n","<u> __Ζητούμενο 10</u>__ :Για κάθε ένα από τα2  datasets που σας παρέχονται αναφέρετε τις επιδόσειςτου μοντέλου στις μετρικές:  accuracy, F1score (macro average), recall (macro average).Επίσης,δημιουργήστε γραφικές παραστάσεις, στις οποίες θα φαίνονται οι καμπύλες εκπαίδευσης του μοντέλου(training καιtest loss) ανά εποχή.\n","\n","Για να εκτελέσουμε το παραπάνω ζητούμενο υλοποιήσαμε στην main.py τον εξής κώδικα:\n","\n","```python\n","    #############################################################################\n","    # Training Pipeline\n","    #############################################################################\n","    trainning_loss = []\n","    testing_loss = []\n","    for epoch in range(1, EPOCHS + 1):\n","        # train the model for one epoch\n","        train_dataset(epoch, train_loader, model, criterion, optimizer)\n","\n","        # evaluate the performance of the model, on both data sets\n","        train_loss, (y_train_gold, y_train_pred) = eval_dataset(train_loader, model, criterion)\n","\n","        test_loss, (y_test_gold, y_test_pred) = eval_dataset(test_loader, model, criterion)\n","\n","        # make list of losses to plot them\n","        trainning_loss.append(train_loss)\n","        testing_loss.append(test_loss)\n","\n","    print(\"----------------- Results for \", DATASET, \" dataset -----------------\")\n","    print(\"The trainning loss is: \", train_loss)\n","    print(\"The testing loss is: \", test_loss)\n","    print(\"The accuracy, F1score (macro average), recall (macro average) \\033[1mfor train set\\033[0m are:\")\n","    y_train_gold = np.concatenate(y_train_gold, axis=0)\n","    y_test_gold = np.concatenate(y_test_gold, axis=0)\n","    y_train_pred = np.concatenate(y_train_pred, axis=0)\n","    y_test_pred = np.concatenate(y_test_pred, axis=0)\n","    print(classification_report(y_train_gold, y_train_pred), \"\\n\\n\")\n","    print(\"The accuracy, F1score (macro average), recall (macro average) \\033[1mfor test set\\033[0m are:\")\n","    print(classification_report(y_test_gold, y_test_pred), \"\\n\")\n","\n","    fig = plt.figure()\n","    plt.plot(trainning_loss, '-o', color = \"r\", label = \"Training data\")\n","    plt.plot(testing_loss, '-o', color = \"g\", label = \"Testing data\")\n","    fig.suptitle('Learning Curve')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","```\n","\n","Για τις μετρικές έχουμε τα εξής αποτελέσματα:\n","\n","<a href=\"https://ibb.co/NWZrXnQ\"><img src=\"https://i.ibb.co/L9nrMhb/Screenshot-from-2020-01-18-02-04-01.png\" alt=\"Screenshot-from-2020-01-18-02-04-01\" border=\"0\"></a>\n","<a href=\"https://ibb.co/17PzSxX\"><img src=\"https://i.ibb.co/fqyDc7N/Screenshot-from-2020-01-18-02-01-13.png\" alt=\"Screenshot-from-2020-01-18-02-01-13\" border=\"0\"></a>\n","<br><br><br>\n","Οι καμπύλες εκπαίδευσης του μοντέλου(training και test loss) ανά εποχή είναι:\n","\n","* ## ___-------------------------------------------------MR Datatset-------------------------------------------------___\n","<a href=\"https://ibb.co/ckL53b5\"><img src=\"https://i.ibb.co/ydSTPhT/Figure-1.png\" alt=\"Figure-1\" border=\"0\"></a>\n","\n","* ## ___---------------------------------------------Semeval2017A Datatset-------------------------------------------___\n","<a href=\"https://ibb.co/fQ5yMjn\"><img src=\"https://i.ibb.co/4JGXWhY/Figure-2.png\" alt=\"Figure-2\" border=\"0\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"Koq2dxml6vDB","colab_type":"text"},"source":["Η απόδοση του μοντέλου μας δεν είναι ιδαίτερα ικανοποιητική γεγονός που οφείλεται στο μικρό μέγεθος των embeddings καθώς και στην μη αποτελεσματική παραμετροποίηση του, το οποίο δεν αφορά τα πλάισια της προπαρασκευαστικής εργασίας.\n","Παρατηρούμε αρκετές διακυμάνσεις που οφείλονται στο overfitting που κάνει το μοντέλο μας στα δεδομένα του.\n","\n","Εκτελώντας το επόμενο κελί μπορούμε να δούμε όλα τα προηγούμενα αποτελέσματα συγκεντρωμένα."]},{"cell_type":"code","metadata":{"id":"tHnRN2kr6vDE","colab_type":"code","colab":{}},"source":["!python main.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KwuMpbNq6vDQ","colab_type":"text"},"source":["# Μέρος 2: Εργαστήριο\n","\n","Για τα ερωτήματα 1 έως και 4 δημιουργούμε διαφορετικά python scripts με τα αντίστοιχα ονόματα (πχ. models_1_1) και αλλάζουμε το Model Definition κομμάτι της main.py ώστε να μπορούμε να την καλούμε με όρισμα την κλάση που θα χρησιμοποιούμε την εκάστοτε φορά (πχ. OptimizedDNN), την οποία έχουμε ήδη κάνει import στην αρχή του κώδικα. Συνεπώς το αναφερθέν κομμάτι κώδικα γίνεται:\n","```python\n","    #############################################################################\n","    # Model Definition (Model, Loss Function, Optimizer)\n","    #############################################################################\n","    model_name = sys.argv[1] # Lab3.1.1 - Lab3.4.2\n","    model = eval(model_name)(output_size=n_classes, embeddings=embeddings, trainable_emb=EMB_TRAINABLE) # EX8\n","\n","    # move the mode weight to cpu or gpu\n","    model.to(DEVICE)\n","    print(model)\n","\n","    # We optimize ONLY those parameters that are trainable (p.requires_grad==True)\n","    criterion = torch.nn.BCEWithLogitsLoss() if n_classes == 2 else torch.nn.CrossEntropyLoss() # EX8\n","    parameters = []  # EX8\n","    for param in model.parameters():  # EX8\n","        if param.requires_grad == True: parameters.append(param)  # EX8\n","    optimizer = torch.optim.Adam(parameters, lr = 0.0001) # EX8\n","```"]},{"cell_type":"markdown","metadata":{"id":"078cPcdz6vDU","colab_type":"text"},"source":["<font size=\"4\"><b>  Ερώτημα 1.1 </b></font>\n","\n","Η αναπαράσταση κάθε πρότασης πλέον γίνεται $u= [mean(E)||max(E)]$ δηλαδή η συνένωση (concatenation) του μέσου όρου (mean pooling) και του μεγίστου ανά διάσταση (max pooling) των wordembeddings κάθε πρότασης, $E= (e_1, e_2, ..., e_N)$. Παράλληλα διπλασιάαμε το μέγεθος της εισόδου που δίνεται στο τελυταίο linear layer. Για να επιτευχθεί αυτό δημιουργούμε το models_1_1.py script o κώδικας του οποίου είναι: \n","```python\n","import torch\n","\n","from torch import nn\n","\n","\n","class OptimizedDNN(nn.Module):\n","    \"\"\"\n","    1. We embed the words in the input texts using an embedding layer\n","    2. We compute the min, mean, max of the word embeddings in each sample\n","       and use it as the feature representation of the sequence.\n","    4. We project with a linear layer the representation\n","       to the number of classes.ngth)\n","    \"\"\"\n","\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        \"\"\"\n","\n","        Args:\n","            output_size(int): the number of classes\n","            embeddings(bool):  the 2D matrix with the pretrained embeddings\n","            trainable_emb(bool): train (finetune) or freeze the weights\n","                the embedding layer\n","        \"\"\"\n","\n","        super(OptimizedDNN, self).__init__()\n","        num_emb, dim_emb = embeddings.shape\n","        \n","        # 1 - define the embedding layer\n","        self.embedding = nn.Embedding(num_embeddings = num_emb, embedding_dim = dim_emb) # EX4\n","\n","        # 2 - initialize the weights of our Embedding layer\n","        # from the pretrained word embeddings\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings)) # EX4\n","\n","        # 3 - define if the embedding layer will be frozen or finetuned\n","        if not trainable_emb:\n","            self.embedding.weight.requires_grad = False # EX4\n","\n","        # 4 - define a non-linear transformation of the representations\n","        self.linear_hid = nn.Linear(2*dim_emb, 256) # EX5\n","        self.relu = nn.ReLU() # EX5\n","\n","        # 5 - define the final Linear layer which maps\n","        # the representations to the classes\n","        self.linear = nn.Linear(256, output_size) # EX5\n","\n","    def forward(self, x, lengths, bows):\n","        \"\"\"\n","        This is the heart of the model.\n","        This function, defines how the data passes through the network.\n","\n","        Returns: the logits for each class\n","\n","        \"\"\"\n","\n","        # 1 - embed the words, using the embedding layer\n","        embeddings = self.embedding(x)  # EX6\n","\n","        # 2 - construct a sentence representation out of the word embeddings\n","        representation_mean = torch.zeros([len(x), embeddings.shape[2]])  # Lab3.1.1\n","        representation_max = torch.zeros([len(x), embeddings.shape[2]])  # Lab3.1.1\n","        for i in range(len(x)):\n","            representation_mean[i] = torch.sum(embeddings[i], dim=0) / lengths[i].float() # Lab3.1.1\n","            representation_max[i],_ = torch.max(embeddings[i], dim=0)\n","        representations = torch.cat((representation_mean,representation_max), 1) # Lab3.1.1\n","\n","        # 3 - transform the representations to new ones.\n","        representations = self.relu(self.linear_hid(representations.cuda())) # EX6\n","\n","        # 4 - project the representations to classes using a linear layer\n","        logits = self.linear(representations) # EX6\n","\n","        return logits\n","```\n","\n","Συνεπώς εκπαιδεύοντας το μοντέλο μας παίρνουμε τα εξής αποτελέσματα:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"VmkCPd1u6vDW","colab_type":"code","outputId":"8c48feb9-b1f9-404d-8fb1-02e01dc6a4d3","executionInfo":{"status":"ok","timestamp":1580133379807,"user_tz":-120,"elapsed":776455,"user":{"displayName":"Sila Vassiliou","photoUrl":"","userId":"12235529962578225857"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%run -i 'main.py' OptimizedDNN No"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading word embeddings...\n","Loaded word embeddings from cache.\n","OptimizedDNN(\n","  (embedding): Embedding(400002, 50)\n","  (linear_hid): Linear(in_features=100, out_features=256, bias=True)\n","  (relu): ReLU()\n","  (linear): Linear(in_features=256, out_features=3, bias=True)\n",")\n"," [========================================] ...Epoch 1, Loss: 0.9629\n"," [========================================] ...Epoch 2, Loss: 0.9467\n"," [========================================] ...Epoch 3, Loss: 0.9345\n"," [========================================] ...Epoch 4, Loss: 0.7531\n"," [========================================] ...Epoch 5, Loss: 0.9813\n"," [========================================] ...Epoch 6, Loss: 0.9499\n"," [========================================] ...Epoch 7, Loss: 0.8990\n"," [========================================] ...Epoch 8, Loss: 0.9185\n"," [========================================] ...Epoch 9, Loss: 0.7862\n"," [========================================] ...Epoch 10, Loss: 0.9320\n"," [========================================] ...Epoch 11, Loss: 1.0133\n"," [========================================] ...Epoch 12, Loss: 0.8079\n"," [========================================] ...Epoch 13, Loss: 0.7678\n"," [========================================] ...Epoch 14, Loss: 0.9185\n"," [========================================] ...Epoch 15, Loss: 0.9832\n"," [========================================] ...Epoch 16, Loss: 0.6992\n"," [========================================] ...Epoch 17, Loss: 0.9862\n"," [========================================] ...Epoch 18, Loss: 0.7782\n"," [========================================] ...Epoch 19, Loss: 0.6063\n"," [========================================] ...Epoch 20, Loss: 0.7423\n"," [========================================] ...Epoch 21, Loss: 0.8066\n"," [========================================] ...Epoch 22, Loss: 0.9015\n"," [========================================] ...Epoch 23, Loss: 0.8897\n"," [========================================] ...Epoch 24, Loss: 0.8199\n"," [========================================] ...Epoch 25, Loss: 0.8889\n"," [========================================] ...Epoch 26, Loss: 0.7641\n"," [========================================] ...Epoch 27, Loss: 0.7321\n"," [========================================] ...Epoch 28, Loss: 0.7762\n"," [========================================] ...Epoch 29, Loss: 0.8288\n"," [========================================] ...Epoch 30, Loss: 0.8193\n"," [========================================] ...Epoch 31, Loss: 0.8876\n"," [========================================] ...Epoch 32, Loss: 0.7657\n"," [========================================] ...Epoch 33, Loss: 0.7889\n"," [========================================] ...Epoch 34, Loss: 0.7446\n"," [========================================] ...Epoch 35, Loss: 0.8192\n"," [========================================] ...Epoch 36, Loss: 0.7381\n"," [========================================] ...Epoch 37, Loss: 0.8340\n"," [========================================] ...Epoch 38, Loss: 0.8781\n"," [========================================] ...Epoch 39, Loss: 0.7479\n"," [========================================] ...Epoch 40, Loss: 0.9723\n"," [========================================] ...Epoch 41, Loss: 1.0524\n"," [========================================] ...Epoch 42, Loss: 0.8687\n"," [========================================] ...Epoch 43, Loss: 0.7534\n"," [========================================] ...Epoch 44, Loss: 0.8505\n"," [========================================] ...Epoch 45, Loss: 0.8799\n"," [========================================] ...Epoch 46, Loss: 0.8864\n"," [========================================] ...Epoch 47, Loss: 0.7691\n"," [========================================] ...Epoch 48, Loss: 0.7944\n"," [========================================] ...Epoch 49, Loss: 0.7032\n"," [========================================] ...Epoch 50, Loss: 0.8657\n","----------------- Results for  Semeval2017A  dataset -----------------\n","The trainning loss is:  0.8392664280134378\n","The testing loss is:  0.9403550177812576\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor train set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.24      0.53      0.33      3463\n","           1       0.70      0.59      0.64     26325\n","           2       0.63      0.62      0.63     19782\n","\n","    accuracy                           0.60     49570\n","   macro avg       0.52      0.58      0.53     49570\n","weighted avg       0.64      0.60      0.61     49570\n"," \n","\n","\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor test set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.36      0.64      0.46      2197\n","           1       0.69      0.59      0.64      6997\n","           2       0.57      0.44      0.50      3090\n","\n","    accuracy                           0.56     12284\n","   macro avg       0.54      0.56      0.53     12284\n","weighted avg       0.60      0.56      0.57     12284\n"," \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEjCAYAAAAomJYLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"px8Olwf56vDi","colab_type":"text"},"source":["<br>\n","<font size=\"4\"><b>  Ερώτημα 1.2 </b></font>\n","<br>\n","\n","__Τι διαφορά(ές) έχει αυτή η αναπαράσταση με την αρχική; Τι παραπάνω πληροφορία θα μπορούσε να εξάγει; Απαντήστε συνοπτικά.__\n","\n","Στο __mean pooling__ η αναπαράσταση μιας πρότασης προκύπτει ως ο __μέσος όρος των word embeddings__. Κάθε διάσταση των embeddings εκφράζει κάποια έννοια. Συνεπώς, η σημασία μιας πρότασης εξαρτάται από το βαθμό συχέτισης κάθε μίας από αυτές τις έννοιες με τις λέξεις που την απαρτίζουν. Ουσιαστικά λαμβάνοντας το μέσο όρο θεωρούμε ότι μια πρόταση εκφράζει μια έννοια αν και μόνο αν οι περισσότερες λέξεις της εκφράζουν την έννοια αυτή. Ωστόσο, το πρόβλημα είναι ότι δεν έχουν όλες οι λέξεις την ίδια \"βαρύτητα\" όσον αφορά την σημασία μιας πρότασης. Με άλλα λόγια υπάρχουν λέξεις με πολύ σημαντική σημασία σε κάποια διάσταση οι οποίες παίζουν καθοριστικό ρόλο στην σημασία της πρότασης, χωρίς οι υπόλοιπες λέξεις να είναι κόντα στην έννοια αυτή. Μια θετική ή μια αρνητική λέξη μπορεί να επηρεάζουν σημαντικά το νόημα μιας πρότασης . Για το λόγο αυτό μια καλή πρακτική είναι η προσθήκη (concatenation) του __max polling__ στα representations. Με αυτόν τον τρόπο δύνουμε βαρύτητα και στη σημαντικότητα της λέξης μέσα στην πρόταση."]},{"cell_type":"markdown","metadata":{"id":"F5rWgMSy6vDl","colab_type":"text"},"source":["<font size=\"4\"><b>  Ερώτημα 2.1 </b></font>\n","\n","Στο ερώτημα αυτό χρησιμοποιούμε ένα LSTM για να κωδικοποιήσουμε την πρόταση. Συγκεκριμένα χρησιμοποιούμε την τελευταία έξοδο του LSTM $h_n$ ως αναπαράσταση του κειμένου u. Στον κώδικα που παραθέτουμε στην συνέχεια (models_2_1.py) αρχικά ορίζουμε ένα LSTM με hidden size = 50 και ένα hidden layer. Σε αντίθεση με τα προηγούμενα μοντέλα που έχουμε κατασκευάσει σε αυτή την περίπτωση αφαιρούμε τον μη γραμμικό μετασχηματισμό. Όσον αφορά την συνάρτηση forward εισάγουμε τα embeddings και το lstm δίκτυο που κατασκευάσαμε και στην συνέχεια δημιουργούμε τον πίνακα real_last_timestep. Ο πίνακας αυτός χρησιμοποιείται για να μπορέσουμε να πάρουμε τις πραγματικές τιμές, όπως κάναμε και στην προπαρασκευή. Ο κώδικας λοιπόν που υλοποιήσαμε είναι ο εξής:\n","```python\n","import torch\n","\n","from torch import nn\n","import numpy as np\n","\n","\n","class BaselineLSTM(nn.Module):\n","    \"\"\"\n","    1. We embed the words in the input texts using an embedding layer\n","    2. We compute the min, mean, max of the word embeddings in each sample\n","       and use it as the feature representation of the sequence.\n","    4. We project with a linear layer the representation\n","       to the number of classes.ngth)\n","    \"\"\"\n","\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        \"\"\"\n","\n","        Args:\n","            output_size(int): the number of classes\n","            embeddings(bool):  the 2D matrix with the pretrained embeddings\n","            trainable_emb(bool): train (finetune) or freeze the weights\n","                the embedding layer\n","        \"\"\"\n","\n","        super(BaselineLSTM, self).__init__()\n","        num_emb, dim_emb = embeddings.shape\n","        \n","        # 1 - define the embedding layer\n","        self.embedding = nn.Embedding(num_embeddings = num_emb, embedding_dim = dim_emb) # EX4\n","\n","        # 2 - initialize the weights of our Embedding layer\n","        # from the pretrained word embeddings\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings)) # EX4\n","\n","        # 3 - define if the embedding layer will be frozen or finetuned\n","        if not trainable_emb:\n","            self.embedding.weight.requires_grad = False # EX4\n","\n","        # 4 - define a lstm transformation of the representations\n","        #hidden size = 50\n","        #num of hidden layers = 1\n","        self.lstm = nn.LSTM(dim_emb, 50, 1, batch_first = True) # Lab3.2.1\n","\n","        # 5 - define the final Linear layer which maps\n","        # the representations to the classes\n","        self.linear = nn.Linear(50, output_size) # EX5\n","\n","    def forward(self, x, lengths, bows):\n","        \"\"\"\n","        This is the heart of the model.\n","        This function, defines how the data passes through the network.\n","\n","        Returns: the logits for each class\n","\n","        \"\"\"\n","\n","        # 1 - embed the words, using the embedding layer\n","        embeddings = self.embedding(x)  # EX6\n","        \n","        # 2 - call baseline lstm network\n","        base_lstm, _ = self.lstm(embeddings) # Lab3.2.1\n","        \n","        # 3 - find the real last timestep \n","        real_last_timestep = [min(int(lengths[i]), base_lstm.shape[1])-1 for i in range(len(x))] # Lab3.2.1\n","\n","        # 4 - construct a sentence representation out of the word embeddings\n","        representations = torch.zeros([len(x), embeddings.shape[2]])  # EX6     \n","        for i in range(len(x)):\n","            representations[i] = base_lstm[i, real_last_timestep[i]]\n","\n","        # 5 - project the representations to classes using a linear layer\n","        logits = self.linear(representations.cuda()) # EX6\n","\n","        return logits\n","```\n","Εκπαιδεύοντας λοιπόν το μοντέλο μας παίρνουμε τα εξής αποτελέσματα:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"i3n7sNWl6vDn","colab_type":"code","outputId":"0c122176-f54c-4280-b27a-f847adae980f","executionInfo":{"status":"ok","timestamp":1580126370781,"user_tz":-120,"elapsed":697526,"user":{"displayName":"Sila Vassiliou","photoUrl":"","userId":"12235529962578225857"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%run -i 'main.py' BaselineLSTM No"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading word embeddings...\n","Loaded word embeddings from cache.\n","BaselineLSTM(\n","  (embedding): Embedding(400002, 50)\n","  (lstm): LSTM(50, 50, batch_first=True)\n","  (linear): Linear(in_features=50, out_features=3, bias=True)\n",")\n"," [========================================] ...Epoch 1, Loss: 0.9610\n"," [========================================] ...Epoch 2, Loss: 0.8084\n"," [========================================] ...Epoch 3, Loss: 0.8759\n"," [========================================] ...Epoch 4, Loss: 0.8068\n"," [========================================] ...Epoch 5, Loss: 1.1332\n"," [========================================] ...Epoch 6, Loss: 0.9776\n"," [========================================] ...Epoch 7, Loss: 0.6707\n"," [========================================] ...Epoch 8, Loss: 0.8656\n"," [========================================] ...Epoch 9, Loss: 0.9304\n"," [========================================] ...Epoch 10, Loss: 0.8475\n"," [========================================] ...Epoch 11, Loss: 0.6174\n"," [========================================] ...Epoch 12, Loss: 1.1067\n"," [========================================] ...Epoch 13, Loss: 0.6837\n"," [========================================] ...Epoch 14, Loss: 0.7648\n"," [========================================] ...Epoch 15, Loss: 0.7763\n"," [========================================] ...Epoch 16, Loss: 0.8197\n"," [========================================] ...Epoch 17, Loss: 0.6749\n"," [========================================] ...Epoch 18, Loss: 0.8135\n"," [========================================] ...Epoch 19, Loss: 0.8035\n"," [========================================] ...Epoch 20, Loss: 1.0140\n"," [========================================] ...Epoch 21, Loss: 0.8514\n"," [========================================] ...Epoch 22, Loss: 0.7966\n"," [========================================] ...Epoch 23, Loss: 0.8339\n"," [========================================] ...Epoch 24, Loss: 0.7099\n"," [========================================] ...Epoch 25, Loss: 0.8617\n"," [========================================] ...Epoch 26, Loss: 0.8731\n"," [========================================] ...Epoch 27, Loss: 0.8639\n"," [========================================] ...Epoch 28, Loss: 0.7451\n"," [========================================] ...Epoch 29, Loss: 0.7924\n"," [========================================] ...Epoch 30, Loss: 0.7596\n"," [========================================] ...Epoch 31, Loss: 0.7397\n"," [========================================] ...Epoch 32, Loss: 0.6788\n"," [========================================] ...Epoch 33, Loss: 0.8236\n"," [========================================] ...Epoch 34, Loss: 0.9491\n"," [========================================] ...Epoch 35, Loss: 0.8094\n"," [========================================] ...Epoch 36, Loss: 0.5714\n"," [========================================] ...Epoch 37, Loss: 0.9512\n"," [========================================] ...Epoch 38, Loss: 0.8156\n"," [========================================] ...Epoch 39, Loss: 0.9981\n"," [========================================] ...Epoch 40, Loss: 0.7389\n"," [========================================] ...Epoch 41, Loss: 0.7957\n"," [========================================] ...Epoch 42, Loss: 0.7415\n"," [========================================] ...Epoch 43, Loss: 0.8505\n"," [========================================] ...Epoch 44, Loss: 1.0131\n"," [========================================] ...Epoch 45, Loss: 0.7578\n"," [========================================] ...Epoch 46, Loss: 0.6725\n"," [========================================] ...Epoch 47, Loss: 0.5525\n"," [========================================] ...Epoch 48, Loss: 0.6851\n"," [========================================] ...Epoch 49, Loss: 0.7337\n"," [========================================] ...Epoch 50, Loss: 0.6448\n","----------------- Results for  Semeval2017A  dataset -----------------\n","The trainning loss is:  0.7802290132979757\n","The testing loss is:  0.9088958545277516\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor train set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.32      0.61      0.42      4128\n","           1       0.74      0.61      0.67     27151\n","           2       0.64      0.69      0.67     18291\n","\n","    accuracy                           0.64     49570\n","   macro avg       0.57      0.64      0.59     49570\n","weighted avg       0.67      0.64      0.65     49570\n"," \n","\n","\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor test set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.40      0.69      0.51      2335\n","           1       0.72      0.60      0.66      7133\n","           2       0.58      0.49      0.53      2816\n","\n","    accuracy                           0.59     12284\n","   macro avg       0.57      0.59      0.57     12284\n","weighted avg       0.63      0.59      0.60     12284\n"," \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEjCAYAAAAomJYLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlQUIY4wxrixAGGOMcfX/AXs4uUI7PehZAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"vxeqal0O6vD2","colab_type":"text"},"source":["<br>\n","<font size=\"4\"><b>  Ερώτημα 2.2 </b></font>\n","\n","Το βήμα αυτό αποτελεί μια συνένωση των βημάτων 1.1 και 2.1 συνεπώς ο κώδικας μας αποτελείται από την ένωση των δύο προηγουμένων με μόνη αλλαγή τον τριπλασιασμό του input_size του linear layer. Επομένως το script models_2_2.py περιέχει τον εξής κώδικα:\n","```python\n","import torch\n","\n","from torch import nn\n","import numpy as np\n","\n","\n","class OptimizedLSTM(nn.Module):\n","    \"\"\"\n","    1. We embed the words in the input texts using an embedding layer\n","    2. We compute the min, mean, max of the word embeddings in each sample\n","       and use it as the feature representation of the sequence.\n","    4. We project with a linear layer the representation\n","       to the number of classes.ngth)\n","    \"\"\"\n","\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        \"\"\"\n","\n","        Args:\n","            output_size(int): the number of classes\n","            embeddings(bool):  the 2D matrix with the pretrained embeddings\n","            trainable_emb(bool): train (finetune) or freeze the weights\n","                the embedding layer\n","        \"\"\"\n","\n","        super(OptimizedLSTM, self).__init__()\n","        num_emb, dim_emb = embeddings.shape\n","        \n","        # 1 - define the embedding layer\n","        self.embedding = nn.Embedding(num_embeddings = num_emb, embedding_dim = dim_emb) # EX4\n","\n","        # 2 - initialize the weights of our Embedding layer\n","        # from the pretrained word embeddings\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings)) # EX4\n","\n","        # 3 - define if the embedding layer will be frozen or finetuned\n","        if not trainable_emb:\n","            self.embedding.weight.requires_grad = False # EX4\n","\n","        # 4 - define a lstm transformation of the representations\n","        #hidden size = 50\n","        #num of hidden layers = 1\n","        self.lstm = nn.LSTM(dim_emb, 50, 1, batch_first = True) # Lab3.2.1\n","\n","        # 5 - define the final Linear layer which maps\n","        # the representations to the classes\n","        self.linear = nn.Linear(3*50, output_size) # Lab3.2.2\n","\n","    def forward(self, x, lengths, bows):\n","        \"\"\"\n","        This is the heart of the model.\n","        This function, defines how the data passes through the network.\n","\n","        Returns: the logits for each class\n","\n","        \"\"\"\n","\n","        # 1 - embed the words, using the embedding layer\n","        embeddings = self.embedding(x)  # EX6\n","        \n","        # 2 - call baseline lstm network\n","        base_lstm, _ = self.lstm(embeddings) # Lab3.2.2\n","        \n","        # 3 - find the real last timestep \n","        real_last_timestep = [min(int(lengths[i]), base_lstm.shape[1])-1 for i in range(len(x))] # Lab3.2.2\n","\n","        # 4 - construct a sentence representation out of the word embeddings\n","        representations_lstm = torch.zeros([len(x), embeddings.shape[2]])  # EX6     \n","        for i in range(len(x)):\n","            representations_lstm[i] = base_lstm[i, real_last_timestep[i]]\n","        \n","        representation_mean = torch.zeros([len(x), embeddings.shape[2]])  # Lab3.2.2\n","        representation_max = torch.zeros([len(x), embeddings.shape[2]])  # Lab3.2.2\n","        for i in range(len(x)):\n","            representation_mean[i] = torch.sum(embeddings[i], dim=0) / lengths[i].float() # Lab3.2.2\n","            representation_max[i],_ = torch.max(embeddings[i], dim=0)\n","        representations = torch.cat((representations_lstm, representation_mean,representation_max), 1) # Lab3.2.2\n","        #import pdb; pdb.set_trace()\n","        # 5 - project the representations to classes using a linear layer\n","        logits = self.linear(representations.cuda()) # EX6\n","\n","        return logits\n"," ```\n"," Εκπαιδεύοντας λοιπόν το μοντέλο μας παίρνουμε τα εξής αποτελέσματα:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"CC_Sekcc6vD5","colab_type":"code","outputId":"dc0b1890-a03a-4952-9197-ad73ff42c66d","executionInfo":{"status":"ok","timestamp":1580129009468,"user_tz":-120,"elapsed":1297012,"user":{"displayName":"Sila Vassiliou","photoUrl":"","userId":"12235529962578225857"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%run -i 'main.py' OptimizedLSTM No"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading word embeddings...\n","Loaded word embeddings from cache.\n","OptimizedLSTM(\n","  (embedding): Embedding(400002, 50)\n","  (lstm): LSTM(50, 50, batch_first=True)\n","  (linear): Linear(in_features=150, out_features=3, bias=True)\n",")\n"," [========================================] ...Epoch 1, Loss: 0.9958\n"," [========================================] ...Epoch 2, Loss: 0.7948\n"," [========================================] ...Epoch 3, Loss: 0.9041\n"," [========================================] ...Epoch 4, Loss: 1.0560\n"," [========================================] ...Epoch 5, Loss: 0.8379\n"," [========================================] ...Epoch 6, Loss: 0.8967\n"," [========================================] ...Epoch 7, Loss: 0.8258\n"," [========================================] ...Epoch 8, Loss: 0.9025\n"," [========================================] ...Epoch 9, Loss: 0.9606\n"," [========================================] ...Epoch 10, Loss: 0.7797\n"," [========================================] ...Epoch 11, Loss: 0.6870\n"," [========================================] ...Epoch 12, Loss: 1.0811\n"," [========================================] ...Epoch 13, Loss: 0.7572\n"," [========================================] ...Epoch 14, Loss: 0.8004\n"," [========================================] ...Epoch 15, Loss: 0.7443\n"," [========================================] ...Epoch 16, Loss: 0.7510\n"," [========================================] ...Epoch 17, Loss: 0.7908\n"," [========================================] ...Epoch 18, Loss: 0.9081\n"," [========================================] ...Epoch 19, Loss: 0.7853\n"," [========================================] ...Epoch 20, Loss: 0.9223\n"," [========================================] ...Epoch 21, Loss: 0.6283\n"," [========================================] ...Epoch 22, Loss: 0.7587\n"," [========================================] ...Epoch 23, Loss: 0.8421\n"," [========================================] ...Epoch 24, Loss: 0.8396\n"," [========================================] ...Epoch 25, Loss: 0.7812\n"," [========================================] ...Epoch 26, Loss: 0.9434\n"," [========================================] ...Epoch 27, Loss: 0.7653\n"," [========================================] ...Epoch 28, Loss: 0.6867\n"," [========================================] ...Epoch 29, Loss: 0.8184\n"," [========================================] ...Epoch 30, Loss: 0.9715\n"," [========================================] ...Epoch 31, Loss: 0.9468\n"," [========================================] ...Epoch 32, Loss: 0.8969\n"," [========================================] ...Epoch 33, Loss: 0.8741\n"," [========================================] ...Epoch 34, Loss: 0.8778\n"," [========================================] ...Epoch 35, Loss: 0.7431\n"," [========================================] ...Epoch 36, Loss: 0.8465\n"," [========================================] ...Epoch 37, Loss: 0.7850\n"," [========================================] ...Epoch 38, Loss: 0.8835\n"," [========================================] ...Epoch 39, Loss: 0.9730\n"," [========================================] ...Epoch 40, Loss: 0.7511\n"," [========================================] ...Epoch 41, Loss: 0.8890\n"," [========================================] ...Epoch 42, Loss: 0.7574\n"," [========================================] ...Epoch 43, Loss: 0.7342\n"," [========================================] ...Epoch 44, Loss: 0.8023\n"," [========================================] ...Epoch 45, Loss: 0.8475\n"," [========================================] ...Epoch 46, Loss: 0.7697\n"," [========================================] ...Epoch 47, Loss: 0.9185\n"," [========================================] ...Epoch 48, Loss: 0.6569\n"," [========================================] ...Epoch 49, Loss: 0.6105\n"," [========================================] ...Epoch 50, Loss: 0.7591\n","----------------- Results for  Semeval2017A  dataset -----------------\n","The trainning loss is:  0.7797398475027576\n","The testing loss is:  0.9014787413179874\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor train set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.57      0.46      5158\n","           1       0.71      0.62      0.67     25512\n","           2       0.66      0.68      0.67     18900\n","\n","    accuracy                           0.64     49570\n","   macro avg       0.58      0.63      0.60     49570\n","weighted avg       0.66      0.64      0.65     49570\n"," \n","\n","\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor test set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.66      0.53      2626\n","           1       0.68      0.61      0.64      6667\n","           2       0.60      0.48      0.53      2991\n","\n","    accuracy                           0.59     12284\n","   macro avg       0.57      0.58      0.57     12284\n","weighted avg       0.61      0.59      0.59     12284\n"," \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEjCAYAAAAomJYLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxhhjHP0/ym+FisPYluYAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"05grIOQF6vEC","colab_type":"text"},"source":["<br>\n","<font size=\"4\"><b>  Ερώτημα 3.1 </b></font>\n","<br>\n","\n","Στο βήμα αυτό χρησιμοποιούμε την έτοιμη υλοποίηση του μηχανισμού __attention__ για να υπολογίσουμε την αναπαράσταση ενός κειμένου, ως το σταθμισμένο άθροισμα των word embeddings.\n","\n","$$u_i=tanh(We_i+b)$$\n","\n","$$a_i=\\frac{exp(u_i)}{\\sum_{t=1}^{N}exp(u_t)}$$\n","\n","$$\\sum_{i=1}^{N}a_i \\boldsymbol{e_i}$$\n","\n","Για την υλοποίηση του παρόντος ερωτήματος χρησιμοποιήσαμε το αρχείο SelfAttention.py που μας δώθηκε. Πλέον παίρνουμε τα representations καλώντας την SelfAttentions με ορίσματα τα embeddings και το length. Επομένως το script models_3_1.py περιέχει τον εξής κώδικα:\n","``` python\n","import torch\n","from SelfAttention import SelfAttention # Lab3.3.1\n","from torch import nn\n","\n","\n","class AttentionDNN(nn.Module):\n","\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        super(AttentionDNN, self).__init__()\n","        num_emb, dim_emb = embeddings.shape\n","        \n","        # 1 - define the embedding layer\n","        self.embedding = nn.Embedding(num_embeddings = num_emb, embedding_dim = dim_emb) # EX4\n","\n","        # 2 - initialize the weights of our Embedding layer\n","        # from the pretrained word embeddings\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings)) # EX4\n","        # 3 - define if the embedding layer will be frozen or finetuned\n","        if not trainable_emb:\n","            self.embedding.weight.requires_grad = False # EX4\n","\n","        # 4 - define the final Linear layer which maps\n","        # the representations to the classes\n","        self.linear = nn.Linear(50, output_size) # EX5\n","        self.attention = SelfAttention(50, batch_first = True, non_linearity = \"tanh\") # Lab3.3.1\n","\n","    def forward(self, x, lengths, bows):\n","\n","        # 1 - embed the words, using the embedding layer\n","        embeddings = self.embedding(x)  # EX6\n","\n","        # 2 - call attention to get the representations.\n","        representations = self.attention(embeddings, lengths) # Lab3.3.1\n","        '''representations, scores = self.attention(embeddings, lengths) # Lab3.5'''\n","        \n","        # 3 - project the representations to classes using a linear layer\n","        logits = self.linear(representations) # EX6\n","\n","        return logits\n","        '''return logits, scores  # Lab3.5'''\n","```\n","Εκπαιδεύοντας λοιπόν το μοντέλο μας παίρνουμε τα εξής αποτελέσματα:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"THNeVG-a6vEY","colab_type":"code","outputId":"1371872a-9d38-4903-d5e1-cadb4b6fb194","executionInfo":{"status":"ok","timestamp":1580127548604,"user_tz":-120,"elapsed":782765,"user":{"displayName":"Sila Vassiliou","photoUrl":"","userId":"12235529962578225857"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%run -i 'main.py' AttentionDNN No"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading word embeddings...\n","Loaded word embeddings from cache.\n","AttentionDNN(\n","  (embedding): Embedding(400002, 50)\n","  (linear): Linear(in_features=50, out_features=3, bias=True)\n","  (attention): SelfAttention(\n","    (softmax): Softmax(dim=-1)\n","    (non_linearity): Tanh()\n","  )\n",")\n"," [========================================] ...Epoch 1, Loss: 1.1050\n"," [========================================] ...Epoch 2, Loss: 1.0193\n"," [========================================] ...Epoch 3, Loss: 1.0399\n"," [========================================] ...Epoch 4, Loss: 1.0683\n"," [========================================] ...Epoch 5, Loss: 0.9792\n"," [========================================] ...Epoch 6, Loss: 1.0063\n"," [========================================] ...Epoch 7, Loss: 0.9139\n"," [========================================] ...Epoch 8, Loss: 0.9792\n"," [========================================] ...Epoch 9, Loss: 0.8957\n"," [========================================] ...Epoch 10, Loss: 0.9427\n"," [========================================] ...Epoch 11, Loss: 0.9459\n"," [========================================] ...Epoch 12, Loss: 0.9249\n"," [========================================] ...Epoch 13, Loss: 0.9404\n"," [========================================] ...Epoch 14, Loss: 1.0349\n"," [========================================] ...Epoch 15, Loss: 0.8492\n"," [========================================] ...Epoch 16, Loss: 0.9084\n"," [========================================] ...Epoch 17, Loss: 0.8342\n"," [========================================] ...Epoch 18, Loss: 0.9671\n"," [========================================] ...Epoch 19, Loss: 0.9975\n"," [========================================] ...Epoch 20, Loss: 0.9257\n"," [========================================] ...Epoch 21, Loss: 0.9508\n"," [========================================] ...Epoch 22, Loss: 1.0211\n"," [========================================] ...Epoch 23, Loss: 0.9227\n"," [========================================] ...Epoch 24, Loss: 0.8327\n"," [========================================] ...Epoch 25, Loss: 0.8681\n"," [========================================] ...Epoch 26, Loss: 0.8476\n"," [========================================] ...Epoch 27, Loss: 0.8599\n"," [========================================] ...Epoch 28, Loss: 1.1086\n"," [========================================] ...Epoch 29, Loss: 0.9313\n"," [========================================] ...Epoch 30, Loss: 0.8997\n"," [========================================] ...Epoch 31, Loss: 0.9688\n"," [========================================] ...Epoch 32, Loss: 0.7994\n"," [========================================] ...Epoch 33, Loss: 0.7673\n"," [========================================] ...Epoch 34, Loss: 0.8744\n"," [========================================] ...Epoch 35, Loss: 0.8368\n"," [========================================] ...Epoch 36, Loss: 1.0101\n"," [========================================] ...Epoch 37, Loss: 0.8728\n"," [========================================] ...Epoch 38, Loss: 0.9955\n"," [========================================] ...Epoch 39, Loss: 0.7695\n"," [========================================] ...Epoch 40, Loss: 0.8344\n"," [========================================] ...Epoch 41, Loss: 0.9340\n"," [========================================] ...Epoch 42, Loss: 0.9407\n"," [========================================] ...Epoch 43, Loss: 0.8399\n"," [========================================] ...Epoch 44, Loss: 0.8410\n"," [========================================] ...Epoch 45, Loss: 0.8999\n"," [========================================] ...Epoch 46, Loss: 0.8749\n"," [========================================] ...Epoch 47, Loss: 0.7631\n"," [========================================] ...Epoch 48, Loss: 0.8666\n"," [========================================] ...Epoch 49, Loss: 0.7879\n"," [========================================] ...Epoch 50, Loss: 0.7328\n","----------------- Results for  Semeval2017A  dataset -----------------\n","The trainning loss is:  0.8712182052663922\n","The testing loss is:  0.9278068610777458\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor train set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.20      0.54      0.29      2896\n","           1       0.72      0.57      0.64     28153\n","           2       0.59      0.62      0.60     18521\n","\n","    accuracy                           0.59     49570\n","   macro avg       0.50      0.58      0.51     49570\n","weighted avg       0.64      0.59      0.60     49570\n"," \n","\n","\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor test set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.37      0.64      0.47      2285\n","           1       0.71      0.59      0.65      7192\n","           2       0.55      0.47      0.50      2807\n","\n","    accuracy                           0.57     12284\n","   macro avg       0.54      0.57      0.54     12284\n","weighted avg       0.61      0.57      0.58     12284\n"," \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEjCAYAAAAomJYLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXzU1b3/8dcnC0sQggKKFZJYXCqK\nRkQsxSouV3GvVW+vRsU1bj9b2+rVlvaitLH22t6LW6tREdS43bqhdal6XdtaRQVxvaCyRLEgSgBZ\nQz6/P+abMEm+3ySTzGQmM+/n4zGPzJzvd+Z7vhjzmXPO55xj7o6IiEhLeemugIiIZCYFCBERCaUA\nISIioRQgREQklAKEiIiEUoAQEZFQChAiHWBmT5rZpHTXQ6Q7KUBIRjOzhWZ2aLrr4e5HuPvMVHy2\nmQ0ws2lmttjM1pjZR8Hrwam4nkhHKUBIzjOzgjReuxfwHLA7MBEYAIwDVgBjO/F5absXyT4KENJj\nmdnRZjbHzFaa2d/MbM+4Y1cE38RXm9l7ZnZ83LEzzOyvZvbfZrYCuDIoe8XMfmdmX5nZJ2Z2RNx7\nXjCzc+Le39a5O5rZS8G1nzWzm8zs7ojbOB0oAY539/fcvcHdl7n7r9z9ieDz3Mx2ivv8GWb26+D5\nBDOrNbPLzexz4A4ze9/Mjo47v8DMlpvZ6OD1t4N/r5VmNtfMJnTlv4NkLwUI6ZHMbG9gOnAeMAi4\nBZhlZr2DUz4CvgsUA1cBd5vZ9nEfsR/wMbAdUBVX9iEwGPhP4HYzs4gqtHXuPcBrQb2uBE5r41YO\nBZ5y9zXt33WkocA2QClQCdwLnBx3/HDgC3d/08x2AP4M/Dp4z6XAg2Y2pAvXlyylACE9VSVwi7v/\nw903B+MDG4BvA7j7/7j7Z8E38vuB+TTvsvnM3W9w93p3XxeULXL3W919MzAT2J5YAAkTeq6ZlQD7\nAv/h7hvd/RVgVhv3MQhY2ql/gS0agCnuviG4l3uAY82sKDh+CrGgAXAq8IS7PxH82zwDzAaO7GId\nJAspQEhPVQr8NOgmWWlmK4HhwDcAzOz0uO6nlcAexL7tN1oS8pmfNz5x97XB060irh917jeAL+PK\noq7VaAWx4NIVy919fVx9FgDvA8cEQeJYYkEDYv9uJ7X4d9s/CXWQLKQBLemplgBV7l7V8oCZlQK3\nAocAf3f3zWY2B4jvLkrVMsZLgW3MrCguSAxv4/xngV+bWT93/zrinLVAUdzroUBt3Ouwe2nsZsoD\n3guCBsT+3e5y93PbuQ8RtSCkRyg0sz5xjwJiAeB8M9vPYvqZ2VFm1h/oR+yP5nIAMzuTWAsi5dx9\nEbEumyvNrJeZjQOOaeMtdxH7o/2gmX3LzPLMbJCZ/dzMGrt95gCnmFm+mU0EDuxAVe4DDgMuYEvr\nAeBuYi2Lw4PP6xMMdA9L8FYlByhASE/wBLAu7nGlu88GzgVuBL4CFgBnALj7e8Dvgb8D/wRGAX/t\nxvpWsCVV9dfA/cTGR1px9w3EBqo/AJ4BVhEb4B4M/CM47UfEgszK4LMfaa8C7r6U2P1/J7h+Y/kS\n4Djg58QC6BLgMvS3QEKYNgwSSS0zux/4wN2npLsuIonQtwaRJDOzfc1sRNBdNJHYN/Z2v/WLZBoN\nUosk31DgIWIprLXABe7+VnqrJJI4dTGJiEgodTGJiEgoBQgREQmlACEiIqEUIEREJJQChIiIhFKA\nEBGRUAoQIiISSgFCRERCKUCIiEgoBQgREQmlACEiIqEUIEREJJQChIiIhFKAEBGRUFm1H8TgwYO9\nrKws3dUQEekx3njjjS/cfUjYsawKEGVlZcyePTvd1RAR6THMbFHUMXUxiYhIKAUIEREJpQAhIiKh\nsmoMQkQyw6ZNm6itrWX9+vXprooE+vTpw7BhwygsLOzwexQgRCTpamtr6d+/P2VlZZhZuquT89yd\nFStWUFtby4477tjh9+V8F1PNvBrKppWRd1UeZdPKqJlXk+4qifR469evZ9CgQQoOGcLMGDRoUMIt\nupxuQdTMq6HysUrWbloLwKK6RVQ+VglAxaiKdFZNpMdTcMgsnfnvkdMtiMnPTW4KDo3WblrL5Ocm\np6lGIiKZI6cDxOK6xQmVi0jPsGLFCsrLyykvL2fo0KHssMMOTa83btzYoc8488wz+fDDD9s856ab\nbqKmJvnd0s8++yzf+9732jznzTff5Kmnnkr6tePldBdTSXEJi+paTyIsKS5JQ21EclhNDUyeDIsX\nQ0kJVFVBRee7eQcNGsScOXMAuPLKK9lqq6249NJLm53j7rg7eXnh35PvuOOOdq9z0UUXdbqOXfXm\nm2/yzjvvMHHixJRdI6dbEFWHVFFUWNSsrE9BH6oOqUpTjURyUE0NVFbCokXgHvtZWRkrT7IFCxYw\ncuRIKioq2H333Vm6dCmVlZWMGTOG3XffnalTpzadu//++zNnzhzq6+sZOHAgV1xxBXvttRfjxo1j\n2bJlAPziF79g2rRpTedfccUVjB07ll133ZW//e1vAHz99deccMIJjBw5khNPPJExY8Y0Ba94f/7z\nn9l1110ZPXo0jz76aFP5q6++yrhx49h7770ZP3488+fPZ926dUydOpWamhrKy8v505/+FHpeV6Ws\nBWFm04GjgWXuvkfI8W8BdwCjgcnu/ru4YwuB1cBmoN7dx6Sijo0D0ZOfm8ziusWYGcMHDOfkPU5O\nxeVEctMll0DIH8Qmr74KGzY0L1u7Fs4+G269Nfw95eUQ/GFO1AcffMCdd97JmDGxPyvXXHMN22yz\nDfX19Rx00EGceOKJjBw5stl76urqOPDAA7nmmmv4yU9+wvTp07niiitafba789prrzFr1iymTp3K\nU089xQ033MDQoUN58MEHmTt3LqNHj271vrVr13Leeefx4osv8s1vfpMTTzyx6dhuu+3Gyy+/TEFB\nAU899RS/+MUvuP/++/mP//gP3nnnnaYAVVdXF3peV6Syi2kGcCNwZ8TxL4EfAlEdbQe5+xcpqFcz\nFaMqmgLFzDkzOePRM7hl9i1csO8Fqb60iEDr4NBeeReNGDGiKTgA3Hvvvdx+++3U19fz2Wef8d57\n77UKEH379uWII44AYJ999uHll18O/ezvf//7TecsXLgQgFdeeYXLL78cgL322ovdd9+91fvee+89\ndtllF0aMGAFARUUFd94Z+9O5cuVKTj/9dD766KM276uj5yUiZQHC3V8ys7I2ji8DlpnZUamqQ6JO\n3+t07p53N5c/eznH7HoMwwYMS3eVRHq+9r7pl5XFupVaKi2FF15IenX69evX9Hz+/Plcd911vPba\nawwcOJBTTz01dK5Ar169mp7n5+dTX18f+tm9e/du95xETZ48mcMPP5wLL7yQBQsWRI45dPS8RGTq\nGIQDfzGzN8yssq0TzazSzGab2ezly5d36aJmxi1H30J9Qz0X/vlC3L1LnyciHVBVBUXNxwIpKoqV\np9iqVavo378/AwYMYOnSpTz99NNJv8b48eN54IEHAJg3bx7vvfdeq3NGjhzJ/Pnz+eSTT3B37r33\n3qZjdXV17LDDDgDMmDGjqbx///6sXr263fO6IlMDxP7uPho4ArjIzA6IOtHdq919jLuPGTIkdM+L\nhHxz62/yq4N+xWP/9xjb/m5bzbAWSbWKCqiujrUYzGI/q6u7lMXUUaNHj2bkyJF861vf4vTTT2f8\n+PFJv8bFF1/Mp59+ysiRI7nqqqsYOXIkxcXFzc4pKiri5ptv5ogjjmDMmDFsv/32Tccuv/xyLrvs\nMkaPHt3sS+vBBx/M3Llz2XvvvfnTn/4UeV5XWCq/JQddTI+HDVLHnXMlsCZ+kDqR4/HGjBnjydgw\n6K65dzHpkUk4W/5tigqLqD6mWjOsRTrg/fffZ7fddkt3NTJCfX099fX19OnTh/nz53PYYYcxf/58\nCgq6f5ZB2H8XM3sjKhEo4+ZBmFk/IM/dVwfPDwOmtvO2pPrl879sFhxgywxrBQgRScSaNWs45JBD\nqK+vx9255ZZb0hIcOiOVaa73AhOAwWZWC0wBCgHc/WYzGwrMBgYADWZ2CTASGAw8HKwbUgDc4+6p\nnS7YgmZYi0iyDBw4kDfeeCPd1eiUVGYxtTmZwN0/B8LShFYBe6WkUh2kGdYiIpk7SJ1WYTOsC/MK\nNcNaRHKKAkSIilEVVB9TTWlxKYbRr7Afmxs2s/fQvdNdNRGRbqMAEaFiVAULL1lIw5QGPvnRJwzs\nO5DKxypp8IZ0V01EpFsoQHTAkH5D+P1hv+evS/7KrW9ErA0jIhkjGct9A0yfPp3PP/+86XVHlgDv\njPhF/6I89NBDfPDBB0m/dlsUIDpo0l6TOKjsIC5/9nKWrl6a7uqIZJVkb/3buNz3nDlzOP/88/nx\nj3/c9Dp+2Yz2tAwQd9xxB7vuumuX6tZZChAZrHEZjjUb17DT9TtphrVIkjRu/buobhGON239m6r/\nt2bOnMnYsWMpLy/nwgsvpKGhgfr6ek477TRGjRrFHnvswfXXX8/999/PnDlz+MEPftDU8ujIEuDz\n589nv/32Y9SoUUyePJmBAweG1mPq1Knssssu7L///s2W5r755pvZd9992WuvvTjppJNYt24dL7/8\nMk888QQ//vGPKS8vZ+HChaHnJVvPmK2RIV777DXyLI+19drDWqSjLnnqEuZ8Hr3c96u1r7Jhc/OV\nW9duWsvZj54d2aVbPrScaRMTX+77nXfe4eGHH+Zvf/sbBQUFVFZWct999zFixAi++OIL5s2bB8RW\nRh04cCA33HADN954I+Xl5a0+K2oJ8IsvvphLL72Uk046iRtvvDG0Hq+99lrT8t8bN26kvLyccePG\nAXDSSSdx/vnnA3DFFVcwY8YMLrjgAo488khOPPHEpp3mos5LJrUgEjD5uclsatjUrEx7WIt0Tcvg\n0F55Vzz77LO8/vrrjBkzhvLycl588UU++ugjdtppJz788EN++MMf8vTTT7daKylMyyXAG5f3/sc/\n/sEJJ5wAwCmnnBL63pdeeokTTjiBvn37UlxczDHHHNN07O233+a73/0uo0aN4r777uPdd98N/YyO\nntcVakEkQDOsRRLX3jf9smlloRNTS4tLeeGMF5JaF3fnrLPO4le/+lWrY2+//TZPPvkkN910Ew8+\n+CDV1dVtflZHlwBP1Omnn86TTz7JHnvswW233carr77apfO6Qi2IBETNpNYMa5HOC5uYWlRYlJKJ\nqYceeigPPPAAX3wR24tsxYoVLF68mOXLl+PunHTSSUydOpU333wTaL2kdkeMHTuWhx9+GID77rsv\n9JwDDjiAhx9+mPXr17Nq1Soef/zxpmNff/01Q4cOZdOmTdxzzz1N5S3rEnVeMilAJEAzrEWSr+XE\n1NLi0pStnDxq1CimTJnCoYceyp577slhhx3GP//5T5YsWcIBBxxAeXk5Z555JldffTUQS2s955xz\nEkqPvf766/ntb3/LnnvuySeffBLaXTV27FiOP/549txzT4466ijGjh3bdGzq1Knsu+++jB8/vtnO\ndieffDJXX3110yB11HnJlNLlvrtbspb7bkvNvJqmPax75feib0Ffll66lD4FfVJ6XZGeJJeX+/76\n668pKirCzLj77rt5+OGHefDBB9NdLSDx5b7VgkhQ/AzrJyueZOWGlZo8JyJNXn/9dfbee2/23HNP\nbr31Vq699tp0V6nTNEjdBRPKJnBA6QH85pXfcO4+56oVISJMmDCBOXOi03p7ErUgusDMuGrCVSxd\ns5TqN9rOeBDJNdnUfZ0NOvPfQwGiiyaUTeDA0gO55pVrWLcp+TMZRXqiPn36sGLFCgWJDOHurFix\ngj59EuvlUBdTElw54UoOmnkQ1W9U86Nv/yjd1RFJu2HDhlFbW8vy5cvTXRUJ9OnTh2HDwvZoi6Ys\npiQZedNIPlzxIe5OSXEJVYdUafkNEcl4bWUxqQWRBDXzavj4q4+b9orQGk0ikg00BpEEk5+bHLrY\nmNZoEpGeTAEiCbRGk4hkIwWIJNAaTSKSjRQgkiBsjaZ8y9caTSLSoylAJEHLxcYG9h7IZt/MtkXb\nprtqIiKdpjTXFNhQv4Hd/7A7hfmFzD1/Lr3yO74HrohId0rLYn1mNt3MlpnZOxHHv2VmfzezDWZ2\naYtjE83sQzNbYGZXpKqOqdK7oDfTJk7jgy8+4MbXwrccFBHJdKnsYpoBTGzj+JfAD4HfxReaWT5w\nE3AEMBI42cxSs9h5Ch29y9EcufORXPnClXy+5vN0V0dEJGEpCxDu/hKxIBB1fJm7vw5sanFoLLDA\n3T92943AfcBxqapnKk07fBobNm/gimd7XCNIRCQjB6l3AJbEva4NynqcnQftzE++/RNmzp3J0N8N\nJe+qPMqmlVEzrybdVRMRaVcmBoiEmFmlmc02s9mZuDDYzoN2xjD++fU/cbxpGQ4FCRHJdJkYID4F\nhse9HhaUhXL3ancf4+5jhgwZkvLKJWrqi1NxmmeKaRkOEekJMjFAvA7sbGY7mlkv4N+AWWmuU6dp\nGQ4R6alStpqrmd0LTAAGm1ktMAUoBHD3m81sKDAbGAA0mNklwEh3X2Vm/w94GsgHprv7u6mqZ6qV\nFJewqG5RaLmISCZLWYBw95PbOf45se6jsGNPAE+kol7dreqQKiofq2TtprVNZYV5hVqGQ0QyXiZ2\nMWWVlstw9CvsR31DPTttvVO6qyYi0iYttdHN6tbXsefNe9I7vzdvnfcW/Xr1S3eVRCSHpWWpDQlX\n3KeYO793Jwu+XMBlz1yW7uqIiERSgEiDA8sO5KfjfsofZ/+R7a7dThPoRCQjaU/qNNlj2z0wjGVr\nlwHax1pEMo9aEGky5YUpmkAnIhlNASJNNIFORDKdAkSaaB9rEcl0ChBpEraPtWFMOXBKmmokItKc\nAkSatJxAt23RtjjO7M8yex6HiOQOZTGlUcWoimYZS5f+5VJ+//ffc9iIwzjuWz1yjyQRySJqQWSQ\nqw+5mtHbj6bioQqG/dcwzY8QkbRSgMggvfJ7ccoep/D1pq/5dPWn2mBIRNJKASLD3PDaDa3KND9C\nRNJBASLDaH6EiGQKBYgMo/kRIpIpFCAyTNj8CICLx16chtqISC5TgMgwLedHfKP/N9iqcCv+OPuP\nLP96ebqrJyI5RBsG9QB/X/J3Dr7zYHbovwMbN2+kdlUtJcUlVB1SpZVfRaRLtGFQDzdu+DjO2+c8\nPvrqI5asWqL0VxHpFgoQPcQjHzzSqkzpryKSSgoQPYTSX0WkuylA9BBKfxWR7qYA0UOEpb/mWz5V\nh1SlqUYiku0UIHqIlumvxb2L2eyb6ZPfJ91VE5EspTTXHmrT5k2Mu30ci+oW8e6F77Jtv23TXSUR\n6YHSkuZqZtPNbJmZvRNx3MzsejNbYGZvm9nouGObzWxO8JiVqjr2ZIX5hcz83kxWbVjFhX++kGwK\n9CKSGVLZxTQDmNjG8SOAnYNHJfDHuGPr3L08eBybuir2bLtvuztTJ0zlwfcf5P537093dUQky6Qs\nQLj7S8CXbZxyHHCnx7wKDDSz7VNVn2z10+/8lBEDR1DxUIU2GBKRpErnIPUOwJK417VBGUAfM5tt\nZq+a2ffa+hAzqwzOnb18ee6tVXT/u/fz6ZpPafAGzbAWkaTK1Cym0mDQ5BRgmpmNiDrR3avdfYy7\njxkyZEj31TBDTH5uMuvr1zcr0wxrEUmGdAaIT4Hhca+HBWW4e+PPj4EXgL27u3I9hWZYi0iqpDNA\nzAJOD7KZvg3UuftSM9vazHoDmNlgYDzwXhrrmdGiZlJvt9V23VwTEck2qUxzvRf4O7CrmdWa2dlm\ndr6ZnR+c8gTwMbAAuBW4MCjfDZhtZnOB54Fr3F0BIkLYDGvDWLtprVoRItIlmiiXBWrm1TD5ucks\nrltMSXEJF+57IVUvV1FaXMorZ73CgN4D0l1FEclQbU2UU4DIUs989AxH1BzB7kN2Z+WGlSypW6JN\nhkSkFW0YlIP+ZcS/cMZeZ/D2srdZXLdYKbAikjAFiCz27CfPtipTCqyIdJQCRBZTCqyIdIUCRBaL\nSoEdXjw8tFxEJJ4CRBYLS4EF2HmbnWnwhjTUSER6EgWILNZyk6GS4hKO3vlonvvkOQ6acRCl00q1\nwJ+IRFKaa45xd0584EQe+uChZuVFhUVUH1OtFFiRHKM0V2liZryx9I1W5cpuEpGWFCBykLKbRKQj\nOhQgzGxE3AJ6E8zsh2Y2MLVVk1RRdpOIdERHWxAPApvNbCegmtgy3fekrFaSUlHZTWO+EdoNKSI5\nqqMBosHd64HjgRvc/TIgO7YHramBsjLIy4v9rMn+bJ6w7KbvlnyXh95/iNMeOo2yaWXKbhIRCjp4\n3iYzOxmYBBwTlBWmpkrdqKYGKith7drY60WLYq8BKrI7m6diVEWzjKX6hnrG3T6Ou+fd3VTWuHZT\n4/kikls62oI4ExgHVLn7J2a2I3BX6qrVTSZP3hIcGq1dGyvPMQV5BSxbs6xVubKbRHJXh1oQwYY9\nPwQws62B/u7+21RWrFssjsjaiSrPcktWLQktV3aTSG7qaBbTC2Y2wMy2Ad4EbjWz/0pt1bpBSXg2\nT2R5lovKbooqF5Hs1tEupmJ3XwV8H7jT3fcDDk1dtbpJVRUUtcjmyc+PleegqOymY3c9Ng21EZF0\n62iAKDCz7YF/BR5PYX26V0UFVFdDaSmYQXExbN4MvXqlu2Zp0TK7afiA4eyyzS784fU/cP8796e7\neiLSzTq0FpOZnQT8Eviru19gZt8ErnX3E1JdwUR0eS2m+nr4znfg44/h3Xdhu+2SV7keas3GNRxZ\ncyQvL36ZwX0Hs2LdCm1dKpJFurwWk7v/j7vv6e4XBK8/zrTgkBQFBTBzJqxZE0t3zaKFDDtrq15b\ncUb5GeRZHl+s+0Jbl4rkkI4OUg8zs4fNbFnweNDMhqW6cmmx225w9dUwaxYMGZJTE+iiTH1xaqv9\nI5T+KpL9OjoGcQcwC/hG8HgsKMtOjYFhxYpYK6JxAl2OBgkt7ieSmzoaIIa4+x3uXh88ZgBDUliv\n9PrlL6GhxY5rOTqBDqLTXPsV9qO+ob6bayMi3aWjAWKFmZ1qZvnB41RgRSorllaaQNdMWPprYV4h\nazat4YQHTuCOt+7Q+k0iWaijAeIsYimunwNLgROBM9p7k5lND8Ys3ok4bmZ2vZktMLO3zWx03LFJ\nZjY/eEzqYD2TQxPommmZ/lpaXMod37uDG4+4kVkfzuKcx85hUd0iDWCLZJlObzlqZpe4+7R2zjkA\nWENsct0eIcePBC4GjgT2A65z9/2CGduzgTGAA28A+7j7V21dL2lbjrZcxK/R5Mnw6193/fOzyJBr\nh/DF2i9alZcWl7LwkoXdXyERSUiqthz9SXsnuPtLwJdtnHIcseDh7v4qMDCYkHc48Iy7fxkEhWeA\niV2oa2JaTqAbPhy23x5uvhk++aTbqtETrFgb3tOoAWyRnq8rAcKScP0dgPgV4mqDsqjy1pUwqzSz\n2WY2e/ny5UmoUqCiAhYujA1WL14ML74Ye37AAbGuJqW/AtED2MV9ipkxZ4bGJkR6sK4EiIyYRebu\n1e4+xt3HDBmSwsSqnXeG886D2lpYskTpr4GwAex8y2fl+pWc9ehZGpsQ6cHaDBBmttrMVoU8VhOb\nD9FVnxLbvrTRsKAsqjy97r23dVkOp79C+AD2zONnsm2/bfEW3yE0uU6kZ+n0IHWHL2BWBjweMUh9\nFPD/2DJIfb27jw0Gqd8AGrOa3iQ2SN3WeEbyBqmj5OWFL79h1nreRI7LuyqvVYAAMIyGKfq3EskU\nbQ1Sd3TL0c5e+F5gAjDYzGqBKQRblbr7zcATxILDAmAtsZ3rcPcvzexXwOvBR01tLzh0i5KSWLdS\nS8OHty7LcSXFJSyqa/1v9Y3+yWh4ikh36MoYRLvc/WR3397dC919mLvf7u43B8GBIHvpIncf4e6j\n3H123Hunu/tOwSMzlvUI2z8CYK+9tLBfC1F7S6zeuJqql6o0eC3SA6Q0QGSdlumvJSVwyCHw2GNw\n1FGxcmU3AeFjE9cccg0FeQX84vlfaPBapAdI+RhEd0r5GEQYdzjiCHj66eblRUWxYFKhPRPiDfuv\nYXy6unW+gSbWiaRHqibKCcRaEu+/37o8x7Obony2+rPQ8sV1i6mZV6OuJ5EMogCRDEuWhJfn6OJ+\nbYmaWOc4ZzxyhrqeRDKIAkQyRC3i9w1l7LQUNnjdp6APvfN7t1o6XPMmRNJLASIZorKb1q2DefO6\nvz4ZLGzw+rZjb2Pj5o2h52tNJ5H0UYBIhpbZTaWlsVVf+/SB8ePh8stjmU3KcAJiQWLhJQtpmNLA\nwksWUjGqIrLrqVd+L67967UamxBJA2UxpVJtLXznO63HKJTh1ErNvBoqH6tk7aYtS6z3yu+FNzib\nfFOzc4sKi6g+ppqKUfr3E+kqZTGly7Bh4eXKcGolrOtp+nHT2a7/dq3O1diESPdQCyLVtH5Tl0St\n6QSw5mdreOTDR5j83GQW1y2mpLiEqkOq1LIQSUDa1mISotdv2n777q9LDxS1phPAdr/bjo2bN7Kp\nIdYF1ZgaCyhIiCSBuphSLSrD6csv4d//XYPX7QhLiy0qLGLKgVNo8Iam4NBI3U8iyaMAkWphGU7X\nXQfbbgvXXhtrXWjzoUhhYxPVx1Rz5YQrWV+/PvQ9mpUtkhwag0iXkpLwGdilpbGtTqVdZdPKIruf\n8iyPBt8yxqPMJ5FwymLKRLW14eVanqPDwrqf+hb0paigqFlwgC1dT2pZiHScAkS6RC3PMXBgrJtJ\nYxPtCut+uvXYW1lXvy70/EV1izh31rla70mkg9TFlC41NbExh7VbJoaRlxdLfc3Ph82bt5RrYl1C\n2up6ClNaXErVIVVKl5WcpC6mTBQ2eD1zZqwFER8cQBPrEhSV+RRlUd0izn70bLUsRFpQgEiniorY\ngHRDQ+znqadCXV34uRqb6LCozKfS4tLI92zYvKHZa6XLimiiXObRxLqkqBhVEdpF1HK9p6LComav\n4y2qW8T0t6Yz9cWp6nqSnKQWRKaJmli3YgWce672ve6CzrQszp6lrifJXRqkzkQ1NbExh8WLYy2K\nn/wEbr659damGrxOirCVZDTwBYwAABEmSURBVIsKiyjMK6RuQ+suv8b9s2vm1WhgW3q8tgapFSB6\nitLS8HEITaxLirA/9qc9dFrkQoHn73M+d869k7X1zYOKJuNJT6MAkQ20Kmy3i0qXLcgraLU9aiOl\nzEpPozTXbBA1sQ7gjDM0NpECUemyM46bgWGh72krZVazuKWnSWkLwswmAtcB+cBt7n5Ni+OlwHRg\nCPAlcKq71wbHNgONGzovdvdj27teVrcgwibW9e0Lgwa1XrZDYxNJEzXOkOhkvP69+lPfUN9slndj\nlxSgFoekTVq6mMwsH/g/4F+AWuB14GR3fy/unP8BHnf3mWZ2MHCmu58WHFvj7lslcs2sDhDQevC6\nqgp+/nONTaRB1MB2VMpslAG9BrCpYVNo4KgYVaGBcEm5dHUxjQUWuPvH7r4RuA84rsU5I4H/DZ4/\nH3Jc4rWcWFdREb4iLMTmUqxbp3WdUqQzKbNhVm1c1WrtqLWb1vKzZ3/WFISUZivpksqJcjsA8X+9\naoH9WpwzF/g+sW6o44H+ZjbI3VcAfcxsNlAPXOPuj6Swrj1X1MQ6iO2JvWYNbNwYe9245wSo+ykJ\nEpmM17egLyvWrejwZy9ZtYQzHzmzzQ2RwloWanFIMqV7kPpS4EAzews4EPgUaFyIqDRo9pwCTDOz\nEWEfYGaVZjbbzGYvX768WyqdUcIm1hUVxbqe4oNDI63rlFJRLYvrjrgudMB7UN9BoZ9T3Lu4VXBo\ntKhuEWc9elarlsWFf75QLQ5JqlSOQYwDrnT3w4PXPwNw999EnL8V8IG7Dws5NoPYWMWf2rpm1o9B\nRAkbm6ioUGpshgn7dg/hLY7qY6qZ/NzkhAbCDQudt9E4sU8kTLrGIF4HdjazHc2sF/BvwKwWFRts\nZo11+BmxjCbMbGsz6914DjAeeA8JFzY2AdGpsf36xWZma2yiW1WMqmDhJQtpmNLAwksWNnVRhbU4\nKkZVJLwqbdSkvra2YFXqrbQl1WmuRwLTiKW5Tnf3KjObCsx291lmdiLwG8CBl4CL3H2DmX0HuAVo\nIBbEprn77e1dL2dbEFHCUmMLCqA+ZJKXUmMzUlirI6plkW/5bPbNIZ/S+lhRYRGT9prEzLkzQ1sv\nbY1naJwju2gmdS4L63667DJYurT1uUqN7RGiUmzD/uD3ye+D462WM2/L4KLB/PKAX/Kz537WoWto\nPkfPpgAhzUWNTQDMmAFTprQez5CMksi3+7bWlEpU1DjHoL6DWFe/LrI1IplLAUKaKyuLTo01ax48\n1PXU40XN+o7qkhq61VA+X/N5Uq7d1tpU6qrKDFqLSZqLSo0dMKB1y0JpsT1e1GB35T6VoeW/O+x3\nkRP+8i0/oWuHpeSeO+tcTn/4dM6ddW5kSm6ig+oabE8NBYhcFLYfdnU1rF4dfv6iRfDf/62spx4q\nKlPqD0f9IeEMqqigEjWfA2Dj5uZzcdbVr+Out+8KnUF+weMXcP7j53POrHM6PM9D8z9SR11MskVb\nXU8tqesp6yUyzgGJbefaGVHjH3mWR4O3ntfT2e6tXMve0hiEdExYWmxREfTuDV991fr8xmU+oibq\nSU5JRkpuSXEJS+qWJG1QvTCvsNmM9L4FfTll1CncM++eyJV1O5oh1pXsrUwKNgoQ0nFhf+xPOy06\n6+n88+HOO1sHFbUuhMRSctubQR4VVNqa/5GIwrxC8vPyWV+/vtWxzmRvQfR6WVGz56Pek0oKENI1\nUV1PhYWwKXy9IM2pkEaJdtkkGlSiypPZvZWogb0HsmHzhmatlN75vTmj/Azuf+d+Vm5Y2eo9WxVu\nxaaGTc3mrHQk2HQ1oChASNdEdT1VV0e3LszgrrvU9SSd0pmg0tXurcbMrURnqada34K+NHhDq8DR\n3kz4jlKAkK6LGmeIal2YxZb1iG9hqOtJulFnurcgsTGIRJdxN4xhA4axZFXEPi5JkOjijJoHIV0X\ntSBg2JyKXr0gP79191PjnAptYiTdoDPpvYm+J9Fl3EuKS/jNob9JOFU4EYvrQnaY7CS1IKTrEh3Y\n7t0bNsStDaSWhfRgiS7jnmiqcFQrpa2usmS1IBQgJDUSmVMBsUHtqiqNWUjW6MwAciKBQ2MQCVKA\nyCBRA9tr28gsUctCJFQqJ+8pQEh6hHU9TZ6sloVIBlGAkMzRmZZFr17N99ZWy0IkaZTFJJkjaqHA\n0vDVQ4HmwQFiweTnP489V0aUSMoUpLsCkoMqKsK//SfSsli8GA4/HF58ccu4xaJFsc9ovIaIdIla\nEJIZEm1Z9O0Lf/lL80Ft2NK6UMtCpMsUICRzhE3Gi9rc6NZbY4EkzOLFMGlSrEXhvqVlUVOjwCGS\nAAUIyWxRLYuKilhGUxgz2NxiAtHatXDBBbFAERY4RKQVBQjJfIks81FUFD2De/Xq1mMaWv5DJJIC\nhPRcncmICrNoEZxxhrqkRFrQPAjJPlFzLfr2hRUdX3mTAQOgvl6bIUlW0zwIyS1RLYvrrgvvkoqy\nalV0lxSodSFZTwFCslPYuEUyu6ROPRXOOUfdUpLVUtrFZGYTgeuAfOA2d7+mxfFSYDowBPgSONXd\na4Njk4BfBKf+2t1ntnc9dTFJpyTaJVVQEOt6CjNwYGzmd1i3FGhNKck4bXUx4e4peRALCh8B3wR6\nAXOBkS3O+R9gUvD8YOCu4Pk2wMfBz62D51u3d8199tnHRTrl7rvdS0vdzWI/77479igqco+1EWKP\noqJYuVnz8vYegwZFf5ZIGgGzPeJvaiq7mMYCC9z9Y3ffCNwHHNfinJHA/wbPn487fjjwjLt/6e5f\nAc8AE1NYV8l1iXRJtTUHI8qKFUqxlR4nlQFiByB+49XaoCzeXOD7wfPjgf5mNqiD7wXAzCrNbLaZ\nzV6+fHlSKi7SJNE5GIMS3DayrRRbUPCQtEr3IPWlwIFm9hZwIPAp0HoPvTa4e7W7j3H3MUOGDElF\nHUVaSzRTqq3A0XI8Y+1auOii2JpS556rgXBJm1Su5vopMDzu9bCgrIm7f0bQgjCzrYAT3H2lmX0K\nTGjx3hdSWFeRxEWtSgutB6MhsdVq6+rgN79pXd4YPDZuhHXrYmXxq9iGXVsD4dJZUYMTXX0QCz4f\nAzuyZZB69xbnDAbygudVwFTfMkj9CbEB6q2D59u0d00NUktGCxsILy0NH9QeNizxgfCBA6MHwsOu\nLeJtD1KnLEDErsuRwP8Ry2aaHJRNBY4Nnp8IzA/OuQ3oHffes4AFwePMjlxPAUJ6nLYypaKCR6IP\nBQ5pQ9oCRHc/FCCkR4r6Ix0VPAYNSk7g2GabtlNvFTxyQlsBQjvKiaRb1FhGY1lHxzMSXWvqyy9b\nl8Vv5xp/DY1z5CQt1ifSE9XUpC5wAOTnt95TA2CbbWD9es0UzyJtzaRWgBDJJskIHAMGxBYqTMTW\nW8e2f1Xg6HEUIERyXSKBo7o6du6iRV2/7oABsGnTlpTc+GuAAkcGSMtaTOl4aJBaJEHpGiDv18+9\nd+/EB8g1cJ50tDFIrRaEiIRL9ThHmP794YQT4N57Y11W8deYNAlmzlQ3VpKpi0lEkicdgQNiS5qE\n/b0aNCjWhaXA0SnaUU5EkieRlW8TXZuqpCT2/jBRX2ajVsq98MLObeqkda62iOp76okPjUGIZKBE\n99qImkGen5+c8Y++faPHP9qqV5aOi6CZ1CKScRIdIL/ggtQOnPfp0/rz45cr6du343VqbxmTDAoq\nChAi0rMk8m091RlXbT2iFlQsLg4PKBnYSmkrQGiQWkR6vmQMnJeWxn4mY/5HlH79YrPUwyYiRs1S\nT3H2lrKYRCQ3JTpBMOpYVFCJWpIkmaKyt9qavZ5AkFAWk4jkpkT3Gk80G6uyMrEsrdLSxPczj/oS\n/9VX0fucJ4laECIiHRHWGqmoyLxWilksIHb49OgWhJb7FhHpiLaWZe/o1rPx53U0qESNQUQFlERb\nKG1QgBARSYW2AkeiQWX8+I4HlMZjSaAuJhGRniqq2ysB6mISEclGbbVEkkBZTCIiEkoBQkREQilA\niIhIKAUIEREJpQAhIiKhsirN1cyWA51daWsw8EUSq9NT6L5zi+47t3TkvkvdfUjYgawKEF1hZrOj\ncoGzme47t+i+c0tX71tdTCIiEkoBQkREQilAbFGd7gqkie47t+i+c0uX7ltjECIiEkotCBERCZXz\nAcLMJprZh2a2wMyuSHd9UsnMppvZMjN7J65sGzN7xszmBz+3Tmcdk83MhpvZ82b2npm9a2Y/Csqz\n+r4BzKyPmb1mZnODe78qKN/RzP4R/M7fb2a90l3XZDOzfDN7y8weD15n/T0DmNlCM5tnZnPMbHZQ\n1unf9ZwOEGaWD9wEHAGMBE42s5HprVVKzQAmtii7AnjO3XcGngteZ5N64KfuPhL4NnBR8N842+8b\nYANwsLvvBZQDE83s28Bvgf92952Ar4Cz01jHVPkR8H7c61y450YHuXt5XHprp3/XczpAAGOBBe7+\nsbtvBO4DjktznVLG3V8CvmxRfBwwM3g+E/het1Yqxdx9qbu/GTxfTeyPxg5k+X0DeMya4GVh8HDg\nYOBPQXnW3buZDQOOAm4LXhtZfs/t6PTveq4HiB2AJXGva4OyXLKduy8Nnn8ObJfOyqSSmZUBewP/\nIEfuO+hqmQMsA54BPgJWunt9cEo2/s5PA/4daNyYeRDZf8+NHPiLmb1hZpVBWad/17VhkDRxdzez\nrExrM7OtgAeBS9x9VexLZUw237e7bwbKzWwg8DDwrTRXKaXM7Ghgmbu/YWYT0l2fNNjf3T81s22B\nZ8zsg/iDif6u53oL4lNgeNzrYUFZLvmnmW0PEPxclub6JJ2ZFRILDjXu/lBQnPX3Hc/dVwLPA+OA\ngWbW+OUw237nxwPHmtlCYl3GBwPXkd333MTdPw1+LiP2hWAsXfhdz/UA8Tqwc5Dh0Av4N2BWmuvU\n3WYBk4Lnk4BH01iXpAv6n28H3nf3/4o7lNX3DWBmQ4KWA2bWF/gXYmMwzwMnBqdl1b27+8/cfZi7\nlxH7//l/3b2CLL7nRmbWz8z6Nz4HDgPeoQu/6zk/Uc7MjiTWZ5kPTHf3qjRXKWXM7F5gArEVHv8J\nTAEeAR4ASoithPuv7t5yILvHMrP9gZeBeWzpk/45sXGIrL1vADPbk9igZD6xL4MPuPtUM/smsW/X\n2wBvAae6+4b01TQ1gi6mS9396Fy45+AeHw5eFgD3uHuVmQ2ik7/rOR8gREQkXK53MYmISAQFCBER\nCaUAISIioRQgREQklAKEiIiEUoAQaYeZbQ5Wx2x8JG1hPzMri19dVySTaKkNkfatc/fydFdCpLup\nBSHSScHa+/8ZrL//mpntFJSXmdn/mtnbZvacmZUE5duZ2cPB/gxzzew7wUflm9mtwZ4NfwlmPWNm\nPwz2sXjbzO5L021KDlOAEGlf3xZdTD+IO1bn7qOAG4nNyAe4AZjp7nsCNcD1Qfn1wIvB/gyjgXeD\n8p2Bm9x9d2AlcEJQfgWwd/A556fq5kSiaCa1SDvMbI27bxVSvpDYhjwfBwsCfu7ug8zsC2B7d98U\nlC9198FmthwYFr/EQ7AE+TPBZi6Y2eVAobv/2syeAtYQWw7lkbi9HUS6hVoQIl3jEc8TEb8m0Ga2\njA0eRWzHw9HA63GrkYp0CwUIka75QdzPvwfP/0ZsJVGACmKLBUJsu8cLoGkjn+KoDzWzPGC4uz8P\nXA4UA61aMSKppG8kIu3rG+zK1ugpd29Mdd3azN4m1go4OSi7GLjDzC4DlgNnBuU/AqrN7GxiLYUL\ngKWEywfuDoKIAdcHezqIdBuNQYh0UjAGMcbdv0h3XURSQV1MIiISSi0IEREJpRaEiIiEUoAQEZFQ\nChAiIhJKAUJEREIpQIiISCgFCBERCfX/AYJ+ZQk97nLGAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"inEBQUHW6vEv","colab_type":"text"},"source":["<br>\n","<font size=\"4\"><b>  Ερώτημα 3.2 </b></font>\n","<br>\n","\n","Τώρα χρησιμοποιούμε την έτοιμη υλοποίηση του μηχανισμού __attention__ για να υπολογίσουμε την αναπαράσταση ενός κειμένου,ως το σταθμισμένο άθροισμα των εξόδων ενός LSTM.\n","\n","$$u_i=tanh(Wh_i+b)$$\n","\n","$$a_i=\\frac{exp(u_i)}{\\sum_{t=1}^{N}exp(u_t)}$$\n","\n","$$\\sum_{i=1}^{N}a_i h_i$$\n","\n","Για την υλοποίηση του παρόντος ερωτήματος συνδυάσαμε τα ερωτήματα 2.2 και 3.1. Συγκεκριμένα πλέον ώς είσοδος στο SelfAttention layer δεν μπαίνουν τα embeddings αλλά οι έξοδοι του lstm στο οποίο έχουμε περάσει τα embeddings. Ο κώδικας που υλοποιήσαμε λοιπόν βρίσκεται στο script models_3_2.py και είναι ο εξής:\n","``` python\n","import torch\n","from SelfAttention import SelfAttention # Lab3.3.1\n","from torch import nn\n","\n","\n","class AttentionLSTM(nn.Module):\n","\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        super(AttentionLSTM, self).__init__()\n","        num_emb, dim_emb = embeddings.shape\n","        \n","        # 1 - define the embedding layer\n","        self.embedding = nn.Embedding(num_embeddings = num_emb, embedding_dim = dim_emb) # EX4\n","\n","        # 2 - initialize the weights of our Embedding layer\n","        # from the pretrained word embeddings\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings)) # EX4\n","        # 3 - define if the embedding layer will be frozen or finetuned\n","        if not trainable_emb:\n","            self.embedding.weight.requires_grad = False # EX4\n","\n","        # 4 - define a lstm transformation of the representations\n","        #hidden size = 50\n","        #num of hidden layers = 1\n","        self.lstm = nn.LSTM(dim_emb, 50, 1, batch_first = True) # Lab3.2.1\n","\n","        # 5 - define the final Linear layer which maps\n","        # the representations to the classes\n","        self.linear = nn.Linear(50, output_size) # EX5\n","        self.attention = SelfAttention(50, batch_first = True, non_linearity = \"tanh\") # Lab3.3.1\n","\n","    def forward(self, x, lengths, bows):\n","\n","        # 1 - embed the words, using the embedding layer\n","        embeddings = self.embedding(x)  # EX6\n","\n","        # 2 - call baseline lstm network\n","        base_lstm, _ = self.lstm(embeddings) # Lab3.2.1\n","\n","        # 3 - call attention to get the representations.\n","        representations = self.attention(base_lstm, lengths) # Lab3.3.1\n","        '''representations, scores = self.attention(base_lstm, lengths) # Lab3.5'''\n","        \n","        # 4 - project the representations to classes using a linear layer\n","        logits = self.linear(representations) # EX6\n","\n","        return logits\n","        '''return logits, scores # Lab3.5'''\n","```\n","Εκπαιδεύοντας λοιπόν το μοντέλο μας παίρνουμε τα εξής αποτελέσματα:"]},{"cell_type":"code","metadata":{"id":"CZ7CzCqg6vEy","colab_type":"code","outputId":"1fa0b2be-0dec-4993-eb69-a46c2e0804a2","executionInfo":{"status":"ok","timestamp":1580132462065,"user_tz":-120,"elapsed":825727,"user":{"displayName":"Sila Vassiliou","photoUrl":"","userId":"12235529962578225857"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%run -i 'main.py' AttentionLSTM No"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading word embeddings...\n","Loaded word embeddings from cache.\n","AttentionLSTM(\n","  (embedding): Embedding(400002, 50)\n","  (lstm): LSTM(50, 50, batch_first=True)\n","  (linear): Linear(in_features=50, out_features=3, bias=True)\n","  (attention): SelfAttention(\n","    (softmax): Softmax(dim=-1)\n","    (non_linearity): Tanh()\n","  )\n",")\n"," [========================================] ...Epoch 1, Loss: 1.0454\n"," [========================================] ...Epoch 2, Loss: 0.7759\n"," [========================================] ...Epoch 3, Loss: 0.8712\n"," [========================================] ...Epoch 4, Loss: 0.9433\n"," [========================================] ...Epoch 5, Loss: 0.8973\n"," [========================================] ...Epoch 6, Loss: 0.9694\n"," [========================================] ...Epoch 7, Loss: 0.9800\n"," [========================================] ...Epoch 8, Loss: 0.8138\n"," [========================================] ...Epoch 9, Loss: 0.8426\n"," [========================================] ...Epoch 10, Loss: 0.9431\n"," [========================================] ...Epoch 11, Loss: 0.6566\n"," [========================================] ...Epoch 12, Loss: 0.8088\n"," [========================================] ...Epoch 13, Loss: 0.8036\n"," [========================================] ...Epoch 14, Loss: 0.8155\n"," [========================================] ...Epoch 15, Loss: 0.6920\n"," [========================================] ...Epoch 16, Loss: 0.8365\n"," [========================================] ...Epoch 17, Loss: 0.8261\n"," [========================================] ...Epoch 18, Loss: 0.8548\n"," [========================================] ...Epoch 19, Loss: 0.7500\n"," [========================================] ...Epoch 20, Loss: 1.0168\n"," [========================================] ...Epoch 21, Loss: 0.7893\n"," [========================================] ...Epoch 22, Loss: 0.7755\n"," [========================================] ...Epoch 23, Loss: 0.9709\n"," [========================================] ...Epoch 24, Loss: 0.8179\n"," [========================================] ...Epoch 25, Loss: 0.9555\n"," [========================================] ...Epoch 26, Loss: 0.8104\n"," [========================================] ...Epoch 27, Loss: 0.8642\n"," [========================================] ...Epoch 28, Loss: 1.0348\n"," [========================================] ...Epoch 29, Loss: 0.6350\n"," [========================================] ...Epoch 30, Loss: 0.8247\n"," [========================================] ...Epoch 31, Loss: 0.7041\n"," [========================================] ...Epoch 32, Loss: 0.8054\n"," [========================================] ...Epoch 33, Loss: 0.9842\n"," [========================================] ...Epoch 34, Loss: 0.6710\n"," [========================================] ...Epoch 35, Loss: 0.7133\n"," [========================================] ...Epoch 36, Loss: 0.8342\n"," [========================================] ...Epoch 37, Loss: 0.8025\n"," [========================================] ...Epoch 38, Loss: 0.7700\n"," [========================================] ...Epoch 39, Loss: 0.8118\n"," [========================================] ...Epoch 40, Loss: 0.8665\n"," [========================================] ...Epoch 41, Loss: 0.7162\n"," [========================================] ...Epoch 42, Loss: 0.8497\n"," [========================================] ...Epoch 43, Loss: 0.8486\n"," [========================================] ...Epoch 44, Loss: 0.7436\n"," [========================================] ...Epoch 45, Loss: 0.7505\n"," [========================================] ...Epoch 46, Loss: 0.7347\n"," [========================================] ...Epoch 47, Loss: 0.7487\n"," [========================================] ...Epoch 48, Loss: 0.7788\n"," [========================================] ...Epoch 49, Loss: 0.8928\n"," [========================================] ...Epoch 50, Loss: 0.8580\n","----------------- Results for  Semeval2017A  dataset -----------------\n","The trainning loss is:  0.7902122408766108\n","The testing loss is:  0.9070659751693407\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor train set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.56      0.45      5200\n","           1       0.69      0.63      0.66     24583\n","           2       0.67      0.66      0.66     19787\n","\n","    accuracy                           0.63     49570\n","   macro avg       0.58      0.62      0.59     49570\n","weighted avg       0.65      0.63      0.64     49570\n"," \n","\n","\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor test set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.44      0.67      0.53      2614\n","           1       0.71      0.61      0.66      6877\n","           2       0.57      0.49      0.53      2793\n","\n","    accuracy                           0.60     12284\n","   macro avg       0.57      0.59      0.57     12284\n","weighted avg       0.62      0.60      0.60     12284\n"," \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEjCAYAAAAomJYLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAoQxxhhP/x+mzx+qiqbkRgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"3hhY1jIC6vFS","colab_type":"text"},"source":["<br>\n","<font size=\"4\"><b>  Ερώτημα 4.1 </b></font>\n","<br>\n","\n","Το μοντέλο αυτό ουσιαστικά είναι ίδιο με το μοντέλο OptimizedLSTM που ορίσαμε στο ερώτημα 2.2 (models_2_2.py) με μοναδική διαφορά ότι στην αρχικοποίηση του μοντέλου ορίζουμε το LSTM ως bidirectional\n","καθώς επίσης το τελευταίο linear layer θα παίρνει τώρα αναπαραστάσεις μεγέθους  $\\small 4 \\cdot \\text{hidden size} $:\n","Ο κώδικας του script models_4_1.py είναι ο ακόλουθος:\n","``` python\n","import torch\n","\n","from torch import nn\n","import numpy as np\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","\n","class OptimizedBiLSTM(nn.Module):\n","    \"\"\"\n","    1. We embed the words in the input texts using an embedding layer\n","    2. We compute the min, mean, max of the word embeddings in each sample\n","       and use it as the feature representation of the sequence.\n","    4. We project with a linear layer the representation\n","       to the number of classes.ngth)\n","    \"\"\"\n","\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        \"\"\"\n","\n","        Args:\n","            output_size(int): the number of classes\n","            embeddings(bool):  the 2D matrix with the pretrained embeddings\n","            trainable_emb(bool): train (finetune) or freeze the weights\n","                the embedding layer\n","        \"\"\"\n","\n","        super(OptimizedBiLSTM, self).__init__()\n","        num_emb, dim_emb = embeddings.shape\n","        \n","        # 1 - define the embedding layer\n","        self.embedding = nn.Embedding(num_embeddings = num_emb, embedding_dim = dim_emb) # EX4\n","\n","        # 2 - initialize the weights of our Embedding layer\n","        # from the pretrained word embeddings\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings)) # EX4\n","\n","        # 3 - define if the embedding layer will be frozen or finetuned\n","        if not trainable_emb:\n","            self.embedding.weight.requires_grad = False # EX4\n","\n","        # 4 - define a lstm transformation of the representations\n","        #hidden size = 50\n","        #num of hidden layers = 1\n","        self.Bi_lstm = nn.LSTM(dim_emb, 50, 1, batch_first = True, bidirectional = True) # Lab3.2.1\n","\n","        # 5 - define the final Linear layer which maps\n","        # the representations to the classes\n","        self.linear = nn.Linear(4*50, output_size) # Lab3.2.2\n","\n","    def forward(self, x, lengths, bows):\n","        \"\"\"\n","        This is the heart of the model.\n","        This function, defines how the data passes through the network.\n","\n","        Returns: the logits for each class\n","\n","        \"\"\"\n","\n","        # 1 - embed the words, using the embedding layer\n","        embeddings = self.embedding(x)  # EX6\n","        \n","        # 2 - call baseline lstm network\n","        base_Bilstm, _ = self.Bi_lstm(embeddings) # Lab3.2.2\n","        \n","        # 3 - find the real last timestep \n","        real_last_timestep = [min(int(lengths[i]), base_Bilstm.shape[1])-1 for i in range(len(x))] # Lab3.2.2\n","        \n","        # 4 - Limit of forward and backward\n","        limit = int(base_Bilstm.shape[2]/2)\n","\n","        # 5 - construct a sentence representation out of the word embeddings\n","        representations_Bilstm_fw = torch.zeros([len(x), embeddings.shape[2]])  # Lab3.4.1     \n","        representations_Bilstm_bw = torch.zeros([len(x), embeddings.shape[2]])  # Lab3.4.1\n","\n","        for i in range(len(x)):\n","            representations_Bilstm_fw[i] = base_Bilstm[i, real_last_timestep[i], :limit]  # Lab3.4.1\n","            representations_Bilstm_bw[i] = base_Bilstm[i, real_last_timestep[i], limit:]  # Lab3.4.1\n","        representation_mean = torch.zeros([len(x), embeddings.shape[2]])  # Lab3.2.2\n","        representation_max = torch.zeros([len(x), embeddings.shape[2]])  # Lab3.2.2\n","        for i in range(len(x)):\n","            representation_mean[i] = torch.sum(embeddings[i], dim=0) / lengths[i].float() # Lab3.2.2\n","            representation_max[i],_ = torch.max(embeddings[i], dim=0)\n","        \n","        representations = torch.cat((representations_Bilstm_fw, representations_Bilstm_bw, representation_mean,representation_max), 1) # Lab3.4.1\n","        # 6 - project the representations to classes using a linear layer\n","        logits = self.linear(representations.cuda()) # EX6\n","\n","        return logits\n","```\n","Εκπαιδεύοντας λοιπόν το μοντέλο μας παίρνουμε τα εξής αποτελέσματα:"]},{"cell_type":"code","metadata":{"id":"_sqAfveS6vFT","colab_type":"code","outputId":"5c8f668a-fdb2-4a7e-a77d-a499b429bc69","executionInfo":{"status":"ok","timestamp":1580088025767,"user_tz":-120,"elapsed":1856169,"user":{"displayName":"Sila Vassiliou","photoUrl":"","userId":"12235529962578225857"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%run -i 'main.py' OptimizedBiLSTM No"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading word embeddings...\n","Loaded word embeddings from cache.\n","OptimizedBiLSTM(\n","  (embedding): Embedding(400002, 50)\n","  (Bi_lstm): LSTM(50, 50, batch_first=True, bidirectional=True)\n","  (linear): Linear(in_features=200, out_features=3, bias=True)\n",")\n"," [========================================] ...Epoch 1, Loss: 0.9383\n"," [========================================] ...Epoch 2, Loss: 0.9191\n"," [========================================] ...Epoch 3, Loss: 0.8885\n"," [========================================] ...Epoch 4, Loss: 0.9638\n"," [========================================] ...Epoch 5, Loss: 0.8517\n"," [========================================] ...Epoch 6, Loss: 0.8742\n"," [========================================] ...Epoch 7, Loss: 0.8449\n"," [========================================] ...Epoch 8, Loss: 0.9816\n"," [========================================] ...Epoch 9, Loss: 0.8284\n"," [========================================] ...Epoch 10, Loss: 0.8653\n"," [========================================] ...Epoch 11, Loss: 0.7841\n"," [========================================] ...Epoch 12, Loss: 0.8825\n"," [========================================] ...Epoch 13, Loss: 0.9045\n"," [========================================] ...Epoch 14, Loss: 0.8701\n"," [========================================] ...Epoch 15, Loss: 0.8047\n"," [========================================] ...Epoch 16, Loss: 0.7614\n"," [========================================] ...Epoch 17, Loss: 0.7348\n"," [========================================] ...Epoch 18, Loss: 0.8011\n"," [========================================] ...Epoch 19, Loss: 0.8070\n"," [========================================] ...Epoch 20, Loss: 0.7858\n"," [========================================] ...Epoch 21, Loss: 0.8995\n"," [========================================] ...Epoch 22, Loss: 0.7722\n"," [========================================] ...Epoch 23, Loss: 0.7661\n"," [========================================] ...Epoch 24, Loss: 0.9260\n"," [========================================] ...Epoch 25, Loss: 0.7862\n"," [========================================] ...Epoch 26, Loss: 0.8553\n"," [========================================] ...Epoch 27, Loss: 0.9105\n"," [========================================] ...Epoch 28, Loss: 0.7796\n"," [========================================] ...Epoch 29, Loss: 0.8358\n"," [========================================] ...Epoch 30, Loss: 0.7154\n"," [========================================] ...Epoch 31, Loss: 0.7994\n"," [========================================] ...Epoch 32, Loss: 0.7706\n"," [========================================] ...Epoch 33, Loss: 0.9272\n"," [========================================] ...Epoch 34, Loss: 0.8213\n"," [========================================] ...Epoch 35, Loss: 0.8365\n"," [========================================] ...Epoch 36, Loss: 0.8365\n"," [========================================] ...Epoch 37, Loss: 0.9410\n"," [========================================] ...Epoch 38, Loss: 0.7595\n"," [========================================] ...Epoch 39, Loss: 0.6615\n"," [========================================] ...Epoch 40, Loss: 0.8312\n"," [========================================] ...Epoch 41, Loss: 0.7091\n"," [========================================] ...Epoch 42, Loss: 0.7854\n"," [========================================] ...Epoch 43, Loss: 0.9227\n"," [========================================] ...Epoch 44, Loss: 0.7691\n"," [========================================] ...Epoch 45, Loss: 0.6734\n"," [========================================] ...Epoch 46, Loss: 0.7016\n"," [========================================] ...Epoch 47, Loss: 0.7716\n"," [========================================] ...Epoch 48, Loss: 0.9417\n"," [========================================] ...Epoch 49, Loss: 0.7103\n"," [========================================] ...Epoch 50, Loss: 0.5260\n","----------------- Results for  Semeval2017A  dataset -----------------\n","The trainning loss is:  0.7787291270863149\n","The testing loss is:  0.8806674294173717\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor train set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.54      0.48      6095\n","           1       0.74      0.62      0.67     26501\n","           2       0.61      0.71      0.66     16974\n","\n","    accuracy                           0.64     49570\n","   macro avg       0.59      0.62      0.60     49570\n","weighted avg       0.66      0.64      0.64     49570\n"," \n","\n","\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor test set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.49      0.65      0.56      2994\n","           1       0.69      0.62      0.65      6692\n","           2       0.56      0.51      0.53      2598\n","\n","    accuracy                           0.60     12284\n","   macro avg       0.58      0.59      0.58     12284\n","weighted avg       0.62      0.60      0.61     12284\n"," \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEjCAYAAAAomJYLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"DGJV142g6vFv","colab_type":"text"},"source":["<br>\n","<font size=\"4\"><b>  Ερώτημα 4.2 </b></font>\n","<br>\n","\n","Το μοντέλο αυτό ουσιαστικά είναι ίδιο με το μοντέλο AttentionLSTM που ορίσαμε στο ερώτημα 3.2 (models_3_2.py) με τη διαφορά ότι στην αρχικοποίηση του μοντέλου ορίζουμε το LSTM ως bidirectional.Επίσης το τελευταίο linear layer θα παίρνει τώρα αναπαραστάσεις μεγέθους  $\\small 2 \\cdot \\text{hidden size} $\n","ενώ διπλασιάζεται και η είσοδος στο Attention Layer.\n","``` python \n","import torch\n","from SelfAttention import SelfAttention # Lab3.3.1\n","from torch import nn\n","\n","\n","class AttentionBiLSTM(nn.Module):\n","\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        super(AttentionBiLSTM, self).__init__()\n","        num_emb, dim_emb = embeddings.shape\n","        \n","        # 1 - define the embedding layer\n","        self.embedding = nn.Embedding(num_embeddings = num_emb, embedding_dim = dim_emb) # EX4\n","\n","        # 2 - initialize the weights of our Embedding layer\n","        # from the pretrained word embeddings\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings)) # EX4\n","        # 3 - define if the embedding layer will be frozen or finetuned\n","        if not trainable_emb:\n","            self.embedding.weight.requires_grad = False # EX4\n","\n","        # 4 - define a lstm transformation of the representations\n","        #hidden size = 50\n","        #num of hidden layers = 1\n","        self.Bi_lstm = nn.LSTM(dim_emb, 50, 1, batch_first = True, bidirectional = True) # Lab3.4.2\n","\n","        # 5 - define the final Linear layer which maps\n","        # the representations to the classes\n","        self.linear = nn.Linear(2*50, output_size) # EX5\n","        self.attention = SelfAttention(2*50, batch_first = True, non_linearity = \"tanh\") # Lab3.4.2\n","\n","    def forward(self, x, lengths, bows):\n","\n","        # 1 - embed the words, using the embedding layer\n","        embeddings = self.embedding(x)  # EX6\n","\n","        # 2 - call baseline lstm network\n","        base_Bilstm, _ = self.Bi_lstm(embeddings) # Lab3.4.2\n","\n","        # 3 - call attention to get the representations.\n","        representations = self.attention(base_Bilstm, lengths) # Lab3.4.2\n","        '''representations, scores = self.attention(base_Bilstm, lengths) # Lab3.5'''\n","        \n","        # 4 - project the representations to classes using a linear layer\n","        logits = self.linear(representations) # EX6\n","\n","        return logits, scores\n","        '''return logits, scores # Lab3.5'''\n","```\n","Εκπαιδεύοντας λοιπόν το μοντέλο μας παίρνουμε τα εξής αποτελέσματα:"]},{"cell_type":"code","metadata":{"id":"za0ddz5R6vFy","colab_type":"code","outputId":"b6346ba3-a0be-4cad-b626-f9732ab9beb4","executionInfo":{"status":"ok","timestamp":1580084630428,"user_tz":-120,"elapsed":727435,"user":{"displayName":"Sila Vassiliou","photoUrl":"","userId":"12235529962578225857"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%run -i 'main.py' AttentionBiLSTM No"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading word embeddings...\n","Loaded word embeddings from cache.\n","AttentionBiLSTM(\n","  (embedding): Embedding(400002, 50)\n","  (Bi_lstm): LSTM(50, 50, batch_first=True, bidirectional=True)\n","  (linear): Linear(in_features=100, out_features=3, bias=True)\n","  (attention): SelfAttention(\n","    (softmax): Softmax(dim=-1)\n","    (non_linearity): Tanh()\n","  )\n",")\n"," [========================================] ...Epoch 1, Loss: 0.9658\n"," [========================================] ...Epoch 2, Loss: 1.0258\n"," [========================================] ...Epoch 3, Loss: 0.9165\n"," [========================================] ...Epoch 4, Loss: 0.9958\n"," [========================================] ...Epoch 5, Loss: 0.8291\n"," [========================================] ...Epoch 6, Loss: 0.9344\n"," [========================================] ...Epoch 7, Loss: 0.8024\n"," [========================================] ...Epoch 8, Loss: 0.6681\n"," [========================================] ...Epoch 9, Loss: 0.7331\n"," [========================================] ...Epoch 10, Loss: 0.7531\n"," [========================================] ...Epoch 11, Loss: 0.8750\n"," [========================================] ...Epoch 12, Loss: 0.7916\n"," [========================================] ...Epoch 13, Loss: 0.9328\n"," [========================================] ...Epoch 14, Loss: 1.0278\n"," [========================================] ...Epoch 15, Loss: 0.9269\n"," [========================================] ...Epoch 16, Loss: 0.9790\n"," [========================================] ...Epoch 17, Loss: 0.9311\n"," [========================================] ...Epoch 18, Loss: 0.6715\n"," [========================================] ...Epoch 19, Loss: 0.6340\n"," [========================================] ...Epoch 20, Loss: 0.7273\n"," [========================================] ...Epoch 21, Loss: 0.8748\n"," [========================================] ...Epoch 22, Loss: 0.7797\n"," [========================================] ...Epoch 23, Loss: 0.7688\n"," [========================================] ...Epoch 24, Loss: 0.7132\n"," [========================================] ...Epoch 25, Loss: 0.7181\n"," [========================================] ...Epoch 26, Loss: 0.7127\n"," [========================================] ...Epoch 27, Loss: 0.8388\n"," [========================================] ...Epoch 28, Loss: 0.7283\n"," [========================================] ...Epoch 29, Loss: 0.8314\n"," [========================================] ...Epoch 30, Loss: 0.9777\n"," [========================================] ...Epoch 31, Loss: 0.9615\n"," [========================================] ...Epoch 32, Loss: 0.8374\n"," [========================================] ...Epoch 33, Loss: 0.6492\n"," [========================================] ...Epoch 34, Loss: 0.6780\n"," [========================================] ...Epoch 35, Loss: 0.7591\n"," [========================================] ...Epoch 36, Loss: 0.7827\n"," [========================================] ...Epoch 37, Loss: 0.8367\n"," [========================================] ...Epoch 38, Loss: 0.6341\n"," [========================================] ...Epoch 39, Loss: 0.7842\n"," [========================================] ...Epoch 40, Loss: 0.9532\n"," [========================================] ...Epoch 41, Loss: 0.6900\n"," [========================================] ...Epoch 42, Loss: 0.7796\n"," [========================================] ...Epoch 43, Loss: 0.7336\n"," [========================================] ...Epoch 44, Loss: 0.7273\n"," [========================================] ...Epoch 45, Loss: 0.9022\n"," [========================================] ...Epoch 46, Loss: 0.8482\n"," [========================================] ...Epoch 47, Loss: 0.6031\n"," [========================================] ...Epoch 48, Loss: 0.9596\n"," [========================================] ...Epoch 49, Loss: 0.6749\n"," [========================================] ...Epoch 50, Loss: 0.8469\n","----------------- Results for  Semeval2017A  dataset -----------------\n","The trainning loss is:  0.7695883303573451\n","The testing loss is:  0.8682713570694128\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor train set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.45      0.56      0.50      6208\n","           1       0.68      0.64      0.66     23738\n","           2       0.68      0.68      0.68     19624\n","\n","    accuracy                           0.65     49570\n","   macro avg       0.61      0.63      0.61     49570\n","weighted avg       0.65      0.65      0.65     49570\n"," \n","\n","\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor test set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.63      0.58      3355\n","           1       0.68      0.63      0.65      6409\n","           2       0.56      0.53      0.54      2520\n","\n","    accuracy                           0.61     12284\n","   macro avg       0.59      0.60      0.59     12284\n","weighted avg       0.61      0.61      0.61     12284\n"," \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEjCAYAAAAomJYLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Uc29qP6KaVBi","colab_type":"text"},"source":["Για μια ενδεικτική __σύγκριση όλων των προηγούμενων αποτελεσμάτων__, παραθέτουμε παρακάτω ένα πίνακα που δείχνει το __accuracy__ πάνω στο train και στο test set όλων των μοντέλων που κατασκευάσαμε:\n","\n","|                   |             |            |\n","|-------------------|-------------|------------|\n","|                   |**Train Set**|**Test Set**|\n","| **OptimizedDNN**  | 0.60        | 0.56       |\n","| **AttentionDNN**  | 0.59        | 0.57       |\n","| **BaselineLSTM**  | 0.64        | 0.59       |\n","|**OptimizedLSTM**  | 0.64        | 0.59       |\n","|**AttentionLSTM**  | 0.63        | 0.60       |\n","|**OptimizedBiLSTM**| 0.64        | 0.60       |\n","|**AttentionBiLSTM**| 0.65        | 0.61       |"]},{"cell_type":"markdown","metadata":{"id":"ml96M2MujoWR","colab_type":"text"},"source":["<br>\n","<font size=\"4\"><b>  Ερώτημα 5.1 </b></font>\n","\n","Συγκρίνοντας τα validation losses όλων των προηγούμενων μοντέλων που εκπαιδεύσαμε βλέπουμε ότι αυτό με το μικρότερο validation loss είναι το AttentionBiLSTM με validation loss = 0.86827135. Συνεπώς καλούμαστε να αποθηκεύσουμε σε ένα checkpoint στο δίσκο το μοντέλο αυτό. Για να το επιτύχουμε αυτό προσθέτουμε στο script main.py την εξής εντολή:\n","```python\n","torch.save(model, model_name+'.pt')\n","```\n","Στη συνέχεια χρησιμοποιώντας το αποθηκευμένο checkpoint αποθηκεύουμε τις προβλέψεις του δικτύου στο validation set. Συγκεκριμένα δημιουργούμε ένα αρχείο που περιέχει τα περιεχόμενα της μεταβλητής y_test_pred. Αυτό το επιτυγχάνουμε με τις επόμενες γραμμές κώδικα:\n","```python\n","with open(model_name+'_predictions.txt', 'w') as f:\n","  for i in y_test_pred:\n","    f.write(str(int(i)) + '\\n')\n","```\n"]},{"cell_type":"code","metadata":{"id":"fqT7lvlP6oZd","colab_type":"code","colab":{}},"source":["%run -i 'main.py' AttentionBiLSTM No"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u9Gong69nz-f","colab_type":"text"},"source":["<br>\n","<font size=\"4\"><b>  Ερώτημα 5.2 </b></font>\n","\n","Στο ερώτημα αυτό χρησιμοποιούμε το NeAt-vision για να οπτικοποιήσουμε τα βάρη των κατανομών του attention. Για να το επιτύχουμε αυτό πρέπει σύμφωνα με το documentation του NeAt-vision να δημιουργήσουμε δύο .json αρχεία. Το πρώτο (predictions) από αυτά θα πρέπει να έχει την μορφή:\n","```python\n","{\n","    \"text\": [],       \\\\ list of strings - the tokens (words, chars) in the text. (required)\n","    \"label\": 0,       \\\\ integer - the class label. (required)\n","    \"prediction\": 0,  \\\\ integer - the predicted label. (required)\n","    \"posterior\": [],  \\\\ list of floats - the posterior probabilities. (optional)\n","    \"attention\": [],  \\\\ list of floats - the attention weigths. (required)\n","    \"id\": \"sample_99\" \\\\ string - a unique id assigned to each sample. (required)\n"," }\n"," ```\n","και το δεύτερο (labels) θα πρέπει να έχει την μορφή παραπλήσια με την επόμενη:\n","```python\n","{\n","  \"0\": {\n","    \"name\": \"❤\",\n","    \"desc\": \"_red_heart_\"\n","  },\n","  \"1\": {\n","    \"name\": \"😍\",\n","    \"desc\": \"_smiling_face_with_hearteyes_\"\n","  },\n","  \"2\": {\n","    \"name\": \"😂\",\n","    \"desc\": \"_face_with_tears_of_joy_\"\n","}\n","```\n","Για να μπορέσουμε να έχουμε όλες τις μεταβλητές αυτές που χρειαζόμασταν στην main έπρεπε να τροποιήσουμε τα κάποια scripts. Τις αλλαγές που θα περιγράψουμε στην συνέχεια τις βάζουμε σε σχόλια μετά την διεκπαιρέωση του ερωτήματος ώστε να υπάρχει συμβατότητα με τα προηγούμενα ερωτήματα που είναι σε πλήθος περισσότερα. Συγκεκριμένα οι αλλαγές που κάναμε ήταν:\n","* ___SelfAttention.py___ : Επιστρέφει την μεταβλητή scores.\n","``` python\n","return representations, scores\n","```\n","* ____models_4_2.py, models_3_2.py, models_3_1.py___ : Η συνάρτηση forward πλέον περιέχει τα scores τα οποία επιστρέφει.\n","```python\n","def forward(self, x, lengths, bows):\n","\n","        # 1 - embed the words, using the embedding layer\n","        embeddings = self.embedding(x)  # EX6\n","\n","        # 2 - call attention to get the representations.\n","        representations, scores = self.attention(embeddings, lengths) # Lab3.3.1\n","        \n","        # 3 - project the representations to classes using a linear layer\n","        logits = self.linear(representations) # EX6\n","\n","        return logits, scores\n","```\n","* ___training.py___ : Πλέον περιέχει τα scores τα οποία βάζει σε μια λίστα και τα επιστρέφει. Επίσης οι a posteriori πιθανότητες που ήδη υπολογίζονταν τώρα μπαίνουν και αυτές σε μια λίστα και επιστρέφονται στην main.\n","```python\n","def eval_dataset(dataloader, model, loss_function):\n","    # IMPORTANT: switch to eval mode\n","    # disable regularization layers, such as Dropout\n","\n","    model.eval()\n","    running_loss = 0.0\n","\n","    y_pred = []  # the predicted labels\n","    y = []  # the gold labels\n","    y_post = [] # the posteriors\n","    y_scores = [] # the scores\n","\n","    # obtain the model's device ID\n","    device = next(model.parameters()).device\n","\n","    # IMPORTANT: in evaluation mode, we don't want to keep the gradients\n","    # so we do everything under torch.no_grad()\n","    with torch.no_grad():\n","        for index, batch in enumerate(dataloader, 1):\n","            # get the inputs (batch)\n","            inputs, labels, lengths, bows = batch\n","\n","            # Step 1 - move the batch tensors to the right device\n","            inputs = inputs.to(device) # EX9\n","            labels = labels.to(device) # EX9\n","            lengths = lengths.to(device) # EX9\n","            bows = bows.to(device)\n","\n","            # Step 2 - forward pass: y' = model(x)\n","            ypred, scores = model(inputs, lengths, bows) # EX9\n","            \n","            # Step 3 - compute loss.\n","            # We compute the loss only for inspection (compare train/test loss)\n","            # because we do not actually backpropagate in test time\n","            if str(loss_function) == \"BCEWithLogitsLoss()\":  # EX9\n","               opt_labels = torch.nn.functional.one_hot(labels, 2).float()  # EX9\n","            else:\n","               opt_labels = labels  # EX9\n","            loss = loss_function(ypred, opt_labels) # EX9\n","\n","            # Step 4 - make predictions (class = argmax of posteriors)\n","            arg_max_post = torch.argmax(ypred, 1) # EX9\n","\n","            # Step 5 - collect the predictions, gold labels and batch loss\n","            y_pred.append(arg_max_post.cpu().numpy()) # EX9\n","            y.append(labels.cpu().numpy()) # EX9\n","            \n","            y_post.append(ypred.cpu().numpy()) # Lab3.5.2\n","            y_scores.append(scores.cpu().numpy()) # Lab3.5.2\n","\n","            running_loss += loss.data.item()\n","\n","    return running_loss / index, (y_pred, y), y_post, y_scores\n","```\n","* ___main.py___ : Δημιουργούμε ένα αρχείο .json και προσθέτουμε τις απαραίτητες μεταβλητές στην απαραίτητη δομή που προαναφέραμε. Στο σημείο αυτό αναφέρουμε ότι κάνουμε tokenize το κείμενο με τον tokenizer που έχουμε χρησιμοποιήσει και στα προηγούμενα ερωτήματα.\n","```python\n","tokenizer = TweetTokenizer()\n","    token_text = [tokenizer.tokenize(example) for example in X_test]\n","           \n","    with open(model_name+'.json', 'w') as f:\n","        all_data = []\n","        for i in range(len(test_set)):\n","            jsn_d ={}\n","            jsn_d['text'] = token_text[i]\n","            jsn_d['label'] = int(test_set[i][1])\n","            jsn_d['prediction'] = int(y_test_pred[i])\n","            jsn_d['posterior'] = y_test_post[i].tolist()\n","            jsn_d['attention'] = y_test_scores[i].tolist()\n","            jsn_d['id'] = i\n","            all_data.append(jsn_d)\n","        json.dump(all_data, f)\n","```\n","\n","Τα αρχεία που δημιουργήθηκαν στα βήματα είναι:\n","1. ___AttentionBiLSTM.pt___ (checkpoint)\n","2. ___AttentionBiLSTM_predictions.txt___ (predictions)\n","3. ___AttentionBiLSTM.json___ (predictions json file)\n","4. ___labels.json___ (labels json file)\n","\n","Και περιέχονται στον φάκελο με τα παραδοτέα.\n","\n","Ανεβάζοντας τα αρχεία μας στο https://cbaziotis.github.io/neat-vision/ δημιουργούμε τις οπτικοποιήσεις που ζητούνται. Μερικά χαρακτηριστικά παραδείγματα είναι τα εξής:\n","\n","* Σωστή αρνητική πρόβλεψη\n","\n","<a href=\"https://ibb.co/9bmDj52\"><img src=\"https://i.ibb.co/3p53HZW/Screenshot-from-2020-01-29-18-37-09.png\" alt=\"Screenshot-from-2020-01-29-18-37-09\" border=\"0\"></a><br /><br>\n","\n","* Σωστή θετική πρόβλεψη\n","\n","<a href=\"https://ibb.co/tXpVx1v\"><img src=\"https://i.ibb.co/sH986XN/Screenshot-from-2020-01-29-18-42-20.png\" alt=\"Screenshot-from-2020-01-29-18-42-20\" border=\"0\"></a><br /><br>\n","\n","* Σωστή ουδέτερη πρόβλεψη\n","\n","<a href=\"https://ibb.co/1qrGytP\"><img src=\"https://i.ibb.co/Wykv84M/Screenshot-from-2020-01-29-18-58-06.png\" alt=\"Screenshot-from-2020-01-29-18-58-06\" border=\"0\"></a><br /><br>\n","\n","* Θετικό ενώ είναι αρνητικό\n","\n","<a href=\"https://ibb.co/D81S8Tg\"><img src=\"https://i.ibb.co/P9rf90z/Screenshot-from-2020-01-29-18-28-10.png\" alt=\"Screenshot-from-2020-01-29-18-28-10\" border=\"0\"></a><br /><a target='_blank'></a><br />\n","\n","* Αρνητικό ενώ είναι θετικό\n","\n","<a href=\"https://ibb.co/gMLsCbQ\"><img src=\"https://i.ibb.co/1ftHxYB/Screenshot-from-2020-01-29-19-05-52.png\" alt=\"Screenshot-from-2020-01-29-19-05-52\" border=\"0\"></a><br />\n"]},{"cell_type":"markdown","metadata":{"id":"dG_UTbkuyIxD","colab_type":"text"},"source":["<br>\n","<font size=\"4\"><b>  Ερώτημα 5.3 </b></font>\n","\n","Ακολουθήσαμε τα ερωτήματα 5.1 και 5.2 για τα μοντέλα AttentionDNN, AttentionLSTM. Των οποίων τα αρχεία οπτικοποιήσαμε και παρουσιάζουμε στην συνέχεια τρία ενδιαφέρνοντα αποτελέσματα. Τα αρχεία που προέκυψαν επισυνάπτονται και αυτά στον φάκελο με τα παραδοτέα. Επισημαίνουμε ότι στις επόμενες εικόνες το πρώτο κομμάτι της καθεμίας αφορά το AttentionBiLSTM, το δεύτερο αφρορά το Attention DNN και το τρίτο το AttentionLSTM.\n"]},{"cell_type":"code","metadata":{"id":"suxK6Op3yVTm","colab_type":"code","colab":{}},"source":["%run -i 'main.py' AttentionDNN No\n","%run -i 'main.py' AttentionLSTM No"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zIsANqxwy7d6","colab_type":"text"},"source":["<a href=\"https://ibb.co/xmfjt99\"><img src=\"https://i.ibb.co/VHQScnn/imgonline-com-ua-twotoone-a1-Ugh-IJUSym61k.jpg\" alt=\"imgonline-com-ua-twotoone-a1-Ugh-IJUSym61k\" border=\"0\"></a><br />\n","\n","Παρατηρούμε ότι το μόνο που κάνει σωστή πρόβλεψη (positive)είναι το BiLSTM καθώς εξετάζει την ακολουθία και αριστερόστροφα και δεξιόστροφα με αποτέλεσμα να δίνει τα σωστότερα βάρη στις λέξεις. Αντίθετα το απλό νευρωνικό που εξετάζει τις λέξεις ξεχωριστά κάνει εντελώς λανθασμένη πρόβλεψη (negative). Το απλό lstm που εξετάζει την ακολουθία μόνο προς μία κατεύθυνση δίνει μερικώς σωστά βάρη στις λέξεις με αποτέλεσμα να κρίνει το tweet ως neutral.\n","<br><br>\n","\n","<a href=\"https://ibb.co/th7GQzd\"><img src=\"https://i.ibb.co/z5yMQFk/imgonline-com-ua-twotoone-LWBHY3n-C0c-Kee.jpg\" alt=\"imgonline-com-ua-twotoone-LWBHY3n-C0c-Kee\" border=\"0\"></a><br />\n","Η συμπεριφορά που παρατηρούμε είναι παραπλήσια με πρίν με μόνη διαφορά στο απλό νευρωνικό όπου τα βάρη των λέξεων είναι κάπως σταθμισμένα με αποτελέσμα το tweet να αναγνωρίζεται ως neutral.\n","<br><br>\n","\n","<a href=\"https://ibb.co/ng5nz0K\"><img src=\"https://i.ibb.co/YRqypWV/imgonline-com-ua-twotoone-t-OEtr-FLi-IC.jpg\" alt=\"imgonline-com-ua-twotoone-t-OEtr-FLi-IC\" border=\"0\"></a><br />\n","Οι παρατηρήσεις μας είναι αντίστοιχες με αυτές των δύο προηγούμενων παραδειγμάτων. Το ενδιαφέρον που παρατηρούμε σε αυτό το παράδειγμα είναι ότι το lstm δίνει σχεδόν μηδενικά βάρη σε λέξεις που και το απλό dnn δίνει μηδενικά βάρη οπότε η πρόβλεψη τους είναι σχεδόν ολόιδια. Όσον αφορά το BiLSTM, όπως και στις προηγούμενες δύο περιπτώσεις δίνει σωστή πρόβλεψη.\n"]},{"cell_type":"markdown","metadata":{"id":"FFGV5FR8XOy6","colab_type":"text"},"source":["<br>\n","<font size=\"4\"><b>  Ερώτημα 6.1 </b></font>\n","<br>\n","\n","Στο ερώτημα αυτό χρησιμοποιήσαμε τα Bag-of-Words(BoW) χαρακτηριστικά σε συνδυασμό με το μοντέλο που αναπτύξαμε στο ερώτημα 2.1 (τυχαία επιλογή). Για τον υπολογισμό των BoW χαρακτηριστικών χρησιμοποιήσαμε τον TfidfVectorizer. Το βήμα αυτό χρειάστηκε ειδική μεταχείριση καθώς οι πυκνοί πίνακες γέμιζαν την ram. Τα βήματα που ακολουθήσαμε ήταν τα εξής:\n","1. Είσοδος στην main αν θα χρησιμοποιήσουμε τα bow. Αν αυτή είναι Yes τότε συνεχίζουμε. Οι υπόλοιπες αλλαγές έγιναν στο scrip dataloading.py.\n","2. Εφαρμόζουμε τον TfidfVectorizer στο corpus μας και προκύπτει ένας αραιός πίνακας όπου κάθε γραμμή του έχει στοιχεία όσες οι μοναδικές λέξεις της αντίστοιχης πρότασης.\n","3. Στη συνάρτηση getitem χρησιμοποιώντας την έτοιμη συνάρτηση vectorizer.vocabulary_[word] μπορούσαμε να έχουμε την θέση της λέξης στον αραιό πίνακα και συνεπώς να πάρουμε την Tfidf αναπαράσταση της.\n","4. Δημιιουργήσαμε λοιπόν τον πίνακα bowar αντίστοιχο του exmaple που δημιουργούσαμε έως τώρα. Ο πίνακας αυτός περιέχει πλέον τα βάρη και τον επιστρέφουμε στην main ως το 4ο object του train και του test set.\n","5. Δημιουργούμε το μοντέλο BOW_LSTM. Πλέον η forward δέχεται ως όρισμα και τα βάρη των αντίστοιχων embeddings. Επιλέγουμε λοιπόν τα βάρη αυτά να τα πολλαπλασιάσουμε με τα embeddings και το γινόμενο αυτό να είναι τα νέα embeddings που θα δωθούν ως είσοδος στο νευρωνικό μας. Η ιδέα αυτή πάρθηκε από το paper https://www.aclweb.org/anthology/S17-2100.pdf.\n","\n","Το script dataloading.py περιέχει τον εξής κώδικα:\n","``` python\n","from torch.utils.data import Dataset\n","from tqdm import tqdm\n","import numpy as np\n","from nltk.tokenize import TweetTokenizer\n","import string\n","from nltk.corpus import stopwords\n","from numpy import mean, std\n","from math import ceil\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","#DATASET = \"Semeval2017A\"  # options: \"MR\", \"Semeval2017A\"\n","\n","class SentenceDataset(Dataset):\n","    \"\"\"\n","    Our custom PyTorch Dataset, for preparing strings of text (sentences)\n","    What we have to do is to implement the 2 abstract methods:\n","\n","        - __len__(self): in order to let the DataLoader know the size\n","            of our dataset and to perform batching, shuffling and so on...\n","\n","        - __getitem__(self, index): we have to return the properly\n","            processed data-item from our dataset with a given index\n","    \"\"\"\n","    \n","\n","    def __init__(self, X, y, word2idx,DATASET, bow):\n","        \"\"\"\n","        In the initialization of the dataset we will have to assign the\n","        input values to the corresponding class attributes\n","        and preprocess the text samples\n","\n","        -Store all meaningful arguments to the constructor here for debugging\n","         and for usage in other methods\n","        -Do most of the heavy-lifting like preprocessing the dataset here\n","\n","\n","        Args:\n","            X (list): List of training samples\n","            y (list): List of training labels\n","            word2idx (dict): a dictionary which maps words to indexes\n","        \"\"\"\n","        # EX2\n","        self.bow = bow\n","        if DATASET == \"Semeval2017A\":\n","            tweetToken = TweetTokenizer()\n","            self.data = [tweetToken.tokenize(example) for example in X]\n","\n","            if bow == \"Yes\": \n","               self.vectorizer = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False)\n","               self.corpus_tf_idf = self.vectorizer.fit_transform(self.data)\n","        elif DATASET == \"MR\":\n","            self.data = []\n","            for sample in X:\n","                new_string = sample.strip()\t\t# remove all the leading and trailing spaces from a string\n","                new_string = new_string.lower()\t\t# lowercase string\n","                for punctuation in string.punctuation:\t# remove punctuation\n","                    new_string = new_string.replace(punctuation,' ')\n","                new_string = \"\".join((char for char in new_string if char.isalpha() or char.isspace()))\t\t# Keeps only letters and spaces\n","                new_string = new_string.replace(\"\\n\", \" \")\t\t# replace newlines with spaces\n","                new_string = new_string.split()\t\t\t# use split without parameter to split the words indipendently of spaces number\n","                self.data.append(new_string)\n","        else:\n","            raise ValueError(\"Invalid dataset\")\n","        self.labels = y\n","        self.word2idx = word2idx\n","\n","        # raise NotImplementedError\n","        \n","        #EX3\n","        init_len = [len(sample) for sample in self.data]\n","        init_len_mean = np.mean(init_len)\n","        init_len_std = np.std(init_len)\n","        upper_bound = init_len_mean+2*init_len_std\n","        lower_bound = init_len_mean-2*init_len_std\n","        without_outl_len = [l for l in init_len if l >= lower_bound and l <= upper_bound]\n","        without_outl_len = sorted(without_outl_len)\n","        self.best_len = without_outl_len[ceil(0.8*len(without_outl_len))]\n","\n","    def __len__(self):\n","        \"\"\"\n","        Must return the length of the dataset, so the dataloader can know\n","        how to split it into batches\n","        Returns:\n","            (int): the length of the dataset\n","        \"\"\"\n","\n","        return len(self.data)\n","    \n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Returns the _transformed_ item from the dataset\n","        Args:\n","            index (int):\n","        Returns:\n","            (tuple):\n","                * example (ndarray): vector representation of a training example\n","                * label (int): the class label\n","                * length (int): the length (tokens) of the sentence\n","        Examples:\n","            For an `index` where:\n","            ::\n","                self.data[index] = ['this', 'is', 'really', 'simple']\n","                self.target[index] = \"neutral\"\n","            the function will have to return something like:\n","            ::\n","                example = [  533  3908  1387   649   0     0     0     0]\n","                label = 1\n","                length = 4\n","        \"\"\"\n","        # EX3\n","        i = 0\n","        example = np.zeros(self.best_len, dtype = np.int64)\n","        bowar = []\n","        for word in self.data[index]:\n","            if i < self.best_len:\n","                if self.bow == \"Yes\":\n","                   c = self.vectorizer.vocabulary_[word]\n","                   bowar.append(self.corpus_tf_idf[index].todense()[:,c].item(0))\n","                if word in self.word2idx.keys():\n","                   example[i] = (self.word2idx[word])\n","                else:\n","                   example[i] = (self.word2idx['<unk>'])\n","                i += 1\n","        while(len(bowar)<self.best_len): bowar.append(0)\n","        bowar = np.asarray(bowar)\n","        length = len(self.data[index])\n","        label = self.labels[index]\n","\n","        return example, label, length, bowar\n","```\n","Και το models_6_1.py περιέχει τον εξής κώδικα:\n","``` python\n","import torch\n","\n","from torch import nn\n","import numpy as np\n","\n","\n","class BOW_LSTM(nn.Module):\n","    \"\"\"\n","    1. We embed the words in the input texts using an embedding layer\n","    2. We compute the min, mean, max of the word embeddings in each sample\n","       and use it as the feature representation of the sequence.\n","    4. We project with a linear layer the representation\n","       to the number of classes.ngth)\n","    \"\"\"\n","\n","    def __init__(self, output_size, embeddings, trainable_emb=False):\n","        \"\"\"\n","\n","        Args:\n","            output_size(int): the number of classes\n","            embeddings(bool):  the 2D matrix with the pretrained embeddings\n","            trainable_emb(bool): train (finetune) or freeze the weights\n","                the embedding layer\n","        \"\"\"\n","\n","        super(BOW_LSTM, self).__init__()\n","        num_emb, dim_emb = embeddings.shape\n","        \n","        # 1 - define the embedding layer\n","        self.embedding = nn.Embedding(num_embeddings = num_emb, embedding_dim = dim_emb) # EX4\n","\n","        # 2 - initialize the weights of our Embedding layer\n","        # from the pretrained word embeddings\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings)) # EX4\n","\n","        # 3 - define if the embedding layer will be frozen or finetuned\n","        if not trainable_emb:\n","            self.embedding.weight.requires_grad = False # EX4\n","\n","        # 4 - define a lstm transformation of the representations\n","        #hidden size = 50\n","        #num of hidden layers = 1\n","        self.lstm = nn.LSTM(dim_emb, 50, 1, batch_first = True) # Lab3.2.1\n","\n","        # 5 - define the final Linear layer which maps\n","        # the representations to the classes\n","        self.linear = nn.Linear(50, output_size) # EX5\n","\n","    def forward(self, x, lengths, bows):\n","        \"\"\"\n","        This is the heart of the model.\n","        This function, defines how the data passes through the network.\n","\n","        Returns: the logits for each class\n","\n","        \"\"\"\n","\n","        # 1 - embed the words, using the embedding layer\n","        embeddings = self.embedding(x)  # EX6\n","        \n","        new_embeddings = torch.zeros([embeddings.shape[0], embeddings.shape[1], embeddings.shape[2]])\n","        for i in range(embeddings.shape[0]):\n","            for j in range(embeddings.shape[1]):\n","                new_embeddings[i][j][:] = bows[i][j]*embeddings[i][j][:]\n","        \n","        # 2 - call baseline lstm network\n","        base_lstm, _ = self.lstm(new_embeddings.cuda()) # Lab3.2.1\n","        \n","        # 3 - find the real last timestep \n","        real_last_timestep = [min(int(lengths[i]), base_lstm.shape[1])-1 for i in range(len(x))] # Lab3.2.1\n","\n","        # 4 - construct a sentence representation out of the word embeddings\n","        representations = torch.zeros([len(x), embeddings.shape[2]])  # EX6     \n","        for i in range(len(x)):\n","            representations[i] = base_lstm[i, real_last_timestep[i]]\n","\n","        # 5 - project the representations to classes using a linear layer\n","        logits = self.linear(representations.cuda()) # EX6\n","\n","        return logits\n","```\n","Στο σημείο αυτό αναφέρουμε ότι η εκπαίδευση του μοντέλου αυτού κατέστη ιδιαίτερα χρονοβόρα καθώς δεν βρέθηκε τρόπος να μεταφερθεί η πράξη του πολλαπλασιασμού των πινάκων σε gpu. Συνεπώς η εκπαίδευση εκτελέστηκε τοπικά στον υπολογιστή μόνο μία φορά, τα αποτελέσματα της οποίας επισυνάπτουμε σε εικόνες στην συνέχεια. Για λόγους συμβατότητας με τα προηγούμενα ερωτήματα επιλέξαμε να το εκπαιδεύσουμε με μόνο 10 εποχές και στο παρόν notebook.\n","\n","Εκπαιδεύοντας λοιπόν το μοντέλο μας παίρνουμε τα εξής αποτελέσματα:"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"9397306f-7243-4cd4-a156-449905a93531","executionInfo":{"status":"ok","timestamp":1580238381160,"user_tz":-120,"elapsed":2854198,"user":{"displayName":"Sila Vassiliou","photoUrl":"","userId":"12235529962578225857"}},"id":"B-iFhYQPVO5R","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%run -i 'main.py' BOW_LSTM Yes"],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading word embeddings...\n","Loaded word embeddings from cache.\n","BOW_LSTM(\n","  (embedding): Embedding(400002, 50)\n","  (lstm): LSTM(50, 50, batch_first=True)\n","  (linear): Linear(in_features=50, out_features=3, bias=True)\n",")\n"," [========================================] ...Epoch 1, Loss: 0.9467\n"," [========================================] ...Epoch 2, Loss: 1.0050\n"," [========================================] ...Epoch 3, Loss: 0.9116\n"," [========================================] ...Epoch 4, Loss: 0.8704\n"," [========================================] ...Epoch 5, Loss: 0.8606\n"," [========================================] ...Epoch 6, Loss: 0.8119\n"," [========================================] ...Epoch 7, Loss: 0.8590\n"," [========================================] ...Epoch 8, Loss: 0.8246\n"," [========================================] ...Epoch 9, Loss: 0.8874\n"," [========================================] ...Epoch 10, Loss: 0.9788\n","----------------- Results for  Semeval2017A  dataset -----------------\n","The trainning loss is:  0.8978266725220632\n","The testing loss is:  0.9903497869769732\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor train set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.05      0.52      0.10       815\n","           1       0.76      0.53      0.62     31537\n","           2       0.52      0.60      0.56     17218\n","\n","    accuracy                           0.55     49570\n","   macro avg       0.44      0.55      0.43     49570\n","weighted avg       0.66      0.55      0.59     49570\n"," \n","\n","\n","The accuracy, F1score (macro average), recall (macro average) \u001b[1mfor test set\u001b[0m are:\n","              precision    recall  f1-score   support\n","\n","           0       0.09      0.71      0.16       510\n","           1       0.84      0.53      0.65      9471\n","           2       0.42      0.43      0.43      2303\n","\n","    accuracy                           0.52     12284\n","   macro avg       0.45      0.56      0.41     12284\n","weighted avg       0.73      0.52      0.59     12284\n"," \n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYgAAAEjCAYAAAAomJYLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npZRSTv0/IEQrYO9WKsoAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"JPFdYlpd1HHx","colab_type":"text"},"source":["<a href=\"https://ibb.co/zWM13CT\"><img src=\"https://i.ibb.co/dsTSNXw/Screenshot-from-2020-01-28-23-22-07.png\" alt=\"Screenshot-from-2020-01-28-23-22-07\" border=\"0\"></a>\n","<a href=\"https://ibb.co/TRSV4Gq\"><img src=\"https://i.ibb.co/4MG68Lg/Screenshot-from-2020-01-28-23-21-28.png\" alt=\"Screenshot-from-2020-01-28-23-21-28\" border=\"0\"></a>\n","<a href=\"https://ibb.co/nnTHgpB\"><img src=\"https://i.ibb.co/BrmXzkG/Screenshot-from-2020-01-28-23-20-25.png\" alt=\"Screenshot-from-2020-01-28-23-20-25\" border=\"0\"></a>\n","\n","Και προέκυψε η εξής γραφική απεικόνιση:\n","\n","<a href=\"https://ibb.co/YLYR3CG\"><img src=\"https://i.ibb.co/Js0BK1P/Figure-1.png\" alt=\"Figure-1\" border=\"0\"></a>"]},{"cell_type":"markdown","metadata":{"id":"usSf8X6w2BFZ","colab_type":"text"},"source":["<font size=\"4\"><b>  Ερώτημα 6.2 </b></font>\n","<br>\n","\n","__Σε ποιες περιπτώσεις θα μπορούσαν τα BoW χαρακτηριστικά να οδηγήσουν σε καλύτερα αποτελέσματα σε σχέση με αναπαραστάσεις όπως ο μέσος όρος των word embeddings?__\n","\n","Η μέθοδος Bag of Words δημιουργεί ορισμένους περιορισμούς, όπως είναι η αραιή αναπαράσταση πινάκων (sparse tables) και η μεγάλη διάσταση χαρακτηριστικών (large dimension features). Από την άλλη, τα word embendings δίνουν εν γένει πυκνές (dense) αναπαραστάσεις και μικρότερες διαστάσεις διανυσμάτων, με αποτέλεσμα να αποτελούν ένα από τα πιο κατάλληλα εργαλεία στον τομέα της επεξεργασίας φωνής και φυσικής γλώσσας. Ωστόσο, τα word embendings λειτουργούν πολύ καλά όταν εκπαιδεύονται πάνω σε μεγάλο πλήθος δεδομένων, δηλαδή όταν το dataset είναι μεγάλο. Τότε μπορούν να προσομοιώσουν πολύ αποτελεσματικά την σημασιολογική απόσταση των λέξεων διατηρώντας διανύσματα μικρών διαστάσεων. Το πρόβλημα εμφανίζεται __όταν το dataset είναι μικρό και το context είναι domain specific__. Στην περίπτωση αυτή, το πλήθος των δεδομένων δεν είναι αρκετό για να γίνει το feature extraction σωστά και τα word embendings αποτυνχάνουν σε σχέση με το Βag of Words που δεν επηρεάζεται. Με άλλα λόγια, όταν το dataset είναι μικρό τα word embeddings θα είναι προεκπαιδευμένα σε διαφορετικό context, συνήθως πιο γενικό, με αποτέλεσμα να μην εκφράχονται σωστά οι ερμηνείες και οι σημασιολογικές σχέσεις των λέξεων στο συγκεκριμένο domain του dataset. Αντίθετα, χρησιμοποιώντας BoW παίρνουμε πιο συγκεκριμένη πληροφορία για τις λέξεις σε αυτό το context και παράλληλα αφού έχουμε μικρό dataset δεν έχουμε θέμα με τους αραιούς πίνακες που θα δημιουργηθούν. __Συμπερασματικά, όταν θέλουμε να κάνουμε classification σε ένα μικρό πλήθος λέξεων είναι προτιμότερο να χρησιμοποιήσουμε ως γνώμονα τις συχνότερα εμφανιζόμενες λέξεις, κάτι το οποίο κάνει το ΒοW.__"]},{"cell_type":"markdown","metadata":{"id":"Q4u7dodG2mYg","colab_type":"text"},"source":["Για λόγους πληρότητας παραθέτουμε και τον κώδικα της main.py\n","```python\n","import os\n","import warnings\n","\n","from sklearn.exceptions import UndefinedMetricWarning\n","from sklearn.preprocessing import LabelEncoder\n","import torch\n","from torch.utils.data import DataLoader\n","import numpy as np\n","from config import EMB_PATH\n","from dataloading import SentenceDataset\n","from models import BaselineDNN # Prep\n","from models_1_1 import OptimizedDNN # Lab3.1.1\n","from models_2_1 import BaselineLSTM # Lab3.2.1\n","from models_2_2 import OptimizedLSTM # Lab3.2.2\n","from models_3_1 import AttentionDNN # Lab3.3.1\n","from models_3_2 import AttentionLSTM # Lab3.3.2\n","from models_4_1 import OptimizedBiLSTM # Lab3.4.1\n","from models_4_2 import AttentionBiLSTM # Lab3.4.2\n","from models_6_1 import BOW_LSTM # Lab3.6.1\n","from training import train_dataset, eval_dataset\n","from utils.load_datasets import load_MR, load_Semeval2017A\n","from utils.load_embeddings import load_word_vectors\n","from nltk.tokenize import word_tokenize\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import classification_report\n","import sys\n","import json\n","from nltk.tokenize import TweetTokenizer\n","\n","warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n","\n","########################################################\n","# Configuration\n","########################################################\n","\n","\n","# Download the embeddings of your choice\n","# for example http://nlp.stanford.edu/data/glove.6B.zip\n","\n","# 1 - point to the pretrained embeddings file (must be in /embeddings folder)\n","EMBEDDINGS = os.path.join(EMB_PATH, \"glove.6B.50d.txt\")\n","\n","# 2 - set the correct dimensionality of the embeddings\n","EMB_DIM = 50\n","\n","EMB_TRAINABLE = False\n","BATCH_SIZE = 128\n","EPOCHS = 50\n","DATASETS = [\"Semeval2017A\"]\n","\n","# if your computer has a CUDA compatible gpu use it, otherwise use the cpu\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","########################################################\n","# Define PyTorch datasets and dataloaders\n","########################################################\n","\n","# load word embeddings\n","print(\"loading word embeddings...\")\n","word2idx, idx2word, embeddings = load_word_vectors(EMBEDDINGS, EMB_DIM)\n","\n","# load the raw data\n","for DATASET in DATASETS:\n","    if DATASET == \"Semeval2017A\":\n","        X_train, y_train, X_test, y_test = load_Semeval2017A()\n","    elif DATASET == \"MR\":\n","        X_train, y_train, X_test, y_test = load_MR()\n","    else:\n","        raise ValueError(\"Invalid dataset\")\n","\n","    # convert data labels from strings to integers\n","    le = LabelEncoder()\n","\n","    y_train = le.fit_transform(y_train)  # EX1\n","    y_test = le.fit_transform(y_test)    # EX1\n","    n_classes = le.classes_.size         # EX1\n","\n","    #print(\"------------------- EX1 -\", DATASET, \"-------------------\")\n","    #print(\"The first 10 unencoded labels from the training set are: \")\n","    #print(le.inverse_transform(y_train[:10]))\n","    #print(\"The first 10 encoded labels from the training set are: \")\n","    #print(y_train[:10],\"\\n\")\n","\n","    # Define our PyTorch-based Dataset\n","    bow = sys.argv[2] #Lab3.6.1\n","    train_set = SentenceDataset(X_train, y_train, word2idx, DATASET, bow)\n","    test_set = SentenceDataset(X_test, y_test, word2idx, DATASET, bow)\n","    \n","    #print(\"------------------- EX2 -\", DATASET, \"-------------------\")\n","    #print(\"The first 10 examples from training set are: \")\n","    #print(train_set.data[:10],\"\\n\")\n","    \n","    #print(\"------------------- EX3 -\", DATASET, \"-------------------\")\n","    #for i in range(5):\n","        #print('dataitem = \"', X_train[i], '\", label = \"', le.inverse_transform(y_train).item(i), '\"\\n')\n","        #print(\"Return values:\")\n","        #print(\"example = \", train_set[i][0])\n","        #print(\"label = \", train_set[i][1])\n","        #print(\"length = \", train_set[i][2], \"\\n\")\n","    \n","    #la = torch.FloatTensor(train_set[0][3])\n","    #import pdb; pdb.set_trace()\n","    # EX7 - Define our PyTorch-based DataLoader\n","    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) # EX7\n","    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True) # EX7\n","\n","    #############################################################################\n","    # Model Definition (Model, Loss Function, Optimizer)\n","    #############################################################################\n","    model_name = sys.argv[1] # Lab3.1.1 - Lab3.4.2\n","    model = eval(model_name)(output_size=n_classes, embeddings=embeddings, trainable_emb=EMB_TRAINABLE) # EX8\n","\n","    # move the mode weight to cpu or gpu\n","    model.to(DEVICE)\n","    # save the model - Only for 5.1 question\n","    '''torch.save(model, model_name+'.pt')'''\n","    print(model)\n","\n","    # We optimize ONLY those parameters that are trainable (p.requires_grad==True)\n","    criterion = torch.nn.BCEWithLogitsLoss() if n_classes == 2 else torch.nn.CrossEntropyLoss() # EX8\n","    parameters = []  # EX8\n","    for param in model.parameters():  # EX8\n","        if param.requires_grad == True: parameters.append(param)  # EX8\n","    optimizer = torch.optim.Adam(parameters, lr = 0.0001) # EX8\n","\n","    #############################################################################\n","    # Training Pipeline\n","    #############################################################################\n","    trainning_loss = []\n","    testing_loss = []\n","    for epoch in range(1, EPOCHS + 1):\n","        # train the model for one epoch\n","        train_dataset(epoch, train_loader, model, criterion, optimizer)\n","\n","        # evaluate the performance of the model, on both data sets\n","        train_loss, (y_train_gold, y_train_pred) = eval_dataset(train_loader, model, criterion)\n","        '''train_loss, (y_train_gold, y_train_pred), y_train_post, y_train_scores = eval_dataset(train_loader, model, criterion) #lab3.5'''\n","\n","        test_loss, (y_test_gold, y_test_pred) = eval_dataset(test_loader, model, criterion)\n","        '''test_loss, (y_test_gold, y_test_pred), y_test_post, y_test_scores = eval_dataset(test_loader, model, criterion) #lab3.5'''\n","\n","        # make list of losses to plot them\n","        trainning_loss.append(train_loss)\n","        testing_loss.append(test_loss)\n","\n","    print(\"----------------- Results for \", DATASET, \" dataset -----------------\")\n","    print(\"The trainning loss is: \", train_loss)\n","    print(\"The testing loss is: \", test_loss)\n","    print(\"The accuracy, F1score (macro average), recall (macro average) \\033[1mfor train set\\033[0m are:\")\n","    y_train_gold = np.concatenate(y_train_gold, axis=0)\n","    y_test_gold = np.concatenate(y_test_gold, axis=0)\n","    y_train_pred = np.concatenate(y_train_pred, axis=0)\n","    \n","    y_test_pred = np.concatenate(y_test_pred, axis=0) \n","    '''y_test_post = np.concatenate(y_test_post, axis=0) #lab3.5.2\n","    y_test_scores = np.concatenate(y_test_scores, axis=0) #lab3.5.2'''\n","    \n","    print(classification_report(y_train_gold, y_train_pred), \"\\n\\n\")\n","    print(\"The accuracy, F1score (macro average), recall (macro average) \\033[1mfor test set\\033[0m are:\")\n","    print(classification_report(y_test_gold, y_test_pred), \"\\n\")\n","    \n","    # create predictions txt file - Only for question 5\n","    '''with open(model_name+'_predictions.txt', 'w') as f:\n","        for i in y_test_pred:\n","            f.write(str(int(i)) + '\\n')'''\n","    \n","    # create .json file - Only for question 5\n","    '''tokenizer = TweetTokenizer()\n","    token_text = [tokenizer.tokenize(example) for example in X_test]\n","           \n","    with open(model_name+'.json', 'w') as f:\n","        all_data = []\n","        for i in range(len(test_set)):\n","            jsn_d ={}\n","            jsn_d['text'] = token_text[i]\n","            jsn_d['label'] = int(test_set[i][1])\n","            jsn_d['prediction'] = int(y_test_pred[i])\n","            jsn_d['posterior'] = y_test_post[i].tolist()\n","            jsn_d['attention'] = y_test_scores[i].tolist()\n","            jsn_d['id'] = i\n","            all_data.append(jsn_d)\n","        json.dump(all_data, f)'''\n","    \n","\n","    #fig = plt.figure()\n","    plt.plot(trainning_loss, '-o', color = \"r\", label = \"Training data\")\n","    plt.plot(testing_loss, '-o', color = \"g\", label = \"Testing data\")\n","    plt.suptitle('Learning Curve')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","```"]},{"cell_type":"code","metadata":{"id":"dlfiocJY386Z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}