{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Εθνικό Μετσόβιο Πολυτεχνείο\n",
    "### Σχολή Ηλεκτρολόγων Μηχανικών και Μηχανικών Υπολογιστών\n",
    "### Τομέας Σημάτων, Ελέγχου και Ρομποτικής\n",
    "### Εργαστήριο Όρασης Υπολογιστών, Επικοινωνίας Λόγου και Επεξεργασίας Σημάτων\n",
    "### Επεξεργασία Φωνής και Φυσικής Γλώσσας"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------- 2ο Εργαστήριο: Αναγνώριση φωνής με το KALDI TOOLKIT --------------------------\n",
    "##### Ακ. Έτος: 2019 - 2020      -      Εξάμηνο: 7o\n",
    "\n",
    "#### Βασιλείου Βασιλική - 03115033                 Ψαρουδάκης Ανδρέας - 03116001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___1. Περιγραφή___\n",
    "\n",
    "Σκοπός της παρούσας εργαστηριακής άσκησης είναι η χρήση του εργαλείου __Kaldi__ για την υλοποίηση ενός συστήματος επεξεργασίας και αναγνώρισης φωνής. Συγκεκριμένα,ως δεδομένα, έχουμε ηχογραφήσεις της USC-TIMIT από 4 διαφορετικούς ομιλητές αλλά και τα transcriptions, ώστε να εκπαιδεύσουμε και να εκτιμήσουμε το σύστημα μας. Η διαδικασία σχεδιασμού του συστήματος μπορεί να χωριστεί σε 4 μέρη. Αρχικά, καλούμαστε να εξάγουμε κατάλληλα ακουστικά χαρακτηριστικά από τα φωνητικά δεδομένα - MFCCs (Mel-Frequency Cepstral Coefficients). Τα εν λόγω χαρακτηριστικά είναι στην ουσία ένας αριθμός συντελεστών cepstrum που εξάγονται μετά από ανάλυση των σημάτων φωνής με μια ειδικά σχεδιασμένη συστοιχία φίλτρων (Mel filterbank). Η συστοιχία αυτή είναι εμπνευσμένη από το μη γραμμικό τρόπο που το ανθρώπινο αυτί αντιλαβάνεται τον ήχο και ειδικά σχεδιασμένη από ψυχοακουστικές μελέτες. Στη συνέχεια, δημιουργούμε γλωσσικά μοντέλα από τα trancriptions που προαναφέραμε, τα οποία θα δίνουν την a priori πιθανότητα στο τελικό σύστημα. Ακολουθεί η εκπαίδευση των ακουστικών μοντέλων με βάση τα MFCCs που εξάγαμε. Συνδυάζοντας εν τέλει όλα τα προηγούμενα, σχηματίζουμε το τελικό σύστημα αναγνώρισης φωνής. Συμπερασματικά, γίνεται κατανοητό ότι καλούμαστε να δημιουργήσουμε ένα σύστημα αναγνώρισης φωνής που δέχεται ως είσοδο ένα σήμα φωνής, βρίσκει τα ακουστικά χαρακτηριστικά και τα χρησιμοποιεί για να αποκωδικοποιήσει το σήμα σε μία ακολουθία φωνημάτων ή λέξεων."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Θεωρητικό Υπόβαθρο\n",
    "\n",
    "### A) __MFCCs__\n",
    "Όπως αναφέραμε και στην περιγραφή η πρώτη φάση της διαδικασίας σχεδιασμού ενός συστήματος επεξεργασίας και αναγνώρισης φωνής είναι η εξαγωγή φωνητικών δεδομένων MFCCs. Η εξαγωγή αυτή γίνεται σε πέντε στάδια, τα οποία αναλυτικά είναι:\n",
    "1. ___Προέμφαση (Pre-Emphasis):___ Μέσω αυτής επιτυγχάνουμε α) ισορροπία του φάσματος συχνοτήτων, δεδομένου ότι οι υψηλές συχνότητες έχουν συνήθως μικρότερα μεγέθη σε σύγκριση με χαμηλότερες συχνότητες, β) αποφυγή των αριθμητικών προβλημάτων κατά τη διάρκεια του μετασχηματισμού Fourier και γ) βελτίωση του σηματοθορυβικού λόγου (SNR).          \n",
    "Το φίλτρο αυτό εφαρμόζεται στο σήμα μέσω της εξίσωσης: $ y(t)=x(t)−αx(t−1)$.\n",
    "\n",
    "\n",
    "2. ___Πλαισίωση (Framing) & Παραθυροποίηση (Windowing):___ Η πλαισίωση αποτελεί ένα σημαντικό στάδιο καθώς μέσω αυτής \"σπάμε\" το σήμα σε μικρότερα πλαίσια και στη συνέχεια εφαρμόζουμε μετασχηματιμό Fourier σε αυτά. Σε αντίθετη περίπτωση, επειδή οι συχνότητες αλλάζουν διαρκώς με τον χρόνο, αν εφαρμόζαμε μετασχηματισμό Fourier σε ολόκληρο το σήμα θα χάναμε σημαντική πληροφορία (frequency contours). Στο σημείο αυτό αξίζει να αναφέρουμε ότι η πλαισίωση γίνεται σε πλαίσια 20 ~ 40 ms με overlap γύρω στο 50%. Στη συνέχεια για να αντισταθμίσουμε την παραδοχή του FFT ότι τα δεδομένα είναι άπειρα και για να μειώσουμε την φασματική διαρροή εφαρμόζουμε κάποιο παράθυρο στα πλαίσια. Η πιο συνηθισμένη παραθυροποίηση που χρησιμοποείται είναι τα hamming παράθυρα. Ένα παράθυρο Hamming έχει την ακόλουθη μορφή: \n",
    "\n",
    "$$ w(n) = 0.54 - 0.46cos\\left(\\frac{2\\pi{n}}{M-1}\\right) \\qquad 0 \\leq n \\leq M-1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import fft, fftshift\n",
    "window = np.hamming(51)\n",
    "plt.plot(window)\n",
    "plt.title(\"Hamming window\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ___Fourier-Transform && Power Spectrum:___ Αρχικά υπολογίζουμε το φάσμα συχνοτήτων και στη συνέχεια το χρησιμοποιούμε για να υπολογίσμουμε το φάσμα ισχύος, το οποίο δίνεται από την σχέση: \n",
    "$$ P = \\frac{|FFT(x_i)|^2}{N} $$\n",
    "\n",
    "\n",
    "4. ___Filter Banks:___ Για να εφαρμόσουμε τα Filter Banks πρέπει αρχικά να εφαρμόσουμε κάποια τριγωνικά φίλτρα (συνήθως 40). Χρησιμοποιούμε την κλίμακα Mel προσπαθώντας να προσομοιώσουμε την αντίληψη του ήχου από τον άνθρωπο. Αυτό επιτυγχάνεται καθιστώντας πιο διακριτικές τις χαμηλότερες συχνότητες και λιγότερο διακριτικές τις υψηλότερες συχνότητες. Η μετατροπή στην κλίμακα Mel γίνεται με τις ακόλουθες σχέσεις: \n",
    "\n",
    "$$ m = 2595 \\log_{10} (1 + \\frac{f}{700}) $$ $$ f = 700 (10^{m/2595} - 1) $$\n",
    "\n",
    "\n",
    "5. ___Discrete cosine transform:___ Οι συντελεστές που υπολογίστηκαν στο προηγούμενο βήμα είναι πολύ συσχετισμένοι, οπότε εφαρμόζουμε τον DCT για να μειώσουμε την συσχέτιση αυτή που μπορεί να προκαλέσει προβλήματα.\n",
    "\n",
    "Όλα τα προηγούμενα βήματα φαίνονται στην επόμενη εικόνα:\n",
    "\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/R26Fx47/Screenshot-2019-12-28-Microsoft-Word-27-NVEC10086-27-NVEC10086-pdf.png\" alt=\"Screenshot-2019-12-28-Microsoft-Word-27-NVEC10086-27-NVEC10086-pdf\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __B) Γλωσσικά Μοντέλα__\n",
    "\n",
    "Τα γλωσσικά μοντέλα ορίζουν πιθανότητες ακολουθιών λέξεων (a-priori) με βάση το likelihood της συγκεκριμένης ακολουθίας στο εξεταζόμενο dataset από το μοντέλο αναγνώρισης μας. Ο σκοπός του γλωσσικού μοντέλου ή της γραμματικής είναι να επιτρέψει τον υπολογισμό της a priori πιθανότητας, $P_L(W)$, μιας λέξης συμβολοσειράς, $W$, σύμφωνα με την εργασία αναγνώρισης. Για την δημιουργία γλωσσικού μοντέλου χρησιμοποιούμε μια στατιστική γραμματική. Για κάθε πρόταση στο σύνολο εκπαίδευσης, έχουμε ένα αρχείο κειμένου που προσδιορίζει τις λέξεις αυτής της πρότασης. Εάν κάνουμε την υπόθεση ότι η πιθανότητα μιας λέξης σε μια πρόταση εξαρτάται μόνο από τις προηγούμενες λέξεις N-1, έχουμε τη βάση για ένα μοντέλο γλωσσών N-gram. Στην περίπτωση μας κάνουμε αναγωγή της προηγούμενης περιγραφής σε φωνήματα και λέξεις αντίστοιχα. Τέλος σημειώνουμε ότι θα αχοληθούμε με unigram και bigram μοντέλα τα οποία το Kaldi Tool θα συνδυάσει προκειμένου να έχουμε τα βέλτιστα αποτελέσματα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Γ) Φωνητικά Μοντέλα__\n",
    "\n",
    "Τα φωνητικά μοντέλα χρησιμοποιούνται για τον υπολογισμό της δεσμευμένης πιθανότητας του κριτηρίου likelihood. Η ακουστική εκπαίδευση (ΑΜ) βασίζεται σε φράσεις ομιλίας με ετικέτες που είναι ταξινομημένες σύμφωνα με το αντίστοιχο transcription. Στην πλειονότητα των περιπτώσεων χρησιμοποιούμε Κρυφά Μαρκοβιανά Μοντέλα (HMM) για κάθε φώνημα. Συνεπώς το HMM της λέξης είναι η σύνδεση των HMM των φωνημάτων και αντίστοιχα το HMM των συμβολοσειρών είναι η συνένωση των HMMs των λέξεων που τις απαρτίζουν. Ένα παράδειγμα 5 καταστάσεων αριστερά προς τα δεξιά HMM φαίνεται στην επόμενη εικόνα:\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/FVyrCXH/Screenshot-2019-12-28-MC-He-Ch02-indd-MC-He-Ch02-pdf.png\" alt=\"Screenshot-2019-12-28-MC-He-Ch02-indd-MC-He-Ch02-pdf\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Βήματα προπαρασκευής\n",
    "\n",
    "Για την προπαρασκευή του εργαστηρίου αφού ακολουθήσαμε τις οδηγίες για την εγκατάσταση του kaldi στη συνέχεια κατεβάσαμε τα δεδομένα που χρειαζόμαστε για την εκτέλεση της εργαστηριακής άσκησης. Σημειώνουμε ότι όλα τα δεδομένα και οι κώδικες της παρούσας εργαστηριακής άσκησης βρίσκονται στο directory: ___~/Documents/SLP_Lab2/kaldi___. Αρχικά, μέσα στο φάκελο egs δημιουργούμε ένα φάκελο usc, μέσα στον οποίο θα εργάζόμαστε από εδώ και πέρα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usc folder is ok\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/Documents/SLP_Lab2/kaldi/egs/usc\n",
    "!echo \"usc folder is ok\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all necessary folders are ok\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/Documents/SLP_Lab2/kaldi/egs/usc/data\n",
    "!mkdir ~/Documents/SLP_Lab2/kaldi/egs/usc/data/train\n",
    "!mkdir ~/Documents/SLP_Lab2/kaldi/egs/usc/data/test\n",
    "!mkdir ~/Documents/SLP_Lab2/kaldi/egs/usc/data/dev\n",
    "!echo \"all necessary folders are ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στη συνέχεια αντιγράφουμε τους φακέλους lab2_help_scripts και slp_lab2_data στο directory που δημιουργήσαμε (για την δικιά μας περίπτωση είναι ___~/Documents/SLP_Lab2/kaldi/egs/usc___). Αντιγράφουμε επίσης τα python και bash scripts που υλοποιήσαμε για την εκτέλεση των υπολοίπων βημάτων της εργαστηριακής άσκησης. Τα script αυτά σας επισυνάπτονται στον φάκελο με τα παραδοτέα. Έχοντας πλέον όλα τα απαραίτητα αρχεία καλούμε το 3.sh bash script που δημιουργήσαμε για την υλοποίηση του παρόντος βήματος."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all uttids files are ok\n",
      "all utt2spk files are ok\n",
      "all wav.scp files are ok\n",
      "all text files are ok\n",
      "all new text files are ok\n",
      "Step 3 is OK!\n"
     ]
    }
   ],
   "source": [
    "!~/Documents/SLP_Lab2/kaldi/egs/usc/3.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To script 3.sh υλοποιεί αναλυτικά όσα ζητούνται στο βήμα 3. Συγκεκριμένα για την δημιουργία των:\n",
    "* ___uttids___ αρχείων αντιγράφουμε το περιεχόμενο των αντίστοιχων φακέλων των δεδομένων μας μέσω της εντολής ___cat___.\n",
    "* ___utt2spk___ αρχείων υλοποιήσαμε το utt2spk.py script που σε κάθε γραμμή γράφει τον ομιλητή που αντιστοιχεί σε κάθε πρόταση και είναι της μορφής: utterance_id_1 <κενό> speaker_id, όπου ως speaker_id επιλέγουμε αντίστοιχα τα m1, m3, f1, f5.\n",
    "* ___wav.scp___ αρχείων υλοποιήσαμε το wav_scp.py script που σε κάθε γραμμή γράφει τη θέση του αρχείου ήχου και είναι της μορφής:                                                                                                                                 \n",
    "utterance_id_1 <κενό> /path/to/wav1.\n",
    "* ___text___ αρχείων υλοποιήσαμε το text.py script που σε κάθε γραμμή γράφει το κείμενο που αντιστοιχεί στην κάθε πρόταση και είναι της μορφής: utterance_id_1 <κενό> <utterance 1 text>.\n",
    "\n",
    "Στη συνέχεια για κάθε αρχείο text που δημιουργούμε αντικαθιστούμε τις λέξεις που περιέχουν οι προτάσεις με τις αντίστοιχες αλληλουχίες φωνημάτων. Για την υλοποίηση αυτού δημιουργήσαμε το script text_to_phonem.py στο οποίο αρχικά δημιουργούμε με βάση το αρχείο lexicon.txt ένα dictionary μεταξύ των λέξεων και της αντίστοιχης αλληλουχίας φωνημάτων. Στη συνέχεια, υλοποιούμε την συνάρτηση tokenize ωστε να μετατρέψουμε όλους τους χαρακτήρες σε πεζούς, να αφαιρέσουμε όλους τους ειδικούς χαρακτήρες εκτός από την απόστροφο καθώς και να σπάσουμε λέξεις που ενώνονται με - ώστε να μπορέσουμε να τις διαχειριστούμε στη συνέχεια. Τέλος, κάθε πρόταση του εκάστωτε αρχείου text την περνάμε από την συνάρτηση tokenize, γράφουμε στην αρχή το φώνημα της σιωπής ακολουθούν οι αλληλουχίες φωνημάτων και τέλος ξανά το φώνημα της σιωπής. Τα παραπάνω αποθηκεύονται στα αρχεία new_text.\n",
    "Τελικά, διαγράφουμε τα αρχικά αρχεία text, μετονομάζουμε τα αρχεία new_text σε text και τυπώνουμε μήνυμα ότι το βήμα 3 ολοκληρώθηκε επιτυχώς!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Βήματα κυρίως μέρους\n",
    "### 4.1 Προετοιμασία διαδικασίας αναγνώρισης φωνής για τη USC-TIMIT\n",
    "\n",
    "Από τη διαδικασία για τη Wall Street Journal (wsj) που βρίσκεται στο φάκελο egs παίρνουμε τα αρχεία path.sh και cmd.sh. Στο αρχείο path.sh πρέπει να θέσουμε τη μεταβλητή KALDI_ROOT στο directory που βρίσκεται ο κύριος φάκελος της εγκατάστασης του Kaldi ενώ στο cmd.sh αλλάζουμε τις τιμές των μεταβλητών train_cmd, decode_cmd και cuda_cmd σε ’run.pl’. Αντιγράφουμε τα νέα αρχεία στο ___~/Documents/SLP_Lab2/kaldi/egs/usc___. Έχοντας πλέον όλα τα απαραίτητα αρχεία καλούμε το 4_1.sh bash script που δημιουργήσαμε για την υλοποίηση του παρόντος βήματος."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We make file path.sh as source so that we have all kaldi commands available\n",
      "We create soft links for the folders steps and utils\n",
      "We create a folder local and inside it we create a soft link for the the file score_kaldi.sh\n",
      "We create a folder conf and inside it we copy the file mfcc.conf\n",
      "We create a folder lang and a folder local inside folder data. Inside folder local we create folders dict, lm_tmp and nist_lm\n"
     ]
    }
   ],
   "source": [
    "!~/Documents/SLP_Lab2/kaldi/egs/usc/4_1.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το script αυτό υλοποιεί τα παρακάτω ζητούμενα του βήματος αυτού:\n",
    "1. Δημιουργείστε soft links μέσα στο φάκελο της δικής σας διαδικασίας με ονόματα ’steps’ και ’utils’ τα οποία θαδείχνουν στους αντίστοιχους φακέλους της wsj.\n",
    "2. Δημιουργείστε το φάκελο local και μέσα σε αυτόν ένα soft link που να δείχνει στο αρχείο score_kaldi.sh που βρίσκεται μέσα στο ’steps’.\n",
    "3. Δημιουργείστε το φάκελο conf και μέσα σε αυτόν αντιγράψτε το αρχείο mfcc.conf που σας δώθηκε στις διευκρινίσεις.\n",
    "4. Τέλος, δημιουργείστε τους εξής φακέλους:data/lang,data/local/dict,data/local/lm_tmp,data/local/nist_lm.\n",
    "\n",
    "Σημειώνουμε ότι το path.sh αρχείο το κάνουμε source στην αρχή κάθε bash script μας από εδώ και πέρα, ώστε να έχουμε διαθέσιμες όλες τις εντολές του Kaldi. Επίσης για την δημιουργία soft links χρησιμοποιούμε την εντολή ln -s του bash, ενώ για την αντιγραφή ενός αρχείου χρησιμοποιούμε την εντολή cp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Προετοιμασία γλωσσικού μοντέλου"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside folder local/data/dict we create files silence_phones.txt and optional_silence.txt that contain only the phonem sil\n",
      "LOGFILE:/dev/null\n",
      "$bin/ngt -i=\"$inpfile\" -n=$order -gooout=y -o=\"$gzip -c > $tmpdir/ngram.${sdict}.gz\" -fd=\"$tmpdir/$sdict\" $dictionary $additional_parameters >> $logfile 2>&1\n",
      "$scr/build-sublm.pl $verbose $prune $prune_thr_str $smoothing \"$additional_smoothing_parameters\" --size $order --ngrams \"$gunzip -c $tmpdir/ngram.${sdict}.gz\" -sublm $tmpdir/lm.$sdict $additional_parameters >> $logfile 2>&1\n",
      "$scr/build-sublm.pl $verbose $prune $prune_thr_str $smoothing \"$additional_smoothing_parameters\" --size $order --ngrams \"$gunzip -c $tmpdir/ngram.${sdict}.gz\" -sublm $tmpdir/lm.$sdict $additional_parameters >> $logfile 2>&1\n",
      "LOGFILE:/dev/null\n",
      "$bin/ngt -i=\"$inpfile\" -n=$order -gooout=y -o=\"$gzip -c > $tmpdir/ngram.${sdict}.gz\" -fd=\"$tmpdir/$sdict\" $dictionary $additional_parameters >> $logfile 2>&1\n",
      "$bin/ngt -i=\"$inpfile\" -n=$order -gooout=y -o=\"$gzip -c > $tmpdir/ngram.${sdict}.gz\" -fd=\"$tmpdir/$sdict\" $dictionary $additional_parameters >> $logfile 2>&1\n",
      "$scr/build-sublm.pl $verbose $prune $prune_thr_str $smoothing \"$additional_smoothing_parameters\" --size $order --ngrams \"$gunzip -c $tmpdir/ngram.${sdict}.gz\" -sublm $tmpdir/lm.$sdict $additional_parameters >> $logfile 2>&1\n",
      "LOGFILE:/dev/null\n",
      "$bin/ngt -i=\"$inpfile\" -n=$order -gooout=y -o=\"$gzip -c > $tmpdir/ngram.${sdict}.gz\" -fd=\"$tmpdir/$sdict\" $dictionary $additional_parameters >> $logfile 2>&1\n",
      "$bin/ngt -i=\"$inpfile\" -n=$order -gooout=y -o=\"$gzip -c > $tmpdir/ngram.${sdict}.gz\" -fd=\"$tmpdir/$sdict\" $dictionary $additional_parameters >> $logfile 2>&1\n",
      "$scr/build-sublm.pl $verbose $prune $prune_thr_str $smoothing \"$additional_smoothing_parameters\" --size $order --ngrams \"$gunzip -c $tmpdir/ngram.${sdict}.gz\" -sublm $tmpdir/lm.$sdict $additional_parameters >> $logfile 2>&1\n",
      "$scr/build-sublm.pl $verbose $prune $prune_thr_str $smoothing \"$additional_smoothing_parameters\" --size $order --ngrams \"$gunzip -c $tmpdir/ngram.${sdict}.gz\" -sublm $tmpdir/lm.$sdict $additional_parameters >> $logfile 2>&1\n",
      "LOGFILE:/dev/null\n",
      "$bin/ngt -i=\"$inpfile\" -n=$order -gooout=y -o=\"$gzip -c > $tmpdir/ngram.${sdict}.gz\" -fd=\"$tmpdir/$sdict\" $dictionary $additional_parameters >> $logfile 2>&1\n",
      "$scr/build-sublm.pl $verbose $prune $prune_thr_str $smoothing \"$additional_smoothing_parameters\" --size $order --ngrams \"$gunzip -c $tmpdir/ngram.${sdict}.gz\" -sublm $tmpdir/lm.$sdict $additional_parameters >> $logfile 2>&1\n",
      "LOGFILE:/dev/null\n",
      "$bin/ngt -i=\"$inpfile\" -n=$order -gooout=y -o=\"$gzip -c > $tmpdir/ngram.${sdict}.gz\" -fd=\"$tmpdir/$sdict\" $dictionary $additional_parameters >> $logfile 2>&1\n",
      "$scr/build-sublm.pl $verbose $prune $prune_thr_str $smoothing \"$additional_smoothing_parameters\" --size $order --ngrams \"$gunzip -c $tmpdir/ngram.${sdict}.gz\" -sublm $tmpdir/lm.$sdict $additional_parameters >> $logfile 2>&1\n",
      "LOGFILE:/dev/null\n",
      "$bin/ngt -i=\"$inpfile\" -n=$order -gooout=y -o=\"$gzip -c > $tmpdir/ngram.${sdict}.gz\" -fd=\"$tmpdir/$sdict\" $dictionary $additional_parameters >> $logfile 2>&1\n",
      "$bin/ngt -i=\"$inpfile\" -n=$order -gooout=y -o=\"$gzip -c > $tmpdir/ngram.${sdict}.gz\" -fd=\"$tmpdir/$sdict\" $dictionary $additional_parameters >> $logfile 2>&1\n",
      "$scr/build-sublm.pl $verbose $prune $prune_thr_str $smoothing \"$additional_smoothing_parameters\" --size $order --ngrams \"$gunzip -c $tmpdir/ngram.${sdict}.gz\" -sublm $tmpdir/lm.$sdict $additional_parameters >> $logfile 2>&1\n",
      "$scr/build-sublm.pl $verbose $prune $prune_thr_str $smoothing \"$additional_smoothing_parameters\" --size $order --ngrams \"$gunzip -c $tmpdir/ngram.${sdict}.gz\" -sublm $tmpdir/lm.$sdict $additional_parameters >> $logfile 2>&1\n",
      "inpfile: data/local/lm_tmp/lm_dev_unigram.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Saving in txt format to /dev/stdout\n",
      "inpfile: data/local/lm_tmp/lm_dev_bigram.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Saving in txt format to /dev/stdout\n",
      "inpfile: data/local/lm_tmp/lm_train_unigram.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Saving in txt format to /dev/stdout\n",
      "inpfile: data/local/lm_tmp/lm_train_bigram.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Saving in txt format to /dev/stdout\n",
      "inpfile: data/local/lm_tmp/lm_test_unigram.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Saving in txt format to /dev/stdout\n",
      "inpfile: data/local/lm_tmp/lm_test_bigram.ilm.gz\n",
      "outfile: /dev/stdout\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Saving in txt format to /dev/stdout\n",
      "/home/sila/Documents/SLP_Lab2/kaldi/egs/usc/utils/prepare_lang.sh data/local/dict <oov> data/local/lang data/lang\n",
      "Checking data/local/dict/silence_phones.txt ...\n",
      "--> reading data/local/dict/silence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/local/dict/silence_phones.txt is OK\n",
      "\n",
      "Checking data/local/dict/optional_silence.txt ...\n",
      "--> reading data/local/dict/optional_silence.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/local/dict/optional_silence.txt is OK\n",
      "\n",
      "Checking data/local/dict/nonsilence_phones.txt ...\n",
      "--> reading data/local/dict/nonsilence_phones.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/local/dict/nonsilence_phones.txt is OK\n",
      "\n",
      "Checking disjoint: silence_phones.txt, nonsilence_phones.txt\n",
      "--> disjoint property is OK.\n",
      "\n",
      "Checking data/local/dict/lexicon.txt\n",
      "--> reading data/local/dict/lexicon.txt\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/local/dict/lexicon.txt is OK\n",
      "\n",
      "Checking data/local/dict/extra_questions.txt ...\n",
      "--> data/local/dict/extra_questions.txt is empty (this is OK)\n",
      "--> SUCCESS [validating dictionary directory data/local/dict]\n",
      "\n",
      "**Creating data/local/dict/lexiconp.txt from data/local/dict/lexicon.txt\n",
      "fstaddselfloops data/lang/phones/wdisambig_phones.int data/lang/phones/wdisambig_words.int \n",
      "prepare_lang.sh: validating output directory\n",
      "utils/validate_lang.pl data/lang\n",
      "Checking existence of separator file\n",
      "separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.\n",
      "Checking data/lang/phones.txt ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang/phones.txt is OK\n",
      "\n",
      "Checking words.txt: #0 ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> data/lang/words.txt is OK\n",
      "\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> silence.txt and nonsilence.txt are disjoint\n",
      "--> silence.txt and disambig.txt are disjoint\n",
      "--> disambig.txt and nonsilence.txt are disjoint\n",
      "--> disjoint property is OK\n",
      "\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> found no unexplainable phones in phones.txt\n",
      "\n",
      "Checking data/lang/phones/context_indep.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt\n",
      "--> data/lang/phones/context_indep.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/nonsilence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 160 entry/entries in data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt\n",
      "--> data/lang/phones/nonsilence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 5 entry/entries in data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt\n",
      "--> data/lang/phones/silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/optional_silence.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/disambig.{txt, int, csl} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 2 entry/entries in data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt\n",
      "--> data/lang/phones/disambig.{txt, int, csl} are OK\n",
      "\n",
      "Checking data/lang/phones/roots.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang/phones/roots.txt\n",
      "--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt\n",
      "--> data/lang/phones/roots.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/sets.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 41 entry/entries in data/lang/phones/sets.txt\n",
      "--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt\n",
      "--> data/lang/phones/sets.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/extra_questions.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 9 entry/entries in data/lang/phones/extra_questions.txt\n",
      "--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt\n",
      "--> data/lang/phones/extra_questions.{txt, int} are OK\n",
      "\n",
      "Checking data/lang/phones/word_boundary.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 165 entry/entries in data/lang/phones/word_boundary.txt\n",
      "--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt\n",
      "--> data/lang/phones/word_boundary.{txt, int} are OK\n",
      "\n",
      "Checking optional_silence.txt ...\n",
      "--> reading data/lang/phones/optional_silence.txt\n",
      "--> data/lang/phones/optional_silence.txt is OK\n",
      "\n",
      "Checking disambiguation symbols: #0 and #1\n",
      "--> data/lang/phones/disambig.txt has \"#0\" and \"#1\"\n",
      "--> data/lang/phones/disambig.txt is OK\n",
      "\n",
      "Checking topo ...\n",
      "\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\n",
      "--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols\n",
      "--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\n",
      "--> data/lang/phones/word_boundary.txt is OK\n",
      "\n",
      "Checking word-level disambiguation symbols...\n",
      "--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)\n",
      "Checking word_boundary.int and disambig.int\n",
      "--> generating a 16 word/subword sequence\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\n",
      "--> L.fst is OK\n",
      "--> generating a 53 word/subword sequence\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\n",
      "--> L_disambig.fst is OK\n",
      "\n",
      "Checking data/lang/oov.{txt, int} ...\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\n",
      "--> text contains only allowed whitespaces\n",
      "--> 1 entry/entries in data/lang/oov.txt\n",
      "--> data/lang/oov.int corresponds to data/lang/oov.txt\n",
      "--> data/lang/oov.{txt, int} are OK\n",
      "\n",
      "--> data/lang/L.fst is olabel sorted\n",
      "--> data/lang/L_disambig.fst is olabel sorted\n",
      "--> SUCCESS [validating lang directory data/lang]\n",
      "Preparing train, dev and test data\n",
      "Preparing language models for test\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_test/words.txt - data/lang_test/G_train_unigram.fst \n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 1 to 1\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_test/words.txt - data/lang_test/G_dev_unigram.fst \n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 1 to 1\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_test/words.txt - data/lang_test/G_test_unigram.fst \n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 1 to 1\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_test/words.txt - data/lang_test/G_train_bigram.fst \n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:149) Reading \\2-grams: section.\n",
      "WARNING (arpa2fst[5.5.589~1-1f357]:ConsumeNGram():arpa-lm-compiler.cc:313) line 52 [-2.86686\t<s> <s>] skipped: n-gram has invalid BOS/EOS placement\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 42 to 42\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_test/words.txt - data/lang_test/G_dev_bigram.fst \n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:149) Reading \\2-grams: section.\n",
      "WARNING (arpa2fst[5.5.589~1-1f357]:ConsumeNGram():arpa-lm-compiler.cc:313) line 52 [-1.97068\t<s> <s>] skipped: n-gram has invalid BOS/EOS placement\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 42 to 42\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_test/words.txt - data/lang_test/G_test_bigram.fst \n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:Read():arpa-file-parser.cc:149) Reading \\2-grams: section.\n",
      "WARNING (arpa2fst[5.5.589~1-1f357]:ConsumeNGram():arpa-lm-compiler.cc:313) line 52 [-1.97299\t<s> <s>] skipped: n-gram has invalid BOS/EOS placement\n",
      "LOG (arpa2fst[5.5.589~1-1f357]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 42 to 42\n",
      "Succeeded in formatting data.\n"
     ]
    }
   ],
   "source": [
    "!~/Documents/SLP_Lab2/kaldi/egs/usc/4_2.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όσον αφορά τη δημιουργία του γλωσσικού μοντέλου ___(4.2.1)___ το script αυτό υλοποιεί μέσα στον φάκελο data/local/dict τα επόμενα:\n",
    "* Δημιουργεί τα αρχεία ___silence_phones.txt___ και ___optional_silence.txt___ και γράφει μέσα σε αυτά μόνο το φώνημα της σιωπής χρησιμοποιώντας την bash εντολή echo.\n",
    "* Τρέχει το python script nonsilence_phones.py. Το script αυτό δέχεται ως είσοδο το lexicon.txt των δεδομένων μας και κρατά σε μια λίστα όλα τα φωνήματα που αντιστοιχούν στις λέξεις μόνο μία φορά παραλείποντας συγχρόνως και το φώνημα της σιωπής. Στη συνέχεια ταξινομεί τα φωνήματα αυτά και τα γράφει στο αρχείο ___nonsilence_phones.txt___.\n",
    "* Δημιουργεί το λεξικό του γλωσσικού μας μοντέλου, το οποίο είναι μία 1-1 αντιστοιχία των φωνημάτων με τον εαυτό τους. Αυτό γίνεται μέσω του lexicon.py script που δημιουργήσαμε. Συγκεκριμένα αυτό το script αντιγράφει τα περιεχόμενα του προηγούμενου αρχείου και τα γράφει σε ένα καινούριο δύο φορές με ένα κενό ανάμεσα αφού αρχικά προσθέσει και το φώνημα sil που δεν περιέχεται στο προηγούμενο αρχείο. Έτσι δημιουργούμε το αρχείο ___lexicon.txt___ το οποίο ταξινομούμε ξανά μέσω της εντολής sort του bash ώστε να ταξινομηθεί και το φώνημα της σιωπής.\n",
    "* Δημιουργεί τα αρχεία ___lm_test.text___, ___lm_dev.text___ και ___lm_train.text___ κρατώντας μόνο τις προτάσεις από το αρχείο text και προσθέτοντας πρίν από αυτές το < s> και στο τέλος το < /s >. Στο σημείο αυτό σημειώνουμε ότι απορίφθηκαν τα id κάθε πρότασης προς αποφυγήν των πολλαπλών warrning που δημιουργούσαν. \n",
    "* Τέλος δημιουργεί το κενό αρχείο ___extra_questions.txt___ μέσω της bash εντολής touch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όσον αφορά την ενδιάμεση μορφή του γλωσσικού μοντέλου ___(4.2.2)___, το script καλεί την εντολή build-lm.sh του πακέτου IRSTLM που έχει εγκατασταθεί μαζί με το Kaldi, __build-lm.sh -i <αρχείο lm_train.text> -n <τάξη γλωσσικού μοντέλου> -o <αρχείο_εξόδου.ilm.gz>__ συνολικά 6 φορές. Η παράμετρος -n παίρνει την τιμή 1 για τα unigram μοντέλα και την τιμή 2 για τα bigram μοντέλα. Τα αρχεία αποθηκεύονται στον φάκελο data/local/lm_tmp.\n",
    "\n",
    "Στη συνέχεια αποθηκεύεται το compiled γλωσσικό μοντέλο σε μορφή ARPA ___(4.2.3)___ χρησιμοποιώντας την εντολή __compile-lm <αρχείο .ilm.gz> -t=yes /dev/stdout | grep -v unk | gzip -c > <αρχείο_εξόδου.arpa.gz>__. Τα αρχεία αποθηκεύονται στον φάκελο data/local/nist_lm.\n",
    "\n",
    "Για την δημιουργία του FST ___(4.2.4)___ της γραμματικής (L.fst) το script χρησιμοποιεί την εντολή του Kaldi __prepare_lang.sh__ και αποθηκεύει τα αρχεία ου δημιουργούνται στο φάκελο data/lang.\n",
    "\n",
    "Τέλος τροποποιούμε ελάχιστα το __local/timit_format_data.sh__ ώστε να το προσαρμόσουμε στη δική μας περίπτωση και το αντιγράφουμε στο φάκελο εργασίας μας ώστε να το χρησιμοποιήσουμε για να δημιουργήσουμε το FST της γραμματικής (G.fst). Συγκεκριμένα δημιουργούμε ένα fst αρχείο για κάθε μία από τις 6 περιπτώσεις χρησιμοποιώντας κάθε φορά το αντιστοιχο arpa.gz αρχείο. Τα αρχεία αυτά αποθηκεύονται στο φάκελο data/lang_test. ___(4.2.5)___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ερώτημα 1: Για τα γλωσσικά μοντέλα που δημιουργήσατε υπολογίστε το perplexity στο validation και στο test set. Τι δείχνουν αυτές οι τιμές;\n",
    "\n",
    "Για το ερώτημα αυτό καλούμε το script 4_2_erwthma1.sh το οποίο χρησιμοποιεί την εντολή compile-l που χρησιμοποιήσαμε και στο ερώτημα 4.2.2 με παράμετρο την --eval αυτή τη φορά καθώς σύμφωνα με το documentation του πακέτου IRSTLM ισχύει: _\"--eval|-e text-file (computes perplexity of text-file and returns)\"_ και το global option dub ισούται με 10^7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Perplexity calculation for the unigram model of the validation set\u001b[0m\n",
      "\n",
      "inpfile: lm_dev_unigram.ilm.gz\n",
      "outfile: lm_dev_unigram.ilm.blm\n",
      "evalfile: ../dict/lm_dev.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Start Eval\n",
      "OOV code: 42\n",
      "%% Nw=6357 PP=32.51 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%\n",
      "----------------------------------------------------\n",
      "\n",
      "\u001b[1m\n",
      "Perplexity calculation for the bigram model of the validation set\u001b[0m\n",
      "\n",
      "inpfile: lm_dev_bigram.ilm.gz\n",
      "outfile: lm_dev_bigram.ilm.blm\n",
      "evalfile: ../dict/lm_dev.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Start Eval\n",
      "OOV code: 42\n",
      "%% Nw=6357 PP=15.26 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%\n",
      "----------------------------------------------------\n",
      "\n",
      "\u001b[1m\n",
      "Perplexity calculation for the unigram model of the test set\u001b[0m\n",
      "\n",
      "inpfile: lm_test_unigram.ilm.gz\n",
      "outfile: lm_test_unigram.ilm.blm\n",
      "evalfile: ../dict/lm_test.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Start Eval\n",
      "OOV code: 42\n",
      "%% Nw=6179 PP=32.00 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%\n",
      "----------------------------------------------------\n",
      "\n",
      "\u001b[1m\n",
      "Perplexity calculation for the bigram model of the test set\u001b[0m\n",
      "\n",
      "inpfile: lm_test_bigram.ilm.gz\n",
      "outfile: lm_test_bigram.ilm.blm\n",
      "evalfile: ../dict/lm_test.text\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 42\n",
      "OOV code is 42\n",
      "Start Eval\n",
      "OOV code: 42\n",
      "%% Nw=6179 PP=14.65 PPwp=0.00 Nbo=0 Noov=0 OOV=0.00%\n",
      "----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!~/Documents/SLP_Lab2/kaldi/egs/usc/4_2_erwthma1.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στα προηγούμενα αποτελέσματα παρατηρούμε ότι τόσο για το validation όσο και για το test set η μετάβαση από unigram σε bigram μειώνει το perplexity. Σημειώνουμε ότι το perplexity είναι μια μέτρηση του πόσο καλά ένα μοντέλο κατανομής πιθανοτήτων προβλέπει ένα δείγμα και μπορεί να χρησιμοποιηθεί για να συγκρίνει μοντέλα πιθανότητας. Συνεπώς, μικρό perplexity δηλώνει ότι η κατανομή πιθανότητας είναι καλή στην πρόβλεψη του δείγματος, κάτι που επαληθεύται στα προηγούμενα αποτελέσματα καθώς τα bigram μοντέλα είναι πιο αποτελεσματικά από τα unigram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Εξαγωγή ακουστικών χαρακτηριστικών\n",
    "\n",
    "Στο επόμενο script εξάγουμε τα MFCCs και για τα 3 set χρησιμοποιώντας την εντολή του Kaldi __make_mfcc.sh__. Παράλληλα υπολογίζουμε τα στατιστικά στοιχεία της μέσης τιμής και της κανονικοποίησης της διακύμανσης (CMVN) με την εντολή του Kaldi __compute_cmvn_stats.sh__. Μετά από κάθε διαδικασία, διορθώνονται επίσης τα αρχεία δεδομένων για να βεβαιωθούμε ότι εξακολουθούν να είναι στη σωστή μορφή."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/make_mfcc.sh --mfcc-config conf/mfcc.conf --cmd run.pl data/train exp/make_mfcc/train mfcc_train\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/train\n",
      "steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "steps/make_mfcc.sh: Succeeded creating MFCC features for train\n",
      "steps/compute_cmvn_stats.sh data/train exp/make_mfcc/train mfcc_train\n",
      "Succeeded creating CMVN stats for train\n",
      "steps/make_mfcc.sh --mfcc-config conf/mfcc.conf --cmd run.pl data/test exp/make_mfcc/test mfcc_test\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/test\n",
      "steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "steps/make_mfcc.sh: Succeeded creating MFCC features for test\n",
      "steps/compute_cmvn_stats.sh data/test exp/make_mfcc/test mfcc_test\n",
      "Succeeded creating CMVN stats for test\n",
      "steps/make_mfcc.sh --mfcc-config conf/mfcc.conf --cmd run.pl data/dev exp/make_mfcc/dev mfcc_dev\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/dev\n",
      "steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\n",
      "steps/make_mfcc.sh: Succeeded creating MFCC features for dev\n",
      "steps/compute_cmvn_stats.sh data/dev exp/make_mfcc/dev mfcc_dev\n",
      "Succeeded creating CMVN stats for dev\n"
     ]
    }
   ],
   "source": [
    "!~/Documents/SLP_Lab2/kaldi/egs/usc/4_3.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ερώτημα 2: Με τη δεύτερη εντολή πραγματοποιείται το λεγόμενο Cepstral Mean and Variance Normalization. Τι σκοπό εξυπηρετεί; (Bonus: Δώστε μια μαθηματικά τεκμηριωμένη απάντηση)</font><br>\n",
    "\n",
    "Το __Cepstral mean and Variance normalization (CMVN)__ είναι μια υπολογιστικά αποδοτική τεχνική για εύρωστα αποτελέσματα κατά τη διαδικασία αναγνώρισης φωνής. Το CMVN ελαχιστοποιεί την παραμόρφωση λόγω θορύβου για την εύρωστη εξαγωγή χαρακτηριστικών με γραμμικό μετασχηματισμό των cepstral συνιστωσών ώστε να έχουν τις ίδιες τμηματικά στατιστικές. \n",
    "\n",
    "Τα προηγούμενα μπορούν να περιγραφούν και με βάση τις επόμενες μαθηματικές εκφράσεις:\n",
    "* Θεωρούμε $x[n]$ ένα σήμα εισόδου και $h[n]$ την παλμική απόκριση του καναλιού και η γραμμική συνέλιξη αυτών στο πεδίο του χρόνου είναι το ηχογραφημένο τελικό σήμα μας $y[n] = x[n]*h[n]$.\n",
    "* Για να αποφύγουμε την συνέλιξη μεταβαίνουμε στο πεδίο της συχνότητας με την χρήση του μετασχηματισμού Fourier και η εξίσωση που παίρνουμε είναι: $Y[f] = X[f]\\cdot H[f]$.\n",
    "* Στη συνέχεια λογαριθμώντας την εξίσωση του spectrum παίρνουμε το cepstrum και έτσι μεταβαίνουμε από την πράξη του πολλαπλασιασμού στην πράξη της πρόσθεσης κερδίζοντας παράλληλα αρκετά και υπολογιστική πολυπλοκότητα. Η νέα εξίσωση που προκύπτει είναι: $Y[τ] = \\log Υ[f] \\implies  Y(τ) = \\log \\left( X[f] \\cdot H[f]\\right) \\implies Y(τ) = X[τ] + H[τ]$\n",
    "\n",
    "Γίνεται λοιπόν κατανοητό ότι στο πεδίο του cepstrum οποιοσδήποτε θόρυβος είναι αθροιστικός στο σήμα μας. Θεωρώντας ότι η παλμική απόκριση h είναι στατική για οποιοδήποτε τυχαίο πλαίσιο i έχουμε $Y_i[τ] = H[τ] + X_i[τ]$\n",
    "* Παίρνουμε τον μέσο όρο όλων των πλαισίων και έχουμε: $\\dfrac{1}{N}\\sum_{i} Y_i[τ] = H[τ] + \\dfrac{1}{N}\\sum_{i} X_i[τ]$\n",
    "* Εν συνεχεία ορίζουμε ως $R_i[τ]$ την διαφορά του i-οστού στοιχείου από την μέση τιμή που υπολογίσαμε προηγουμένως $$R_i[τ] = Y_i[τ] - \\dfrac{1}{N}\\sum_{j} Y_j[τ] \\implies R_i[τ] = H[τ] + X_i[τ] - \\left(H[τ] +  \\dfrac{1}{N}\\sum_{j} X_j[τ]\\right) \\implies$$\n",
    "$$R_i[τ] = X_i[τ] - \\dfrac{1}{N}\\sum_{j} X_j[τ]$$\n",
    "\n",
    "Από την τελευταία εξίσωση καταλαβαίνουμε πόσο σημαντική είναι η διαδικασία του CMNV, όταν είμαστε σε ένα περιβάλλον ιδιαίτερα θορυβώδες, καθώς μετά από αυτήν το σήμα που προκύπτει είναι απαλλαγμένο από θόρυβο: $R_i[τ] = X_i[τ] - \\dfrac{1}{N}\\sum_{j} X_j[τ]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ερώτημα 3: Πόσα ακουστικά frames εξήχθησαν για κάθε μία από τις 5 πρώτες προτάσεις του training set; Τι διάσταση έχουν τα χαρακτηριστικά;\n",
    "\n",
    "Για το ερώτημα αυτό υλοποιήσαμε το script 4_3_erwthma3.sh το οποίο χρησιμοποιεί την εντολή feat-to-dim για να εμφανίσει την διάσταση των χαρακτηριστικών. Επίσης χρησιμοποιεί την εντολή feat-to-len για να εμφανίσει τον αριθμό των frames. Τέλος μέσω της εντολής head -5 για να εμφανίσουμε τις 5 πρώτες προτάσεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "The dimension of characteristics is:\u001b[0m\n",
      "\n",
      "feat-to-dim ark:mfcc_train/raw_mfcc_train.1.ark - \n",
      "13\n",
      "\n",
      "feat-to-len scp:data/train/feats.scp ark,t:data/train/feats.lengths \n",
      "\u001b[1m\n",
      "The first 5 sentences are:\n",
      "\n",
      "usctimit_ema_f1_001 237 \n",
      "usctimit_ema_f1_002 377 \n",
      "usctimit_ema_f1_003 317 \n",
      "usctimit_ema_f1_005 399 \n",
      "usctimit_ema_f1_006 338 \n"
     ]
    }
   ],
   "source": [
    "!~/Documents/SLP_Lab2/kaldi/egs/usc/4_3_erwthma3.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Βλέπουμε λοιπόν ότι οι διάσταση των χαρακτηριστικών είναι 13 και τα ακουστικά frames που εξήχθησαν για κάθε μία από τις 5 πρώτες προτάσεις είναι με την σειρά 237, 377, 317, 399, 338."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Εκπαίδευση ακουστικών μοντέλων και αποκωδικοποίηση προτάσεων\n",
    "\n",
    "Στο πρώτο ερώτημα της παρούσας ενότητας ___(4.4.1)___ εκπαιδεύουμε ένα μονοφωνικό ακουστικό μοντέλο πάνω στα train δεδομένα. Για λόγους πληρότητας αναφέρουμε ότι τα μονοφωνικά μοντέλα αποτελούν το πρώτο στάδιο για την εκπαίδευση και πιο πολύπλοκων μοντέλων. Για την υλοποίηση της διαδικασίας αυτής υλοποιήσαμε το 4_4_train_monophone.sh στο οποίο χρησιμοποιούμε την εντολή train_mono.sh με όρισμα το $train_cmd για να ορίσουμε την μηχανή που θα διαχειριστεί την διαδικασία. Το αποτέλεσμα της εκτέλεσης αυτής της εντολής είναι η δημιουργία του μοντέλου mono. Στη συνέχεια με τον ίδιο τρόπο, καλώντας την εντολή align_si.sh κατασκευάζουμε τα alignements του μοντέλου και τα απόθηκεύουμε με το όνομα mono_ali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "Starting monophone GMM-HMM acoutic model training \u001b[0m\n",
      "\n",
      "steps/train_mono.sh --cmd run.pl data/train data/lang_test exp/mono\n",
      "steps/train_mono.sh: Initializing monophone system.\n",
      "steps/train_mono.sh: Compiling training graphs\n",
      "steps/train_mono.sh: Aligning data equally (pass 0)\n",
      "steps/train_mono.sh: Pass 1\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 2\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 3\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 4\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 5\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 6\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 7\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 8\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 9\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 10\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 11\n",
      "steps/train_mono.sh: Pass 12\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 13\n",
      "steps/train_mono.sh: Pass 14\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 15\n",
      "steps/train_mono.sh: Pass 16\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 17\n",
      "steps/train_mono.sh: Pass 18\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 19\n",
      "steps/train_mono.sh: Pass 20\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 21\n",
      "steps/train_mono.sh: Pass 22\n",
      "steps/train_mono.sh: Pass 23\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 24\n",
      "steps/train_mono.sh: Pass 25\n",
      "steps/train_mono.sh: Pass 26\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 27\n",
      "steps/train_mono.sh: Pass 28\n",
      "steps/train_mono.sh: Pass 29\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 30\n",
      "steps/train_mono.sh: Pass 31\n",
      "steps/train_mono.sh: Pass 32\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 33\n",
      "steps/train_mono.sh: Pass 34\n",
      "steps/train_mono.sh: Pass 35\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 36\n",
      "steps/train_mono.sh: Pass 37\n",
      "steps/train_mono.sh: Pass 38\n",
      "steps/train_mono.sh: Aligning data\n",
      "steps/train_mono.sh: Pass 39\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_test exp/mono\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 46.384720327421554% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 51.432469304229194% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log\n",
      "3572 warnings in exp/mono/log/align.*.*.log\n",
      "216 warnings in exp/mono/log/acc.*.*.log\n",
      "6 warnings in exp/mono/log/init.log\n",
      "122 warnings in exp/mono/log/update.*.log\n",
      "2 warnings in exp/mono/log/analyze_alignments.log\n",
      "exp/mono: nj=4 align prob=-84.32 over 1.81h [retry=1.7%, fail=0.1%] states=125 gauss=997\n",
      "steps/train_mono.sh: Done training monophone system in exp/mono\n",
      "\u001b[1m\n",
      "Monophone training done\n",
      "\n",
      "Aligning the monophone model set \u001b[0m\n",
      "\n",
      "steps/align_si.sh --cmd run.pl data/train data/lang_test exp/mono exp/mono_ali\n",
      "steps/align_si.sh: feature type is delta\n",
      "steps/align_si.sh: aligning data in data/train using model from exp/mono, putting alignments in exp/mono_ali\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_test exp/mono_ali\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 47.13506139154161% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 51.432469304229194% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali/log/analyze_alignments.log\n",
      "steps/align_si.sh: done aligning data.\n"
     ]
    }
   ],
   "source": [
    "!~/Documents/SLP_Lab2/kaldi/egs/usc/4_4_train_monophone.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στο βήμα 4.2.5 δημιουργήσαμε συνολικά 6 γραμματικές. Στο παρόν ερώτημα ___(4.4.2)___ μας ζητείται για τις 2 γραμματικές που αφορούν το train set του unigram και του bigram μοντέλου να δημιουργήσουμε το HCLG γράφο του Kaldi. Για την υλοποίηση αυτής της διαδικασίας κατασκευάσμε το script 4_4_make_graphs.sh. Αναλυτικά στο script αυτό δημιουργούμε ένα αντίγραφο του αρχείου G_train_unigram.fst και το μετονομάζουμε σε G.fst ώστε να είναι συμβατό με την εντολή mkgraph.sh --mono που καλούμε στην συνέχεια. Επόμενο βήμα είναι η αποθήκευση του προσορινού αρχείου tmp που δημιουργείται σε ένα αρχείο με το όνομα tmp_mono_unigram και εν συνεχεία διαγράφουμε το tmp ώστε να κάνουμε ξανά την ίδια ακριβώς διαδικασία για το bigram μοντέλο. Με την εκτέλεση αυτού του script έχουμε πλέον έτοιμους τους γράφους του train set τόσο για το unigram όσο και για το bigram μοντέλο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "We create a copy of file G_train_unigram.fst and we name it G.fst so that command mkgraph can find it\n",
      "Then we make the HCLG graph \u001b[0m\n",
      "\n",
      "WARNING: the --mono, --left-biphone and --quinphone options are now deprecated and ignored.\n",
      "tree-info exp/mono/tree \n",
      "tree-info exp/mono/tree \n",
      "fsttablecompose data/lang_test/L_disambig.fst data/lang_test/G.fst \n",
      "fstdeterminizestar --use-log=true \n",
      "fstminimizeencoded \n",
      "fstpushspecial \n",
      "fstisstochastic data/lang_test/tmp/LG.fst \n",
      "0.000519182 0.000486742\n",
      "fstcomposecontext --context-size=1 --central-position=0 --read-disambig-syms=data/lang_test/phones/disambig.int --write-disambig-syms=data/lang_test/tmp/disambig_ilabels_1_0.int data/lang_test/tmp/ilabels_1_0.4990 data/lang_test/tmp/LG.fst \n",
      "fstisstochastic data/lang_test/tmp/CLG_1_0.fst \n",
      "0.000519182 0.000486742\n",
      "make-h-transducer --disambig-syms-out=exp/mono/graph_unigram/disambig_tid.int --transition-scale=1.0 data/lang_test/tmp/ilabels_1_0 exp/mono/tree exp/mono/final.mdl \n",
      "fstdeterminizestar --use-log=true \n",
      "fsttablecompose exp/mono/graph_unigram/Ha.fst data/lang_test/tmp/CLG_1_0.fst \n",
      "fstminimizeencoded \n",
      "fstrmsymbols exp/mono/graph_unigram/disambig_tid.int \n",
      "fstrmepslocal \n",
      "fstisstochastic exp/mono/graph_unigram/HCLGa.fst \n",
      "0.000976562 -0.000320371\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/mono/final.mdl exp/mono/graph_unigram/HCLGa.fst \n",
      "\u001b[1m\n",
      "We create a copy of file tmp and we name it tmp_mono_unigram. Then we delete file tmp.\n",
      "--------- HCLG graph for the unigram model of the train set is ready --------- \u001b[0m\n",
      "\n",
      "\u001b[1m\n",
      "We create a copy of file G_train_bigram.fst and we name it G.fst so that command mkgraph can find it\n",
      "Then we make the HCLG graph \u001b[0m\n",
      "\n",
      "WARNING: the --mono, --left-biphone and --quinphone options are now deprecated and ignored.\n",
      "tree-info exp/mono/tree \n",
      "tree-info exp/mono/tree \n",
      "fsttablecompose data/lang_test/L_disambig.fst data/lang_test/G.fst \n",
      "fstminimizeencoded \n",
      "fstpushspecial \n",
      "fstdeterminizestar --use-log=true \n",
      "fstisstochastic data/lang_test/tmp/LG.fst \n",
      "-0.00855164 -0.009256\n",
      "fstcomposecontext --context-size=1 --central-position=0 --read-disambig-syms=data/lang_test/phones/disambig.int --write-disambig-syms=data/lang_test/tmp/disambig_ilabels_1_0.int data/lang_test/tmp/ilabels_1_0.5047 data/lang_test/tmp/LG.fst \n",
      "fstisstochastic data/lang_test/tmp/CLG_1_0.fst \n",
      "-0.00855164 -0.00925601\n",
      "make-h-transducer --disambig-syms-out=exp/mono/graph_bigram/disambig_tid.int --transition-scale=1.0 data/lang_test/tmp/ilabels_1_0 exp/mono/tree exp/mono/final.mdl \n",
      "fstdeterminizestar --use-log=true \n",
      "fsttablecompose exp/mono/graph_bigram/Ha.fst data/lang_test/tmp/CLG_1_0.fst \n",
      "fstrmepslocal \n",
      "fstminimizeencoded \n",
      "fstrmsymbols exp/mono/graph_bigram/disambig_tid.int \n",
      "fstisstochastic exp/mono/graph_bigram/HCLGa.fst \n",
      "0.000408381 -0.010419\n",
      "HCLGa is not stochastic\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/mono/final.mdl exp/mono/graph_bigram/HCLGa.fst \n",
      "\u001b[1m\n",
      "We create a copy of file tmp and we name it tmp_mono_bigram. Then we delete file tmp.\n",
      "--------- HCLG graph for the bigram model of the train set is ready --------- \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!~/Documents/SLP_Lab2/kaldi/egs/usc/4_4_make_graphs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για την εκτέλεση των βημάτων ___4.4.3___ και ___4.4.4___ υλοποιήσαμε το bash script 4_4_decode.sh. Συγκεκριμένα δημιουργούμε ένα αντίγραφο του script score_kaldi.sh με όνομα score.sh καθώς το script αυτό εκτελείται μέσω του script decode.sh. Τα δύο προηγούμενα scripts του kaldi tool καλούνται έμεσα μέσω του script 4_4_decode.sh που υλοποιήσαμε για το παρόν ερώτημα. Στο σημείο αυτό αναφέρουμε ότι με βάση το documentation του kaldi καλώντας το script decode.sh χρησιμοποιούμε τον αλγόριθμο viterbi όπως ζητείται στην εκφώνηση. Αφού ολοκληρωθεί η αποκωδικοποιήση παρουσιάζουμε τα αποτελέσματα της με την χρήση της μετρικής Phone Error Rate (PER) η οποία δίνεται από τον τύπο:$$Per = 100\\dfrac{insertions+substitutions+deletions}{\\#phonems}$$\n",
    "Για τον υπολογισμό της PER χρησιμοποιήθηκε η εντολή best_wer.sh η οποία βρίσκει το μικρότερο δυνατό WER. Σημειώνουμε ότι το όνομα WER οφείλεται στο γεγονός ότι συνήθως εξετάζονται λέξεις και όχι φωνήματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "We create a copy of the file score_kaldi.sh and we name it score.sh \u001b[0m\n",
      "\u001b[1m\n",
      "----------------------- UNIGRAM MODEL -----------------------\n",
      "\n",
      "------------------- Decoding Validation Set ------------------- \u001b[0m\n",
      "\n",
      "steps/decode.sh --nj 4 --cmd run.pl exp/mono/graph_unigram data/dev exp/mono/decode_dev\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono/graph_unigram exp/mono/decode_dev\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_dev/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(9,42,590) and mean=301.3\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_dev/log/analyze_lattice_depth_stats.log\n",
      "local/score.sh --cmd run.pl data/dev exp/mono/graph_unigram exp/mono/decode_dev\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "\u001b[1m\n",
      "The Phone Error Rate (PER) for the validation set is:\n",
      "\n",
      "%WER 51.30 [ 3167 / 6174, 80 ins, 1690 del, 1397 sub ] exp/mono/decode_dev/wer_7_0.0\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "------------------- Decoding Test Set ------------------- \u001b[0m\n",
      "\n",
      "steps/decode.sh --nj 4 --cmd run.pl exp/mono/graph_unigram data/test exp/mono/decode_test\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono/graph_unigram exp/mono/decode_test\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_test/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(8,42,479) and mean=243.2\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_test/log/analyze_lattice_depth_stats.log\n",
      "local/score.sh --cmd run.pl data/test exp/mono/graph_unigram exp/mono/decode_test\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "\u001b[1m\n",
      "The Phone Error Rate (PER) for the test set is:\n",
      "\n",
      "%WER 49.06 [ 2941 / 5995, 65 ins, 1568 del, 1308 sub ] exp/mono/decode_test/wer_7_0.0\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m\n",
      "----------------------- BIGRAM MODEL -----------------------\n",
      "\n",
      "------------------- Decoding Validation Set ------------------- \u001b[0m\n",
      "\n",
      "steps/decode.sh --nj 4 --cmd run.pl exp/mono/graph_bigram data/dev exp/mono/decode_dev\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono/graph_bigram exp/mono/decode_dev\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 45.3551912568306% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 42.622950819672134% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_dev/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(3,17,125) and mean=70.1\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_dev/log/analyze_lattice_depth_stats.log\n",
      "local/score.sh --cmd run.pl data/dev exp/mono/graph_bigram exp/mono/decode_dev\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "\u001b[1m\n",
      "The Phone Error Rate (PER) for the validation set is:\n",
      "\n",
      "%WER 46.03 [ 2842 / 6174, 110 ins, 1213 del, 1519 sub ] exp/mono/decode_dev/wer_7_0.0\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "------------------- Decoding Test Set ------------------- \u001b[0m \n",
      "\n",
      "steps/decode.sh --nj 4 --cmd run.pl exp/mono/graph_bigram data/test exp/mono/decode_test\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono/graph_bigram exp/mono/decode_test\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 47.82608695652174% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 40.21739130434783% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_test/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(3,17,112) and mean=55.1\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono/decode_test/log/analyze_lattice_depth_stats.log\n",
      "local/score.sh --cmd run.pl data/test exp/mono/graph_bigram exp/mono/decode_test\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "\u001b[1m\n",
      "The Phone Error Rate (PER) for the test set is:\n",
      "\n",
      "%WER 43.39 [ 2601 / 5995, 99 ins, 1144 del, 1358 sub ] exp/mono/decode_test/wer_7_0.0\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!~/Documents/SLP_Lab2/kaldi/egs/usc/4_4_decode.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Οι υπερπαράμετροι___ ορίζονται μέσα στο αρχείο score.sh και είναι τα min_lmwt και max_lmwt. Οι τιμές που έχουν πάρει είναι 7 και 17 αντίστοιχα. Σύμφωνα με την ενότητα acoustic scale του glossary of terms του kaldi το συνηθισμένο εύρος βαρών των γλωδικών μοντέλων είναι στο εύρος 5 με 17. Συνεπώς θεωρήσαμε ότι οι τιμές των υπερπαραμέτρων μπορούν να μείνουν ως έχουν. \n",
    "\n",
    "Όπως ήταν αναμενόμενο το bigram μοντέλο δίνει καλύτερα αποτελέσματα από το unigram μοντέλο της τάξης του 5-6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η εκπαίδευση ενός τριφωνικού μοντέλου περιλαμβάνει επιπλέον arguments για τον αριθμό των φύλλον ή τις HMM καταστάσεις του δέντρου απόφασης και για τον αριθμό των gaussians. Για το triphone μοντέλο ___(4.4.5)___ πρέπει αρχικά να κάνουμε align των φωνημάτων χρησιμοποιώντας το μονοφωνικό μοντέλο. Η διαδικασία αυτή έχει ήδη υλοποιηθεί στο βήμα 4.4.1 και συνεπώς για περισσότερες λεπτομέρειες παραπέμπουμε στο βήμα αυτό. Στη συνέχεια δημιουργούμε ένα υποσύνολο με τα 1000 μικρότερα utterances. Για την εκπαίδευση του triphone χρησιμοποιούμε την εντολή train_deltas.sh. Στη συνέχεια υπόλοιπη διαδικασία είναι ίδια με αυτή των monophones οπότε για την επεξήγηση της παραπέμπουμε σε παραπάνω σχολιασμούς."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "We make a subset with the shortest 1000 utterances from the train data \u001b[0m\n",
      "\n",
      "feat-to-len scp:data/train/feats.scp ark,t:data/train_1000/tmp.len \n",
      "utils/subset_data_dir.sh: reducing #utt from 1468 to 1000\n",
      "\u001b[1m\n",
      "Starting triphone GMM-HMM acoutic model training \u001b[0m\n",
      "\n",
      "steps/train_deltas.sh --cmd run.pl 2000 10000 data/train_1000 data/lang_test exp/mono_ali exp/tri\n",
      "steps/train_deltas.sh: accumulating tree stats\n",
      "steps/train_deltas.sh: getting questions for tree-building, via clustering\n",
      "steps/train_deltas.sh: building the tree\n",
      "WARNING (gmm-init-model[5.5.589~1-1f357]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 \n",
      "** The warnings above about 'no stats' generally mean you have phones **\n",
      "** (or groups of phones) in your phone set that had no corresponding data. **\n",
      "** You should probably figure out whether something went wrong, **\n",
      "** or whether your data just doesn't happen to have examples of those **\n",
      "** phones. **\n",
      "steps/train_deltas.sh: converting alignments from exp/mono_ali to use current tree\n",
      "steps/train_deltas.sh: compiling graphs of transcripts\n",
      "steps/train_deltas.sh: training pass 1\n",
      "steps/train_deltas.sh: training pass 2\n",
      "steps/train_deltas.sh: training pass 3\n",
      "steps/train_deltas.sh: training pass 4\n",
      "steps/train_deltas.sh: training pass 5\n",
      "steps/train_deltas.sh: training pass 6\n",
      "steps/train_deltas.sh: training pass 7\n",
      "steps/train_deltas.sh: training pass 8\n",
      "steps/train_deltas.sh: training pass 9\n",
      "steps/train_deltas.sh: training pass 10\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 11\n",
      "steps/train_deltas.sh: training pass 12\n",
      "steps/train_deltas.sh: training pass 13\n",
      "steps/train_deltas.sh: training pass 14\n",
      "steps/train_deltas.sh: training pass 15\n",
      "steps/train_deltas.sh: training pass 16\n",
      "steps/train_deltas.sh: training pass 17\n",
      "steps/train_deltas.sh: training pass 18\n",
      "steps/train_deltas.sh: training pass 19\n",
      "steps/train_deltas.sh: training pass 20\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 21\n",
      "steps/train_deltas.sh: training pass 22\n",
      "steps/train_deltas.sh: training pass 23\n",
      "steps/train_deltas.sh: training pass 24\n",
      "steps/train_deltas.sh: training pass 25\n",
      "steps/train_deltas.sh: training pass 26\n",
      "steps/train_deltas.sh: training pass 27\n",
      "steps/train_deltas.sh: training pass 28\n",
      "steps/train_deltas.sh: training pass 29\n",
      "steps/train_deltas.sh: training pass 30\n",
      "steps/train_deltas.sh: aligning data\n",
      "steps/train_deltas.sh: training pass 31\n",
      "steps/train_deltas.sh: training pass 32\n",
      "steps/train_deltas.sh: training pass 33\n",
      "steps/train_deltas.sh: training pass 34\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_test exp/tri\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 44.68937875751503% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 44.68937875751503% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri/log/analyze_alignments.log\n",
      "79 warnings in exp/tri/log/init_model.log\n",
      "68 warnings in exp/tri/log/acc.*.*.log\n",
      "34 warnings in exp/tri/log/align.*.*.log\n",
      "1 warnings in exp/tri/log/questions.log\n",
      "125 warnings in exp/tri/log/update.*.log\n",
      "2 warnings in exp/tri/log/analyze_alignments.log\n",
      "1 warnings in exp/tri/log/build_tree.log\n",
      "exp/tri: nj=4 align prob=-79.21 over 1.10h [retry=0.8%, fail=0.2%] states=736 gauss=10058 tree-impr=4.67\n",
      "steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri\n",
      "\u001b[1m\n",
      "Triphone training done\n",
      "\n",
      "Aligning the triphone model set \u001b[0m\n",
      "\n",
      "steps/align_si.sh --cmd run.pl data/train_1000 data/lang_test exp/tri exp/tri_ali\n",
      "steps/align_si.sh: feature type is delta\n",
      "steps/align_si.sh: aligning data in data/train_1000 using model from exp/tri, putting alignments in exp/tri_ali\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_test exp/tri_ali\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 44.48897795591182% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 44.789579158316634% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri_ali/log/analyze_alignments.log\n",
      "steps/align_si.sh: done aligning data.\n",
      "\u001b[1m\n",
      "We create a copy of file G_train_unigram.fst and we name it G.fst so that command mkgraph can find it\n",
      "Then we make the HCLG graph \u001b[0m\n",
      "\n",
      "tree-info exp/tri/tree \n",
      "tree-info exp/tri/tree \n",
      "fsttablecompose data/lang_test/L_disambig.fst data/lang_test/G.fst \n",
      "fstminimizeencoded \n",
      "fstpushspecial \n",
      "fstdeterminizestar --use-log=true \n",
      "fstisstochastic data/lang_test/tmp/LG.fst \n",
      "0.000519182 0.000486742\n",
      "fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang_test/phones/disambig.int --write-disambig-syms=data/lang_test/tmp/disambig_ilabels_3_1.int data/lang_test/tmp/ilabels_3_1.15682 data/lang_test/tmp/LG.fst \n",
      "fstisstochastic data/lang_test/tmp/CLG_3_1.fst \n",
      "0.000519283 0\n",
      "make-h-transducer --disambig-syms-out=exp/tri/graph_unigram/disambig_tid.int --transition-scale=1.0 data/lang_test/tmp/ilabels_3_1 exp/tri/tree exp/tri/final.mdl \n",
      "fstrmepslocal \n",
      "fsttablecompose exp/tri/graph_unigram/Ha.fst data/lang_test/tmp/CLG_3_1.fst \n",
      "fstrmsymbols exp/tri/graph_unigram/disambig_tid.int \n",
      "fstdeterminizestar --use-log=true \n",
      "fstminimizeencoded \n",
      "fstisstochastic exp/tri/graph_unigram/HCLGa.fst \n",
      "0.00110898 -0.00047237\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri/final.mdl exp/tri/graph_unigram/HCLGa.fst \n",
      "\u001b[1m\n",
      "We create a copy of file tmp and we name it tmp_tri_unigram. Then we delete file tmp.\n",
      "--------- HCLG graph for the unigram model of the train set is ready --------- \u001b[0m\n",
      "\n",
      "\u001b[1m\n",
      "We create a copy of file G_train_bigram.fst and we name it G.fst so that command mkgraph can find it\n",
      "Then we make the HCLG graph \u001b[0m\n",
      "\n",
      "tree-info exp/tri/tree \n",
      "tree-info exp/tri/tree \n",
      "fsttablecompose data/lang_test/L_disambig.fst data/lang_test/G.fst \n",
      "fstminimizeencoded \n",
      "fstpushspecial \n",
      "fstdeterminizestar --use-log=true \n",
      "fstisstochastic data/lang_test/tmp/LG.fst \n",
      "-0.00855164 -0.009256\n",
      "fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang_test/phones/disambig.int --write-disambig-syms=data/lang_test/tmp/disambig_ilabels_3_1.int data/lang_test/tmp/ilabels_3_1.15738 data/lang_test/tmp/LG.fst \n",
      "fstisstochastic data/lang_test/tmp/CLG_3_1.fst \n",
      "0 -0.00925601\n",
      "make-h-transducer --disambig-syms-out=exp/tri/graph_bigram/disambig_tid.int --transition-scale=1.0 data/lang_test/tmp/ilabels_3_1 exp/tri/tree exp/tri/final.mdl \n",
      "fsttablecompose exp/tri/graph_bigram/Ha.fst data/lang_test/tmp/CLG_3_1.fst \n",
      "fstminimizeencoded \n",
      "fstrmsymbols exp/tri/graph_bigram/disambig_tid.int \n",
      "fstdeterminizestar --use-log=true \n",
      "fstrmepslocal \n",
      "fstisstochastic exp/tri/graph_bigram/HCLGa.fst \n",
      "0.000474884 -0.0215567\n",
      "HCLGa is not stochastic\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri/final.mdl exp/tri/graph_bigram/HCLGa.fst \n",
      "\u001b[1m\n",
      "We create a copy of file tmp and we name it tmp_tri_bigram. Then we delete file tmp.\n",
      "--------- HCLG graph for the bigram model of the train set is ready --------- \u001b[0m\n",
      "\n",
      "\u001b[1m\n",
      "----------------------- BIGRAM MODEL -----------------------\n",
      "\n",
      "------------------- Decoding Validation Set ------------------- \u001b[0m\n",
      "Decoding validation set \u001b[0m\n",
      "\n",
      "steps/decode.sh --nj 4 --cmd run.pl exp/tri/graph_unigram data/dev exp/tri/decode_dev\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri/graph_unigram exp/tri/decode_dev\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 43.169398907103826% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 50.81967213114754% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri/decode_dev/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(2,10,52) and mean=21.9\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri/decode_dev/log/analyze_lattice_depth_stats.log\n",
      "local/score.sh --cmd run.pl data/dev exp/tri/graph_unigram exp/tri/decode_dev\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "\u001b[1m\n",
      "The Phone Error Rate (PER) for the validation set is:\n",
      "\n",
      "%WER 40.65 [ 2510 / 6174, 293 ins, 729 del, 1488 sub ] exp/tri/decode_dev/wer_8_0.0\n",
      "\u001b[1m\n",
      "------------------- Decoding Test Set ------------------- \u001b[0m\n",
      "\n",
      "steps/decode.sh --nj 4 --cmd run.pl exp/tri/graph_unigram data/test exp/tri/decode_test\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri/graph_unigram exp/tri/decode_test\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 59.23913043478261% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 59.23913043478261% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri/decode_test/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(2,10,49) and mean=20.9\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri/decode_test/log/analyze_lattice_depth_stats.log\n",
      "local/score.sh --cmd run.pl data/test exp/tri/graph_unigram exp/tri/decode_test\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "\u001b[1m\n",
      "The Phone Error Rate (PER) for the test set is:\n",
      "\n",
      "%WER 39.38 [ 2361 / 5995, 253 ins, 705 del, 1403 sub ] exp/tri/decode_test/wer_7_0.5\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m\n",
      "----------------------- BIGRAM MODEL -----------------------\n",
      "\n",
      "------------------- Decoding Validation Set ------------------- \u001b[0m\n",
      "\n",
      "steps/decode.sh --nj 4 --cmd run.pl exp/tri/graph_bigram data/dev exp/tri/decode_dev\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri/graph_bigram exp/tri/decode_dev\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 40.43715846994535% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 44.80874316939891% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri/decode_dev/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,8,37) and mean=15.5\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri/decode_dev/log/analyze_lattice_depth_stats.log\n",
      "local/score.sh --cmd run.pl data/dev exp/tri/graph_bigram exp/tri/decode_dev\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "\u001b[1m\n",
      "The Phone Error Rate (PER) for the validation set is:\n",
      "\n",
      "%WER 36.80 [ 2272 / 6174, 231 ins, 661 del, 1380 sub ] exp/tri/decode_dev/wer_11_0.0\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "------------------- Decoding Test Set ------------------- \u001b[0m \n",
      "\n",
      "steps/decode.sh --nj 4 --cmd run.pl exp/tri/graph_bigram data/test exp/tri/decode_test\n",
      "decode.sh: feature type is delta\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri/graph_bigram exp/tri/decode_test\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 53.26086956521739% of the time at utterance begin.  This may not be optimal.\n",
      "analyze_phone_length_stats.py: WARNING: optional-silence sil is seen only 47.82608695652174% of the time at utterance end.  This may not be optimal.\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri/decode_test/log/analyze_alignments.log\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,7,34) and mean=13.8\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri/decode_test/log/analyze_lattice_depth_stats.log\n",
      "local/score.sh --cmd run.pl data/test exp/tri/graph_bigram exp/tri/decode_test\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\n",
      "\u001b[1m\n",
      "The Phone Error Rate (PER) for the test set is:\n",
      "\n",
      "%WER 35.51 [ 2129 / 5995, 218 ins, 602 del, 1309 sub ] exp/tri/decode_test/wer_8_0.5\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!~/Documents/SLP_Lab2/kaldi/egs/usc/4_4_triphone.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όπως είναι λογικό και αναμενόμενο η μετάβαση από monophone σε triphone βελτιώνεται σημαντικά καθώς όπως βλέπουμε παραπάνω το PER μειώνεται σημαντικά."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ερώτημα 4: Εξηγήστε τη δομή ενός ακουστικού μοντέλου GMM-HMM. Τι σκοπό εξυπηρετούν τα μαρκοβιανά μοντέλα στη συγκεκριμένη περίπτωση και τι τα μίγματα γκαουσιανών? Με ποιό τρόπο γίνεται η εκπαίδευση ενός τέτοιου μοντέλου;\n",
    "\n",
    "Η βασική ιδέα ενός ___GMM-HMM___ ακουστικού μοντέλου είναι ότι η κατανομή των χαρακτηριστικών ενός φωνήματος μοντελοποιείται μέσω ενός Gaussian Mixture Model (GMM) το οποίο εκπαιδεύουμε με δεδομένα εκπαίδευσης. Ενώ η σύζευξη μεταξύ των φωνημάτων και των αντίστοιχων παρατηρήσιμων μοντελοποείται με την χρήση Hidden Markov Model (HMM). \n",
    "\n",
    "Tο ___ΗΜΜ___ είναι ουσιαστικά fsm που αναπαριστούν τις πιθανότητες μετάβασης μεταξύ των φωνημάτων σε μία λέξη. Ένα τυπικό παράδειγμα hmm phone topology φαίνεται στην επόμενη εικόνα:\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/y6SSWM5/Screenshot-2019-12-30-ASRU-talk09-pdf.png\" alt=\"Screenshot-2019-12-30-ASRU-talk09-pdf\" border=\"0\"></a>\n",
    "\n",
    "\n",
    "Ενώ το ___GMM___ ομαδοποιεί ουσιαστικά το fsm σε υποκατηγορίες. Παραθέτουμε μια οπτική απεικόνηση ενός gmm με 3 clusters:\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/F4w0Vrg/index.png\" alt=\"index\" border=\"0\"></a><br /><a target='_blank'></a>\n",
    "Συνεπώς ένα ___GMM-HMM___ ακουστικό μοντέλο συνοψίζει τις δύο προηγούμενες περιγραφές και αποτυπώνεται οπτικά ως εξής:\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/TYgzTB2/Screenshot-2019-12-30-GMM-HMM-ACOUSTIC-MODEL-TRAINING-BY-A-TWO-LEVEL-PROCEDURE-WITH-GAUSSIAN-COMPONENTS-DETERMINED-BY-AUTOM.png\" alt=\"Screenshot-2019-12-30-GMM-HMM-ACOUSTIC-MODEL-TRAINING-BY-A-TWO-LEVEL-PROCEDURE-WITH-GAUSSIAN-COMPONENTS-DETERMINED-BY-AUTOM\" border=\"0\"></a><br /><a target='_blank'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ερώτημα 5: Γράψτε πώς υπολογίζεται η a posteriori πιθανότητα σύμφωνα με τον τύπο του Bayes για το πρόβληματης αναγνώρισης φωνής. Συγκεκριμένα, πώς βρίσκεται η πιο πιθανή λέξη (ή φώνημα στην περίπτωσή μας) δεδομένης μίας ακολουθίας ακουστικών χαρακτηριστικών;\n",
    "\n",
    "Σύμφωνα με τον τύπο του Bayes η a posteriori πιθανότητα της λέξης W δεδομένης του διανύσματος παρατηρήσεων Χ δίνεται από τον τύπο: $$P(W|X) = \\dfrac{{P(W)} \\cdot {P(X|W)}}{P(X)}$$\n",
    "Όπου $P(W)$ είναι η πιθανότητα να έχουμε την λέξη W και προέρχεται από το γλωσικό μοντέλο και $P(X|W)$ η πιθανότητα των χαρακτηριστικών X ενώ έχουμε τη λέξη W και προέρχεται από το ακουστικό μοντέλο.\n",
    "\n",
    "Για να βρούμε το πιο πιθανό φώνημα δεδομένης μιας ακολουθίας ακουστικών χαρακτηριστικών συνδυάζουμε το ακουστικό και το γλωσικό μοντέλο χρησιμοποιώντας παράλληλα το maximum likelihood. Συνεπώς η σχέση που προκύπτει είναι: $W^* = \\operatorname*{arg_w\\,max} P(W)P(X|W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ερώτημα 6: Εξηγήστε τη δομή του γράφου HCLG του Kaldi περιγραφικά.\n",
    "\n",
    "Ο γράφος-αποκωδικοποιητής __HCLG__ του kaldi αποτελεί σύνθεση των ακόλουθων 4 γράφων:\n",
    "\n",
    "* __G__: Αποδοχέας ο οποίος κωδικοποιεί το γλωσσικό μας μοντέλο\n",
    "* __L__: Λεξικό, το οποίο στην περίπτωση μας, επειδή ασχολούμαστε με αναγνώριση φωνημάτων και όχι λέξεων, αποτελεί μια 1-1 αντιστοιχία των φωνημάτων με τον εαυτό τους.\n",
    "* __C__: Απεικόνιση context-dependent labels σε φωνήματα\n",
    "* __H__: Απεικόνιση μεταβάσεων ενός κρυφού μαρκοβιανού μοντέλου (Hidden Markov Model) σε context-dependent labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ερώτημα : Προσπαθείστε να προτείνετε/εκτιμήσετε πως θα μπορούσε να βελτιωθεί το σύστημα αναγνώρισης φωνής που έχετε αναπτύξει.\n",
    "\n",
    "Το σύστημα αναγνώρισης φωνής που αναπτύξαμε στην παρούσα εργαστηρακή άσκηση θα μπορούσε να __βελτιωθεί__ με τους ακόλουθους τρόπους:\n",
    "* Ο __εμπλουτισμός του συνόλου δεδομένων__ μπορεί να συνεισφέρει σημαντικά στην βελτίωση των αποτελεσμάτων μας. Όπως είναι γνωστό, όταν το corpus που έχουμε στη διάθεση μας είναι μεγάλο, τα αποτελέσματα που λαμβάνουμε είναι πολύ πιο ακριβή καθώς υπάρχει μεγαλύτερη ποικιλία από λέξεις και φωνήματα, με αποτέλεσμα η εκπαίδευση του μοντέλου μας να είναι σαφώς καλύτερη.  \n",
    "\n",
    "\n",
    "* Η εισαγωγή __Hidden Markov Models (HMM)__ στην εξαγωγή των χαρακτηριστικών μπορεί να συνδράμει στην βελτιστοποίηση του μοντέλου μας. Έχουμε υποθέσει, κατά την ανάλυση, ότι τα παράθυρα που χρησιμοποιούνται είναι ανεξάρτητα μεταξύ τους. Αυτό έρχεται σε σύγκρουση με τις αλληλουχίες φωνημάτων οι οποίες τις περισσότερες φορές εμφανίζουν κάποια συσχέτιση μέσα σε μια πρόταση. Έτσι λοιπόν, μέσω εισαγωγής HMM μπορούμε να επιτύχουμε κάποια είδους \"συντακτική\" ανάλυση του λόγου ή έστω κάποια συσχέτιση στην ανάλυση διαδοχικών φωνημάτων με χρήση bigrams.\n",
    "\n",
    "\n",
    "* Στα πλαίσια της εργαστηριακής άσκησης αναπτύξαμε unigram και bigram μοντέλα. Για να έχουμε ακόμα καλύτερα αποτελέσματα θα μπορούσαμε να μην περιοριστούμε μόνο σε αυτά τα μοντέλα αλλά να κατασκευάσουμε και άλλα __n-grams για τιμές του n μεγαλύτερες του 2__ (trigram,four-gram κτλ). Ο λόγος που αυτό συμβάλει στην βελτιστοποίηση του μοντέλου μας είναι ότι όσο μεγαλύτερη είναι η τιμή του n τόσο καλύτερα μπορεί να διαχειριστεί το μοντέλο μας ένα μεγάλο όγκο δεδομένων και να κάνει μια πιο επιτυχημένη πρόβλεψη φωνημάτων και λέξεων (με μεγαλύτερη πιθανότητα). Βέβαια αξίζει να σημειωθεί ότι όσο μεγαλύτερο είναι το n-gram μοντέλο μας τόσο μεγαλύτερη είναι και η υπολογιστική πολυπλοκότητα του συστήματός μας, συνεπώς πρέπει να βρούμε ενα trade off μεταξύ απόδοσης και διαθέσιμων πόρων.\n",
    "\n",
    "\n",
    "* Αξίζει να σημειωθεί ότι το μοντέλο μας θα μπορούσε να εμπλουτιστεί ακόμα περισσότερο λαμβάνοντας υπόψην,εκτός από τα ηχογραφήσεις, και τις __χαρακτηριστικές κινήσεις του προσώπου των ομιλητών__, οι οποίες σχετίζονται άμεσα με τους ήχους που αυτοί παράγουν. Άλλωστε, στον τομέα επεξεργασίας φωνής και φυσικής γλώσσας, τα οπτικοακουστικά μοντέλα δίνουν ποιοτικότερα αποτελέσματα σε σχέση με τα μοντέλα που εκμεταλεύονται μόνο την ακουστική πληροφορία, καθώς ο __συνδυασμός ήχου και εικόνας__ παρέχει περισσότερη πληροφορία και οδηγεί σε καλύτερη αναγνώριση λέξεων και φωνημάτων."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Βιβλιογραφία:\n",
    "\n",
    "* https://medium.com/@jonathan_hui/speech-recognition-gmm-hmm-8bb5eff8b196\n",
    "* http://www.inf.ed.ac.uk/teaching/courses/inf1/cl/notes/Comp7.pdf\n",
    "* https://github.com/foundintranslation/Kaldi/blob/master/tools/irstlm/src/compile-lm.cpp?fbclid=IwAR0VF5LUxSVesttL4eBFc32UXEypmymnU3XvWpIugTqefx2lURbhgDmX-ac\n",
    "* https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MC_He_Ch02.pdf\n",
    "* https://www.ijirae.com/volumes/vol1/issue10/27.NVEC10086.pdf\n",
    "* https://eleanorchodroff.com/tutorial/kaldi/training-acoustic-models.html#extract-mfcc-features\n",
    "* https://www.inf.ed.ac.uk/teaching/courses/asr/2016-17/lab1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
